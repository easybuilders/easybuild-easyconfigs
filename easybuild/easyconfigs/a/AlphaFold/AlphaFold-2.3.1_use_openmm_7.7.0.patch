# Add compatibility with OpenMM-7.7.0
# The patch is based on the recipe from https://github.com/deepmind/alphafold/issues/404
# Author: maxim-masterov (SURF)

diff -Nru alphafold-2.3.1.orig/alphafold/relax/amber_minimize.py alphafold-2.3.1/alphafold/relax/amber_minimize.py
--- alphafold-2.3.1.orig/alphafold/relax/amber_minimize.py	2023-03-28 10:58:07.126241000 +0200
+++ alphafold-2.3.1/alphafold/relax/amber_minimize.py	2023-03-28 11:24:17.380332000 +0200
@@ -27,10 +27,10 @@
 import ml_collections
 import numpy as np
 import jax
-from simtk import openmm
-from simtk import unit
-from simtk.openmm import app as openmm_app
-from simtk.openmm.app.internal.pdbstructure import PdbStructure
+from openmm import *
+from openmm import unit
+from openmm import app as openmm_app
+from openmm.app.internal.pdbstructure import PdbStructure
 
 
 ENERGY = unit.kilocalories_per_mole
@@ -47,7 +47,7 @@
 
 
 def _add_restraints(
-    system: openmm.System,
+    system: System,
     reference_pdb: openmm_app.PDBFile,
     stiffness: unit.Unit,
     rset: str,
diff -Nru alphafold-2.3.1.orig/alphafold/relax/cleanup.py alphafold-2.3.1/alphafold/relax/cleanup.py
--- alphafold-2.3.1.orig/alphafold/relax/cleanup.py	2023-03-28 10:58:07.126999000 +0200
+++ alphafold-2.3.1/alphafold/relax/cleanup.py	2023-03-28 11:03:20.689464000 +0200
@@ -20,8 +20,8 @@
 import io
 
 import pdbfixer
-from simtk.openmm import app
-from simtk.openmm.app import element
+from openmm import app
+from openmm.app import element
 
 
 def fix_pdb(pdbfile, alterations_info):
diff -Nru alphafold-2.3.1.orig/alphafold/relax/cleanup_test.py alphafold-2.3.1/alphafold/relax/cleanup_test.py
--- alphafold-2.3.1.orig/alphafold/relax/cleanup_test.py	2023-03-28 10:58:07.127710000 +0200
+++ alphafold-2.3.1/alphafold/relax/cleanup_test.py	2023-03-28 11:03:14.772207000 +0200
@@ -17,7 +17,7 @@
 
 from absl.testing import absltest
 from alphafold.relax import cleanup
-from simtk.openmm.app.internal import pdbstructure
+from openmm.app.internal import pdbstructure
 
 
 def _pdb_to_structure(pdb_str):
diff -Nru alphafold-2.3.1.orig/docker/Dockerfile alphafold-2.3.1/docker/Dockerfile
--- alphafold-2.3.1.orig/docker/Dockerfile	2023-03-28 10:58:07.081432000 +0200
+++ alphafold-2.3.1/docker/Dockerfile	2023-03-28 11:04:09.608354000 +0200
@@ -76,7 +76,6 @@
 
 # Apply OpenMM patch.
 WORKDIR /opt/conda/lib/python3.8/site-packages
-RUN patch -p0 < /app/alphafold/docker/openmm.patch
 
 # Add SETUID bit to the ldconfig binary so that non-root users can run it.
 RUN chmod u+s /sbin/ldconfig.real
diff -Nru alphafold-2.3.1.orig/notebooks/AlphaFold.ipynb alphafold-2.3.1/notebooks/AlphaFold.ipynb
--- alphafold-2.3.1.orig/notebooks/AlphaFold.ipynb	2023-03-28 10:58:07.092241000 +0200
+++ alphafold-2.3.1/notebooks/AlphaFold.ipynb	2023-03-28 11:04:51.464351000 +0200
@@ -103,16 +103,16 @@
         "      %shell rm -rf /opt/conda\n",
         "      %shell wget -q -P /tmp \\\n",
         "        https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
-        "          \u0026\u0026 bash /tmp/Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda \\\n",
-        "          \u0026\u0026 rm /tmp/Miniconda3-latest-Linux-x86_64.sh\n",
+        "          && bash /tmp/Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda \\\n",
+        "          && rm /tmp/Miniconda3-latest-Linux-x86_64.sh\n",
         "      pbar.update(9)\n",
         "\n",
         "      PATH=%env PATH\n",
         "      %env PATH=/opt/conda/bin:{PATH}\n",
         "      %shell conda install -qy conda==4.13.0 \\\n",
-        "          \u0026\u0026 conda install -qy -c conda-forge \\\n",
+        "          && conda install -qy -c conda-forge \\\n",
         "            python=3.8 \\\n",
-        "            openmm=7.5.1 \\\n",
+        "            openmm=7.7.0 \\\n",
         "            pdbfixer\n",
         "      pbar.update(80)\n",
         "\n",
@@ -161,8 +161,7 @@
         "      pbar.update(10)\n",
         "\n",
         "      # Apply OpenMM patch.\n",
-        "      %shell pushd /opt/conda/lib/python3.8/site-packages/ \u0026\u0026 \\\n",
-        "          patch -p0 \u003c /content/alphafold/docker/openmm.patch \u0026\u0026 \\\n",
+        "      %shell pushd /opt/conda/lib/python3.8/site-packages/ && \\\n",
         "          popd\n",
         "\n",
         "      # Make sure stereo_chemical_props.txt is in all locations where it could be searched for.\n",
@@ -186,9 +185,9 @@
         "\n",
         "import jax\n",
         "if jax.local_devices()[0].platform == 'tpu':\n",
-        "  raise RuntimeError('Colab TPU runtime not supported. Change it to GPU via Runtime -\u003e Change Runtime Type -\u003e Hardware accelerator -\u003e GPU.')\n",
+        "  raise RuntimeError('Colab TPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
         "elif jax.local_devices()[0].platform == 'cpu':\n",
-        "  raise RuntimeError('Colab CPU runtime not supported. Change it to GPU via Runtime -\u003e Change Runtime Type -\u003e Hardware accelerator -\u003e GPU.')\n",
+        "  raise RuntimeError('Colab CPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
         "else:\n",
         "  print(f'Running with {jax.local_devices()[0].device_kind} GPU')\n",
         "\n",
@@ -206,7 +205,7 @@
       "source": [
         "## Making a prediction\n",
         "\n",
-        "Please paste the sequence of your protein in the text box below, then run the remaining cells via _Runtime_ \u003e _Run after_. You can also run the cells individually by pressing the _Play_ button on the left.\n",
+        "Please paste the sequence of your protein in the text box below, then run the remaining cells via _Runtime_ > _Run after_. You can also run the cells individually by pressing the _Play_ button on the left.\n",
         "\n",
         "Note that the search against databases and the actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU you are allocated by Colab (see FAQ below)."
       ]
@@ -298,21 +297,21 @@
         "\n",
         "# Check whether total length exceeds limit.\n",
         "total_sequence_length = sum([len(seq) for seq in sequences])\n",
-        "if total_sequence_length \u003e MAX_LENGTH:\n",
+        "if total_sequence_length > MAX_LENGTH:\n",
         "  raise ValueError('The total sequence length is too long: '\n",
         "                   f'{total_sequence_length}, while the maximum is '\n",
         "                   f'{MAX_LENGTH}.')\n",
         "\n",
         "# Check whether we exceed the monomer limit.\n",
         "if model_type_to_use == ModelType.MONOMER:\n",
-        "  if len(sequences[0]) \u003e MAX_MONOMER_MODEL_LENGTH:\n",
+        "  if len(sequences[0]) > MAX_MONOMER_MODEL_LENGTH:\n",
         "    raise ValueError(\n",
         "        f'Input sequence is too long: {len(sequences[0])} amino acids, while '\n",
         "        f'the maximum for the monomer model is {MAX_MONOMER_MODEL_LENGTH}. You may '\n",
         "        'be able to run this sequence with the multimer model by selecting the '\n",
         "        'use_multimer_model_for_monomers checkbox above.')\n",
         "    \n",
-        "if total_sequence_length \u003e MAX_VALIDATED_LENGTH:\n",
+        "if total_sequence_length > MAX_VALIDATED_LENGTH:\n",
         "  print('WARNING: The accuracy of the system has not been fully validated '\n",
         "        'above 3000 residues, and you may experience long running times or '\n",
         "        f'run out of memory. Total sequence length is {total_sequence_length} '\n",
@@ -407,7 +406,7 @@
         "]\n",
         "\n",
         "# Search UniProt and construct the all_seq features only for heteromers, not homomers.\n",
-        "if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) \u003e 1:\n",
+        "if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
         "  MSA_DATABASES.extend([\n",
         "      # Swiss-Prot and TrEMBL are concatenated together as UniProt.\n",
         "      {'db_name': 'uniprot',\n",
@@ -441,7 +440,7 @@
         "  for sequence_index, sequence in enumerate(sorted(set(sequences)), 1):\n",
         "    fasta_path = f'target_{sequence_index:02d}.fasta'\n",
         "    with open(fasta_path, 'wt') as f:\n",
-        "      f.write(f'\u003equery\\n{sequence}')\n",
+        "      f.write(f'>query\\n{sequence}')\n",
         "    sequence_to_fasta_path[sequence] = fasta_path\n",
         "\n",
         "  # Run the search against chunks of genetic databases (since the genetic\n",
@@ -502,7 +501,7 @@
         "      num_templates=0, num_res=len(sequence)))\n",
         "\n",
         "  # Construct the all_seq features only for heteromers, not homomers.\n",
-        "  if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) \u003e 1:\n",
+        "  if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
         "    valid_feats = msa_pairing.MSA_FEATURES + (\n",
         "        'msa_species_identifiers',\n",
         "    )\n",
@@ -662,7 +661,7 @@
         "banded_b_factors = []\n",
         "for plddt in plddts[best_model_name]:\n",
         "  for idx, (min_val, max_val, _) in enumerate(PLDDT_BANDS):\n",
-        "    if plddt \u003e= min_val and plddt \u003c= max_val:\n",
+        "    if plddt >= min_val and plddt <= max_val:\n",
         "      banded_b_factors.append(idx)\n",
         "      break\n",
         "banded_b_factors = np.array(banded_b_factors)[:, None] * final_atom_mask\n",
@@ -675,14 +674,14 @@
         "  f.write(relaxed_pdb)\n",
         "\n",
         "\n",
-        "# --- Visualise the prediction \u0026 confidence ---\n",
+        "# --- Visualise the prediction & confidence ---\n",
         "show_sidechains = True\n",
         "def plot_plddt_legend():\n",
         "  \"\"\"Plots the legend for pLDDT.\"\"\"\n",
-        "  thresh = ['Very low (pLDDT \u003c 50)',\n",
-        "            'Low (70 \u003e pLDDT \u003e 50)',\n",
-        "            'Confident (90 \u003e pLDDT \u003e 70)',\n",
-        "            'Very high (pLDDT \u003e 90)']\n",
+        "  thresh = ['Very low (pLDDT < 50)',\n",
+        "            'Low (70 > pLDDT > 50)',\n",
+        "            'Confident (90 > pLDDT > 70)',\n",
+        "            'Very high (pLDDT > 90)']\n",
         "\n",
         "  colors = [x[2] for x in PLDDT_BANDS]\n",
         "\n",
@@ -796,13 +795,13 @@
         "id": "jeb2z8DIA4om"
       },
       "source": [
-        "## FAQ \u0026 Troubleshooting\n",
+        "## FAQ & Troubleshooting\n",
         "\n",
         "\n",
         "*   How do I get a predicted protein structure for my protein?\n",
         "    *   Click on the _Connect_ button on the top right to get started.\n",
         "    *   Paste the amino acid sequence of your protein (without any headers) into the “Enter the amino acid sequence to fold”.\n",
-        "    *   Run all cells in the Colab, either by running them individually (with the play button on the left side) or via _Runtime_ \u003e _Run all._ Make sure you run all 5 cells in order.\n",
+        "    *   Run all cells in the Colab, either by running them individually (with the play button on the left side) or via _Runtime_ > _Run all._ Make sure you run all 5 cells in order.\n",
         "    *   The predicted protein structure will be downloaded once all cells have been executed. Note: This can take minutes to hours - see below.\n",
         "*   How long will this take?\n",
         "    *   Downloading the AlphaFold source code can take up to a few minutes.\n",
@@ -811,8 +810,8 @@
         "    *   Running AlphaFold and generating the prediction can take minutes to hours, depending on the length of your protein and on which GPU-type Colab has assigned you.\n",
         "*   My Colab no longer seems to be doing anything, what should I do?\n",
         "    *   Some steps may take minutes to hours to complete.\n",
-        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ \u003e _Restart runtime_.\n",
-        "    *   If this doesn’t help, try resetting your Colab runtime via _Runtime_ \u003e _Factory reset runtime_.\n",
+        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ > _Restart runtime_.\n",
+        "    *   If this doesn’t help, try resetting your Colab runtime via _Runtime_ > _Factory reset runtime_.\n",
         "*   How does this compare to the open-source version of AlphaFold?\n",
         "    *   This Colab version of AlphaFold searches a selected portion of the BFD dataset and currently doesn’t use templates, so its accuracy is reduced in comparison to the full version of AlphaFold that is described in the [AlphaFold paper](https://doi.org/10.1038/s41586-021-03819-2) and [Github repo](https://github.com/deepmind/alphafold/) (the full version is available via the inference script).\n",
         "*   What is a Colab?\n",
@@ -821,7 +820,7 @@
         "    *   The resources allocated to your Colab vary. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
         "    *   You can execute the Colab nonetheless.\n",
         "*   I received an error “Colab CPU runtime not supported” or “No GPU/TPU found”, what do I do?\n",
-        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ \u003e _Change runtime type_ \u003e _Hardware accelerator_ \u003e _GPU_.\n",
+        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ > _Change runtime type_ > _Hardware accelerator_ > _GPU_.\n",
         "    *   The type of GPU allocated to your Colab varies. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
         "    *   If you receive “Cannot connect to GPU backend”, you can try again later to see if Colab allocates you a GPU.\n",
         "    *   [Colab Pro](https://colab.research.google.com/signup) offers priority access to GPUs.\n",
