Some tests that require NCCL also use GPUs. Skip those tests when none are available.

Author: Alexander Grund (TU Dresden)

diff --git a/torch/testing/_internal/common_distributed.py b/torch/testing/_internal/common_distributed.py
index 2a8fc04265c..f62678656d0 100644
--- a/torch/testing/_internal/common_distributed.py
+++ b/torch/testing/_internal/common_distributed.py
@@ -43,6 +43,7 @@ from torch.testing._internal.common_utils import (
     TEST_WITH_TSAN,
     TestCase,
     run_tests,
+    TEST_CUDA,
     TEST_HPU,
     TEST_XPU,
 )
@@ -327,6 +328,8 @@ def requires_gloo():
 
 
 def requires_nccl_version(version, msg):
+    if not TEST_CUDA:
+        return skip_but_pass_in_sandcastle(TEST_SKIPS["no_cuda"].message)
     if not c10d.is_nccl_available():
         return skip_but_pass_in_sandcastle(
             "c10d was not compiled with the NCCL backend",
@@ -339,6 +342,8 @@ def requires_nccl_version(version, msg):
 
 
 def requires_nccl():
+    if not TEST_CUDA:
+        return skip_but_pass_in_sandcastle(TEST_SKIPS["no_cuda"].message)
     return skip_but_pass_in_sandcastle_if(
         not c10d.is_nccl_available(),
         "c10d was not compiled with the NCCL backend",
