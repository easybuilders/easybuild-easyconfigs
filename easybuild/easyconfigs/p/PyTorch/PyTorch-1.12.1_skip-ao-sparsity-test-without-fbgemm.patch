Those tests (from test_ao_sparsity) require FBGEMM which may not be available.
So add the skip decorator.
See https://github.com/pytorch/pytorch/issues/87364

Author: Alexander Grund (TU Dresden)

diff --git a/test/ao/sparsity/test_composability.py b/test/ao/sparsity/test_composability.py
index b44c885507..b7d35343c0 100644
--- a/test/ao/sparsity/test_composability.py
+++ b/test/ao/sparsity/test_composability.py
@@ -9,6 +9,7 @@ import torch.ao.quantization as tq
 from torch import nn
 from torch.ao import sparsity
 from torch.testing._internal.common_utils import TestCase
+from torch.testing._internal.common_quantization import skipIfNoFBGEMM
 
 logging.basicConfig(
     format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
@@ -23,6 +24,7 @@ sparse_defaults = {
 # This series of tests are to check the composability goals for sparsity and quantization. Namely
 # that performing quantization and sparsity model manipulations in various orderings
 # does not cause problems
+@skipIfNoFBGEMM
 class TestComposability(TestCase):
     def _get_model_and_sparsifier_and_sparse_config(self, qconfig=None):
         model = nn.Sequential(
