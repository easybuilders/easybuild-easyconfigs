Collect various commits from upstream PyTorch 1.6+ to allow building against cuDNN 8.

Author: Alexander Grund (TU Dresden)

diff --git a/cmake/public/cuda.cmake b/cmake/public/cuda.cmake
index 8e3a0ca873..84adf901ad 100644
--- a/cmake/public/cuda.cmake
+++ b/cmake/public/cuda.cmake
@@ -133,7 +133,11 @@ endif()
 # ---[ Extract versions
 if(CAFFE2_USE_CUDNN)
   # Get cuDNN version
-  file(READ ${CUDNN_INCLUDE_PATH}/cudnn.h CUDNN_HEADER_CONTENTS)
+  if(EXISTS ${CUDNN_INCLUDE_PATH}/cudnn_version.h)
+    file(READ ${CUDNN_INCLUDE_PATH}/cudnn_version.h CUDNN_HEADER_CONTENTS)
+  else()
+    file(READ ${CUDNN_INCLUDE_PATH}/cudnn.h CUDNN_HEADER_CONTENTS)
+  endif()
   string(REGEX MATCH "define CUDNN_MAJOR * +([0-9]+)"
                CUDNN_VERSION_MAJOR "${CUDNN_HEADER_CONTENTS}")
   string(REGEX REPLACE "define CUDNN_MAJOR * +([0-9]+)" "\\1"
diff --git a/caffe2/operators/rnn/recurrent_op_cudnn.cc b/caffe2/operators/rnn/recurrent_op_cudnn.cc
index 8f69944dcf..3679c9d2a7 100644
--- a/caffe2/operators/rnn/recurrent_op_cudnn.cc
+++ b/caffe2/operators/rnn/recurrent_op_cudnn.cc
@@ -99,7 +99,7 @@ void RecurrentBaseOp<T>::initialize(
   // RNN setup
   {
 #if CUDNN_VERSION_MIN(7, 0, 0)
-    CUDNN_ENFORCE(cudnnSetRNNDescriptor(
+    CUDNN_ENFORCE(cudnnSetRNNDescriptor_v6(
         cudnn_wrapper_.inline_cudnn_handle(),
         rnnDesc_,
         hiddenSize,
diff --git a/caffe2/operators/conv_op_cudnn.cc b/caffe2/operators/conv_op_cudnn.cc
index 285a74cf41bb3..cfbebcfe601c4 100644
--- a/caffe2/operators/conv_op_cudnn.cc
+++ b/caffe2/operators/conv_op_cudnn.cc
@@ -751,15 +751,28 @@ bool CudnnConvOp::DoRunWithType() {
       }
     } else {
       // Get the convolution algorithm based on the workspace limit.
-      CUDNN_ENFORCE(cudnnGetConvolutionForwardAlgorithm(
+      constexpr int nalgo = CUDNN_CONVOLUTION_FWD_ALGO_COUNT;
+      int valid_algos;
+      cudnnConvolutionFwdAlgoPerf_t algos[nalgo];
+      CUDNN_ENFORCE(cudnnGetConvolutionForwardAlgorithm_v7(
           cudnn_wrapper_.inline_cudnn_handle(),
           bottom_desc_,
           filter_desc_,
           conv_desc_,
           top_desc_,
-          CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,
-          cudnn_ws_nbytes_limit_,
-          &algo_));
+          nalgo,
+          &valid_algos,
+          algos));
+      bool found = false;
+      for (int i = 0; i < valid_algos; i++) {
+        auto a = algos[i];
+        if (a.memory <= cudnn_ws_nbytes_limit_) {
+          algo_ = a.algo;
+          found = true;
+          break;
+        }
+      }
+      CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN forward");
     }
     for (int step = 0; step < 2; ++step) {
       cudnnStatus_t _status = cudnnGetConvolutionForwardWorkspaceSize(
@@ -1164,15 +1177,28 @@ bool CudnnConvGradientOp::DoRunWithType() {
       }
     } else {
       // choose backward algorithm for filter
-      CUDNN_ENFORCE(cudnnGetConvolutionBackwardFilterAlgorithm(
+      constexpr int nalgo = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_COUNT;
+      int valid_algos;
+      cudnnConvolutionBwdFilterAlgoPerf_t algos[nalgo];
+      CUDNN_ENFORCE(cudnnGetConvolutionBackwardFilterAlgorithm_v7(
           cudnn_wrapper_.inline_cudnn_handle(),
           bottom_desc_,
           top_desc_,
           bwd_filter_conv_desc_,
           filter_desc_,
-          CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT,
-          cudnn_ws_nbytes_limit_,
-          &bwd_filter_algo_));
+          nalgo,
+          &valid_algos,
+          algos));
+      bool found = false;
+      for (int i = 0; i < valid_algos; i++) {
+        auto a = algos[i];
+        if (a.memory <= cudnn_ws_nbytes_limit_) {
+          bwd_filter_algo_ = a.algo;
+          found = true;
+          break;
+        }
+      }
+      CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN backward filter");
     }
     // Pick dX algo if needed
     if (OutputSize() == 3 || (no_bias_ && (OutputSize() == 2))) {
@@ -1252,15 +1278,28 @@ bool CudnnConvGradientOp::DoRunWithType() {
               bwd_data_conv_desc_, kComputeTypesToTry[bestAlgoIndex]);
         }
       } else {
-        CUDNN_ENFORCE(cudnnGetConvolutionBackwardDataAlgorithm(
+        constexpr int nalgo = CUDNN_CONVOLUTION_BWD_DATA_ALGO_COUNT;
+        int valid_algos;
+        cudnnConvolutionBwdDataAlgoPerf_t algos[nalgo];
+        CUDNN_ENFORCE(cudnnGetConvolutionBackwardDataAlgorithm_v7(
             cudnn_wrapper_.inline_cudnn_handle(),
             filter_desc_,
             top_desc_,
             bwd_data_conv_desc_,
             bottom_desc_,
-            CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT,
-            cudnn_ws_nbytes_limit_,
-            &bwd_data_algo_));
+            nalgo,
+            &valid_algos,
+            algos));
+        bool found = false;
+        for (int i = 0; i < valid_algos; i++) {
+          auto a = algos[i];
+          if (a.memory <= cudnn_ws_nbytes_limit_) {
+            bwd_data_algo_ = a.algo;
+            found = true;
+            break;
+          }
+        }
+        CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN backward data");
       }
     }
 
diff --git a/caffe2/operators/conv_transpose_op_cudnn.cc b/caffe2/operators/conv_transpose_op_cudnn.cc
index c00e43eadc476..d432e4d30780f 100644
--- a/caffe2/operators/conv_transpose_op_cudnn.cc
+++ b/caffe2/operators/conv_transpose_op_cudnn.cc
@@ -356,15 +356,28 @@ bool CudnnConvTransposeOp<T>::RunOnDevice() {
             return data_perf_stat[0].algo;
           });
     } else {
-      CUDNN_ENFORCE(cudnnGetConvolutionBackwardDataAlgorithm(
+      constexpr int nalgo = CUDNN_CONVOLUTION_BWD_DATA_ALGO_COUNT;
+      int valid_algos;
+      cudnnConvolutionBwdDataAlgoPerf_t algos[nalgo];
+      CUDNN_ENFORCE(cudnnGetConvolutionBackwardDataAlgorithm_v7(
           cudnn_wrapper_.inline_cudnn_handle(),
           filter_desc_,
           bottom_desc_,
           conv_desc_,
           top_desc_,
-          CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT,
-          cudnn_ws_nbytes_limit_,
-          &bwd_data_algo_));
+          nalgo,
+          &valid_algos,
+          algos));
+      bool found = false;
+      for (int i = 0; i < valid_algos; i++) {
+        auto a = algos[i];
+        if (a.memory <= cudnn_ws_nbytes_limit_) {
+          bwd_data_algo_ = a.algo;
+          found = true;
+          break;
+        }
+      }
+      CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN backward data");
     }
 
     size_t bwd_data_ws_size;
@@ -661,25 +674,55 @@ bool CudnnConvTransposeGradientOp<T>::RunOnDevice() {
           });
     } else {
       // choose backward algorithm for filter
-      CUDNN_ENFORCE(cudnnGetConvolutionBackwardFilterAlgorithm(
+      {
+      constexpr int nalgo = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_COUNT;
+      int valid_algos;
+      cudnnConvolutionBwdFilterAlgoPerf_t algos[nalgo];
+      CUDNN_ENFORCE(cudnnGetConvolutionBackwardFilterAlgorithm_v7(
           cudnn_wrapper_.inline_cudnn_handle(),
           top_desc_,
           bottom_desc_,
           conv_desc_,
           filter_desc_,
-          CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT,
-          cudnn_ws_nbytes_limit_,
-          &bwd_filter_algo_));
+          nalgo,
+          &valid_algos,
+          algos));
+      bool found = false;
+      for (int i = 0; i < valid_algos; i++) {
+        auto a = algos[i];
+        if (a.memory <= cudnn_ws_nbytes_limit_) {
+          bwd_filter_algo_ = a.algo;
+          found = true;
+          break;
+        }
+      }
+      CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN backward filter");
+      }
       // choose backward algo for data
-      CUDNN_ENFORCE(cudnnGetConvolutionForwardAlgorithm(
+      {
+      constexpr int nalgo = CUDNN_CONVOLUTION_FWD_ALGO_COUNT;
+      int valid_algos;
+      cudnnConvolutionFwdAlgoPerf_t algos[nalgo];
+      CUDNN_ENFORCE(cudnnGetConvolutionForwardAlgorithm_v7(
           cudnn_wrapper_.inline_cudnn_handle(),
           top_desc_,
           filter_desc_,
           conv_desc_,
           bottom_desc_,
-          CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,
-          cudnn_ws_nbytes_limit_,
-          &algo_));
+          nalgo,
+          &valid_algos,
+          algos));
+      bool found = false;
+      for (int i = 0; i < valid_algos; i++) {
+        auto a = algos[i];
+        if (a.memory <= cudnn_ws_nbytes_limit_) {
+          algo_ = a.algo;
+          found = true;
+          break;
+        }
+      }
+      CAFFE_ENFORCE(found, "Unable to find algorithms for cuDNN forward");
+      }
     }
     // get workspace for backwards filter algorithm
     size_t bwd_filter_ws_size, fwd_ws_size;
