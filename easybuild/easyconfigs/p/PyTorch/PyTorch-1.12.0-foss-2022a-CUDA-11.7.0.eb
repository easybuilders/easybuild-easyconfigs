name = 'PyTorch'
version = '1.12.0'
versionsuffix = '-CUDA-%(cudaver)s'

homepage = 'https://pytorch.org/'
description = """Tensors and Dynamic neural networks in Python with strong GPU acceleration.
PyTorch is a deep learning framework that puts Python first."""

toolchain = {'name': 'foss', 'version': '2022a'}

source_urls = [GITHUB_RELEASE]
sources = ['%(namelower)s-v%(version)s.tar.gz']
patches = [
    'PyTorch-1.7.0_avoid-nan-in-test-torch.patch',
    'PyTorch-1.7.0_disable-dev-shm-test.patch',
    'PyTorch-1.10.0_fix-kineto-crash.patch',
    'PyTorch-1.10.0_fix-test-dataloader-fixed-affinity.patch',
    'PyTorch-1.10.0_fix-test-model_dump.patch',
    'PyTorch-1.10.0_fix-vsx-vector-functions.patch',
    'PyTorch-1.10.0_skip-nnapi-test-without-qnnpack.patch',
    'PyTorch-1.11.0_fix-fp16-quantization-without-fbgemm.patch',
    'PyTorch-1.11.0_fix-fsdp-fp16-test.patch',
    'PyTorch-1.11.0_fix-test_utils.patch',
    'PyTorch-1.11.0_increase_c10d_gloo_timeout.patch',
    'PyTorch-1.11.0_increase-distributed-test-timeout.patch',
    'PyTorch-1.11.0_install-vsx-vec-headers.patch',
    'PyTorch-1.12.0_fix-EmbeddingBag-without-fbgemm.patch',
    'PyTorch-1.12.0_fix-Gloo-compatibility-with-newer-kernel.patch',
    'PyTorch-1.12.1_add-hypothesis-suppression.patch',
    'PyTorch-1.12.1_fix-cuda-gcc-version-check.patch',
    'PyTorch-1.12.1_fix-skip-decorators.patch',
    'PyTorch-1.12.1_fix-test_cpp_extensions_jit.patch',
    'PyTorch-1.12.1_fix-test_wishart_log_prob.patch',
    'PyTorch-1.12.1_fix-TestCudaFuser.test_unary_ops.patch',
    'PyTorch-1.12.1_fix-TestTorch.test_to.patch',
    'PyTorch-1.12.1_fix-use-after-free-in-tensorpipe-agent.patch',
    'PyTorch-1.12.1_fix-vsx-vector-funcs.patch',
    'PyTorch-1.12.1_fix-vsx-loadu.patch',
    'PyTorch-1.12.1_increase-test-adadelta-tolerance.patch',
    'PyTorch-1.12.1_increase-tolerance-test_ops.patch',
    'PyTorch-1.12.1_no-cuda-stubs-rpath.patch',
    'PyTorch-1.12.1_python-3.10-annotation-fix.patch',
    'PyTorch-1.12.1_python-3.10-compat.patch',
    'PyTorch-1.12.1_remove-flaky-test-in-testnn.patch',
    'PyTorch-1.12.1_skip-ao-sparsity-test-without-fbgemm.patch',
    'PyTorch-1.12.1_skip-failing-grad-test.patch',
    'PyTorch-1.12.1_skip-test_round_robin_create_destroy.patch',
    'PyTorch-2.0.1_skip-test_baddbmm_cpu_bfloat16.patch',
]
checksums = [
    {'pytorch-v1.12.0.tar.gz': '46eff236370b759c427b03ff535c3597099043e8e467b8f81f9cd4b258a7a321'},
    {'PyTorch-1.7.0_avoid-nan-in-test-torch.patch':
     'b899aa94d9e60f11ee75a706563312ccefa9cf432756c470caa8e623991c8f18'},
    {'PyTorch-1.7.0_disable-dev-shm-test.patch': '622cb1eaeadc06e13128a862d9946bcc1f1edd3d02b259c56a9aecc4d5406b8a'},
    {'PyTorch-1.10.0_fix-kineto-crash.patch': 'dc467333b28162149af8f675929d8c6bf219f23230bfc0d39af02ba4f6f882eb'},
    {'PyTorch-1.10.0_fix-test-dataloader-fixed-affinity.patch':
     '313dca681f45ce3bc7c4557fdcdcbe0b77216d2c708fa30a2ec0e22c44876707'},
    {'PyTorch-1.10.0_fix-test-model_dump.patch': '339148ae1a028cda6e750ac93fa38a599f66c7abe26586c9219f1a206ea14557'},
    {'PyTorch-1.10.0_fix-vsx-vector-functions.patch':
     '7bef5f96cb83b2d655d2f76dd7468a171d446f0b3e06da2232ec7f886484d312'},
    {'PyTorch-1.10.0_skip-nnapi-test-without-qnnpack.patch':
     '34ba476a7bcddec323bf9eca083cb4623d0f569d081aa3add3769c24f22849d2'},
    {'PyTorch-1.11.0_fix-fp16-quantization-without-fbgemm.patch':
     'cc526130b6446bbbf5f0f7372d3aeee3e7d4c4d6e471524dff028b430b152934'},
    {'PyTorch-1.11.0_fix-fsdp-fp16-test.patch': 'bb1c4e6d6fd4b0cf57ff8b824c797331b533bb1ffc63f5db0bae3aee10c3dc13'},
    {'PyTorch-1.11.0_fix-test_utils.patch': '4f7e25c4e2eb7094f92607df74488c6a4a35849fabf05fcf6c3655fa3f44a861'},
    {'PyTorch-1.11.0_increase_c10d_gloo_timeout.patch':
     '20cd4a8663f74ab326fdb032b926bf5c7e94d9750c515ab9050927ba00cf1953'},
    {'PyTorch-1.11.0_increase-distributed-test-timeout.patch':
     '087ad20163a1291773ae3457569b80523080eb3731e210946459b2333a919f3f'},
    {'PyTorch-1.11.0_install-vsx-vec-headers.patch':
     'f2e6b9625733d9a471bb75e1ea20e28814cf1380b4f9089aa838ee35ddecf07d'},
    {'PyTorch-1.12.0_fix-EmbeddingBag-without-fbgemm.patch':
     '090598592283e3fc46ee08a68b6a6afe07be41b26514afba51834408bf1c98ed'},
    {'PyTorch-1.12.0_fix-Gloo-compatibility-with-newer-kernel.patch':
     '0d19c3dd7ea088aae2f18a2552420293a06ed0a0e1e8e2a28d44ff3847de32af'},
    {'PyTorch-1.12.1_add-hypothesis-suppression.patch':
     'e71ffb94ebe69f580fa70e0de84017058325fdff944866d6bd03463626edc32c'},
    {'PyTorch-1.12.1_fix-cuda-gcc-version-check.patch':
     'a650f4576f06c749f244cada52ff9c02499fa8f182019129488db3845e0756ab'},
    {'PyTorch-1.12.1_fix-skip-decorators.patch': 'e3ca6e42b2fa592ea095939fb59ab875668a058479407db3f3684cc5c6f4146c'},
    {'PyTorch-1.12.1_fix-test_cpp_extensions_jit.patch':
     '1efc9850c431d702e9117d4766277d3f88c5c8b3870997c9974971bce7f2ab83'},
    {'PyTorch-1.12.1_fix-test_wishart_log_prob.patch':
     'cf475ae6e6234b96c8d1bf917597c5176c94b3ccd940b72f2e1cd0c979580f45'},
    {'PyTorch-1.12.1_fix-TestCudaFuser.test_unary_ops.patch':
     '8e6e844c6b0541e0c8115911ee1a9d548613254b36dfbdada202fd723fc26aa2'},
    {'PyTorch-1.12.1_fix-TestTorch.test_to.patch': '75f27987c3f25c501e719bd2b1c70a029ae0ee28514a97fe447516aee02b1535'},
    {'PyTorch-1.12.1_fix-use-after-free-in-tensorpipe-agent.patch':
     '0bd7e88b92c4c6f0fecf01746009858ba19f2df68b10b88c41485328a531875d'},
    {'PyTorch-1.12.1_fix-vsx-vector-funcs.patch': 'caccbf60f62eac313896c1eaec78b08f5d0fdfcb907079087490bb13d1561aa2'},
    {'PyTorch-1.12.1_fix-vsx-loadu.patch': '8bfe3c94ada1dd1f7974a1261a8b576fb7ae944050fa1c7830fca033831123b2'},
    {'PyTorch-1.12.1_increase-test-adadelta-tolerance.patch':
     '944ed1af5ad4bbe20cbb042764a88dad1eef6cd33218617cf3d4cd90c6764695'},
    {'PyTorch-1.12.1_increase-tolerance-test_ops.patch':
     '1c1fa520801e2ee5faf56a3d6dc96321e7c11664fd16bffd7c6ee437e68357fb'},
    {'PyTorch-1.12.1_no-cuda-stubs-rpath.patch': '2905826ca713752b47c84e4ec8b177c90cbd91fca498ba2ba546f495c4cf70a6'},
    {'PyTorch-1.12.1_python-3.10-annotation-fix.patch':
     '11e168fd429d9e156fc79dd806b08125f3640651ad9998abd810446b2ed0c2d7'},
    {'PyTorch-1.12.1_python-3.10-compat.patch': '81402420a878b40f824778f0333fbec6504325a6a1b06a22749c4cac3eaccf67'},
    {'PyTorch-1.12.1_remove-flaky-test-in-testnn.patch':
     'e81b678e354dd137c0d6d974605cdedbf672096fdbdf567c347bc2fbfc73471d'},
    {'PyTorch-1.12.1_skip-ao-sparsity-test-without-fbgemm.patch':
     'edd464ec8c37b44c07a72008d732604f6837f2dd61c7810c391a86ba4945ca39'},
    {'PyTorch-1.12.1_skip-failing-grad-test.patch':
     '1c89e7e67287fe6b9a95480a4178d3653b94d0ab2fe68edf227606c8ae548fdc'},
    {'PyTorch-1.12.1_skip-test_round_robin_create_destroy.patch':
     '1435fcac3234edc865479199673b902eb67f6a2bd046af7d731141f03594666d'},
    {'PyTorch-2.0.1_skip-test_baddbmm_cpu_bfloat16.patch':
     '199005bbbb913837e557358dee31535d8e3f63af9ac7cdcece624ab8e572e28a'},
]

builddependencies = [
    ('CMake', '3.23.1'),
    ('hypothesis', '6.46.7'),
]
dependencies = [
    ('CUDA', '11.7.0', '', SYSTEM),
    ('Ninja', '1.10.2'),  # Required for JIT compilation of C++ extensions
    ('Python', '3.10.4'),
    ('protobuf', '3.19.4'),
    ('protobuf-python', '3.19.4'),
    ('pybind11', '2.9.2'),
    ('SciPy-bundle', '2022.05'),
    ('PyYAML', '6.0'),
    ('MPFR', '4.1.0'),
    ('GMP', '6.2.1'),
    ('numactl', '2.0.14'),
    ('FFmpeg', '4.4.2'),
    ('Pillow', '9.1.1'),
    ('cuDNN', '8.4.1.50', '-CUDA-%(cudaver)s', SYSTEM),
    ('magma', '2.6.2', '-CUDA-%(cudaver)s'),
    ('NCCL', '2.12.12', '-CUDA-%(cudaver)s'),
    ('expecttest', '0.1.3'),
]

osdependencies = [('libibverbs-dev', 'libibverbs-devel', 'rdma-core-devel')]

# default CUDA compute capabilities to use (override via --cuda-compute-capabilities)
cuda_compute_capabilities = [
    '3.5',
    '3.7',
    '5.2',
    '6.0',
    '6.1',
    '7.0',
    '7.2',
    '7.5',
    '8.0',
    '8.6',
]

custom_opts = ['USE_CUPTI_SO=1']

excluded_tests = {
    '': [
        # Bad tests: https://github.com/pytorch/pytorch/issues/60260
        'distributed/elastic/utils/distributed_test',
        'distributed/elastic/multiprocessing/api_test',
        # These tests fail on A10s at the very least, they time out forever no matter how long the timeout is.
        # Possibly related to NCCL 2.8.3: https://docs.nvidia.com/deeplearning/nccl/release-notes/rel_2-8-3.html
        # 'distributed/test_distributed_fork',
        'distributed/test_distributed_spawn',
        # Fails on A10s: https://github.com/pytorch/pytorch/issues/63079
        'test_optim',
        # Test from this suite timeout often. The process group backend is deprecated anyway
        # 'distributed/rpc/test_process_group_agent',
        # This test fails constently when run as part of the test suite, but succeeds when run interactively
        'test_model_dump',
        # These tests appear flaky, possibly related to number of GPUs that are used
        'distributed/fsdp/test_fsdp_memory',
        'distributed/fsdp/test_fsdp_overlap',
    ]
}

runtest = "cd test && PYTHONUNBUFFERED=1 %(python)s run_test.py --continue-through-error  --verbose %(excluded_tests)s"

# several tests are known to be flaky, and fail in some contexts (like having multiple GPUs available),
# so we allow up to 400 (out of ~90k) tests to fail before treating the installation to be faulty
max_failed_tests = 400

# The readelf sanity check command can be taken out once the TestRPATH test from 
# https://github.com/pytorch/pytorch/pull/68912 is accepted, since it is then checked as part of the PyTorch test suite
local_libcaffe2 = "$EBROOTPYTORCH/lib/python%%(pyshortver)s/site-packages/torch/lib/libcaffe2_nvrtc.%s" % SHLIB_EXT
sanity_check_commands = [
    "readelf -d %s | egrep 'RPATH|RUNPATH' | grep -v stubs" % local_libcaffe2,
]

tests = ['%(name)s-check-cpp-extension.py']

moduleclass = 'ai'
