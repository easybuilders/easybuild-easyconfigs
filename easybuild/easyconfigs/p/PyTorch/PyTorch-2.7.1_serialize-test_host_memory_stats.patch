Fix test_cuda.py TestCuda.test_host_memory_stats
> AssertionError: Scalars are not equal!
> Expected 50333384 but got 0.


From 7abca8cebac9e399151af771233ee2f5d202c5e6 Mon Sep 17 00:00:00 2001
From: eqy <eddiey@nvidia.com>
Date: Thu, 1 May 2025 00:53:15 +0000
Subject: [PATCH] Decorate `test_host_memory_stats` with `@serialTest`
 (#152454)

Seems to need it as it is expecting only its allocation behavior to be visible, to address #152422
Pull Request resolved: https://github.com/pytorch/pytorch/pull/152454
Approved by: https://github.com/Skylion007
---
 test/test_cuda.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/test/test_cuda.py b/test/test_cuda.py
index 93a10072d832..c74f099358f3 100644
--- a/test/test_cuda.py
+++ b/test/test_cuda.py
@@ -165,6 +165,7 @@ def test_pinned_memory_with_cudaregister_multithread(self):
         for thread in threads:
             thread.join()
 
+    @serialTest
     def test_host_memory_stats(self):
         # Helper functions
         def empty_stats():
