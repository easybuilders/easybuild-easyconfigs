From 63c753573d726ae37cac2783fa0f6a3fd1c30e59 Mon Sep 17 00:00:00 2001
From: Alexander Grund <alexander.grund@tu-dresden.de>
Date: Thu, 15 Apr 2021 14:40:39 +0200
Subject: [PATCH] Fix segmentation fault due to access to destroyed
 CudaIPCGlobalEntities instance

There is an instance of the static destruction order fiasco where cuda_ipc_global_entities
may be accessed after it is destroyed. See #51961

This change uses a flag and avoids accesses to the destroyed class when it is set to false.
---
 torch/csrc/CudaIPCTypes.cpp | 23 ++++++++++++++++++++++-
 1 file changed, 22 insertions(+), 1 deletion(-)

diff --git a/torch/csrc/CudaIPCTypes.cpp b/torch/csrc/CudaIPCTypes.cpp
index be2095d9654c6..9146150c04002 100644
--- a/torch/csrc/CudaIPCTypes.cpp
+++ b/torch/csrc/CudaIPCTypes.cpp
@@ -25,6 +25,13 @@ void warnProducerTerminatedBeforeSharedTensorsReleased() {
 }
 
 struct CudaIPCGlobalEntities {
+  // This class is used as a singleton (see cuda_ipc_global_entities)
+  // This variable is used to track its lifetime to avoid accessing it
+  // after it was destroyed which would lead to segmentation faults
+  // Note that a trvial type is used which doesn't suffer from construction
+  // and destruction order issues
+  static bool alive;
+
   std::mutex ref_counters_mutex_;
   std::atomic<int64_t> sync_events_used_;
   std::map<std::string, std::shared_ptr<CudaIPCRefCountersFile>>
@@ -32,18 +39,14 @@ struct CudaIPCGlobalEntities {
   std::shared_ptr<CudaIPCRefCountersFile> next_available_ref_counters_file_;
   CudaIPCSentDataLimbo CudaIPCSentDataLimbo_;
   // NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)
-  CudaIPCGlobalEntities() : ref_counters_files_() {}
+  CudaIPCGlobalEntities() { alive = true; }
   ~CudaIPCGlobalEntities() {
     CudaIPCSentDataLimbo_.collect();
-    // Clear shared blocks to avoid releasing shared blocks after
-    // ~CudaIPCGlobalEntities is done since circular references causes the
-    // destructor of ~CudaIPCSentData to access the cuda_ipc_global_entities
-    // again.
-    CudaIPCSentDataLimbo_.clear_shared_blocks();
     safe_clean_current_file();
     if (next_available_ref_counters_file_) {
       warnProducerTerminatedBeforeSharedTensorsReleased();
     }
+    alive = false;
   }
   void safe_clean_current_file() {
     std::lock_guard<std::mutex> lock(ref_counters_mutex_);
@@ -54,6 +62,7 @@ struct CudaIPCGlobalEntities {
   }
 };
 
+bool CudaIPCGlobalEntities::alive = false;
 CudaIPCGlobalEntities cuda_ipc_global_entities;
 
 CudaIPCSentDataLimbo::~CudaIPCSentDataLimbo() {
@@ -108,6 +117,9 @@ void CudaIPCSentDataLimbo::add(std::unique_ptr<CudaIPCSentData> shared_block) {
 void CudaIPCSentDataDelete(void* ptr) {
   std::unique_ptr<CudaIPCSentData> sent_data(
       static_cast<CudaIPCSentData*>(ptr));
+  if(!CudaIPCGlobalEntities::alive) {
+    return;
+  }
   if (sent_data->counter_value() > 0) {
     cuda_ipc_global_entities.CudaIPCSentDataLimbo_.add(std::move(sent_data));
   }
@@ -115,6 +127,9 @@ void CudaIPCSentDataDelete(void* ptr) {
 }
 
 void ReturnRefCounter(const std::string& handle, uint64_t offset /* unused */) {
+  if(!CudaIPCGlobalEntities::alive) {
+    return;
+  }
   std::lock_guard<std::mutex> lock(
       cuda_ipc_global_entities.ref_counters_mutex_);
   auto& map = cuda_ipc_global_entities.ref_counters_files_;
@@ -185,6 +200,9 @@ CudaIPCSentData::~CudaIPCSentData() {
     if (event_sync_required_) {
       at::cuda::CUDAGuard device_guard(device_.index());
       cudaEventDestroy(event_);
+      if(!CudaIPCGlobalEntities::alive) {
+        return;
+      }
       cuda_ipc_global_entities.sync_events_used_ --;
     }
   } catch (...) { /* No throw */
@@ -239,6 +257,9 @@ at::DataPtr GetNewRefCountedSentData(void* data, at::Device device) {
 }
 
 bool CudaIPCCollect() {
+  if(!CudaIPCGlobalEntities::alive) {
+    return true;
+  }
   bool freed_memory = cuda_ipc_global_entities.CudaIPCSentDataLimbo_.collect();
   if (cuda_ipc_global_entities.CudaIPCSentDataLimbo_.size() == 0) {
     cuda_ipc_global_entities.safe_clean_current_file();
