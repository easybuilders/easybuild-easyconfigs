Those tests (from test_ao_sparsity & test_quantization) require FBGEMM which may not be available.
So add the skip decorator.
See https://github.com/pytorch/pytorch/issues/87364

Author: Alexander Grund (TU Dresden)

diff --git a/test/ao/sparsity/test_composability.py b/test/ao/sparsity/test_composability.py
index 6a1b6067a4c..0c43f585af2 100644
--- a/test/ao/sparsity/test_composability.py
+++ b/test/ao/sparsity/test_composability.py
@@ -9,6 +9,7 @@ import torch.ao.quantization as tq
 from torch import nn
 from torch.ao import sparsity
 from torch.testing._internal.common_utils import TestCase
+from torch.testing._internal.common_quantization import skipIfNoFBGEMM
 from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx, convert_to_reference_fx, prepare_qat_fx
 from torch.ao.sparsity import fqn_to_module
 
@@ -62,6 +63,7 @@ def _calculate_sparsity(tensor):
 # This series of tests are to check the composability goals for sparsity and quantization. Namely
 # that performing quantization and sparsity model manipulations in various orderings
 # does not cause problems
+@skipIfNoFBGEMM
 class TestComposability(TestCase):
     # This test checks whether performing quantization prepare before sparse prepare
     # causes any issues and verifies that the correct observers are inserted and that
@@ -326,6 +328,7 @@ class TestFxComposability(TestCase):
     r"""This series of tests checks that various steps of the quantization and sparsity flow
     compose cleanly despite variation in sequencing.
     """
+    @skipIfNoFBGEMM
     def test_q_prep_fx_before_s_prep(self):
         r"""
         This test checks that the ordering of prepare_fx -> sparse prepare -> convert_fx
@@ -445,6 +448,7 @@ class TestFxComposability(TestCase):
         )
         self.assertGreaterAlmostEqual(cur_sparsity, sparse_config[0]["sparsity_level"])
 
+    @skipIfNoFBGEMM
     def test_s_prep_before_q_prep_fx(self):
         r"""
         This test checks that the ordering of sparse prepare -> prepare_fx -> convert_fx
@@ -490,6 +494,7 @@ class TestFxComposability(TestCase):
         )
         self.assertGreaterAlmostEqual(cur_sparsity, sparse_config[0]["sparsity_level"])
 
+    @skipIfNoFBGEMM
     def test_s_prep_before_qat_prep_fx(self):
         r"""
         This test checks that the ordering of sparse prepare -> prepare_qat_fx -> convert_fx
diff --git a/test/quantization/core/test_docs.py b/test/quantization/core/test_docs.py
index 27842b46ce7..8e50ffa3166 100644
--- a/test/quantization/core/test_docs.py
+++ b/test/quantization/core/test_docs.py
@@ -10,11 +10,13 @@ import torch
 from torch.testing._internal.common_quantization import (
     QuantizationTestCase,
     SingleLayerLinearModel,
+    skipIfNoFBGEMM,
 )
 from torch.testing._internal.common_quantized import override_quantized_engine
 from torch.testing._internal.common_utils import IS_ARM64
 
 
+@skipIfNoFBGEMM
 class TestQuantizationDocs(QuantizationTestCase):
     r"""
     The tests in this section import code from the quantization docs and check that
