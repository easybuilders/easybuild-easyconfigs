The jit_opt_level must be passed as void* directly.
See https://github.com/pytorch/pytorch/issues/52147

Author: Alexander Grund (TU Dresden)

diff --git a/torch/csrc/jit/codegen/cuda/executor_utils.cpp b/torch/csrc/jit/codegen/cuda/executor_utils.cpp
index 9670968b8f..427d1a90b1 100644
--- a/torch/csrc/jit/codegen/cuda/executor_utils.cpp
+++ b/torch/csrc/jit/codegen/cuda/executor_utils.cpp
@@ -293,7 +293,7 @@ NvrtcFunction nvrtcCompile(
     if (val <= 4 && val >= 0) {
       jit_opt_level = static_cast<uint32_t>(val);
       options.push_back(CU_JIT_OPTIMIZATION_LEVEL);
-      option_vals.emplace_back(&jit_opt_level);
+      option_vals.emplace_back((void*) jit_opt_level);
     } else {
       TORCH_WARN_ONCE(
           "acceptable range for PYTORCH_CUDA_FUSER_JIT_OPT_LEVEL is between 0 and 4, but received ",
