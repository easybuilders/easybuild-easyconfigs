test_round_robin & test_round_robin_create_destroy of distributed/test_c10d_gloo may run into timeouts.
So simply skip the on all OS (not only on Windows), the existing skip marker suggest that this is OK.

Author: Alexander Grund (TU Dresden)

diff --git a/test/distributed/test_c10d_gloo.py b/test/distributed/test_c10d_gloo.py
index e49d65ea33d..b4fb75a1b11 100644
--- a/test/distributed/test_c10d_gloo.py
+++ b/test/distributed/test_c10d_gloo.py
@@ -10,6 +10,7 @@ import sys
 import tempfile
 from functools import reduce
 from itertools import groupby
+from unittest import skip
 
 import torch
 import torch.distributed as c10d
@@ -1415,7 +1415,7 @@ class ProcessGroupGlooTest(MultiProcessTestCase):
         for i, tensor in enumerate(tensors):
             self.assertEqual(torch.full(size, float(i * self.world_size)), tensor)
 
-    @skip_if_win32()
+    @skip("Occasionally times out")
     @requires_gloo()
     def test_round_robin(self):
         num_process_groups = 2
@@ -1438,7 +1439,7 @@ class ProcessGroupGlooTest(MultiProcessTestCase):
             pg.broadcast(tensor, root=0).wait()
             self.assertEqual(torch.full([100, 100], 0.0), tensor)
 
-    @skip_if_win32()
+    @skip("Occasionally times out")
     @requires_gloo()
     def test_round_robin_create_destroy(self):
         store = c10d.FileStore(self.file_name, self.world_size)
