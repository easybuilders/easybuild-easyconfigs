easyblock = 'Tarball'

name = 'Spark'
version = '2.2.0'
versionsuffix = '-Hadoop-2.6-Java-%(javaver)s-Python-%(pyver)s'

homepage = 'https://spark.apache.org'
description = """Spark is Hadoop MapReduce done in memory"""

toolchain = {'name': 'intel', 'version': '2017b'}

sources = ['%(namelower)s-%(version)s-bin-hadoop2.6.tgz']
source_urls = [
    'http://apache.belnet.be/%(namelower)s/%(namelower)s-%(version)s/',
    'http://www.eu.apache.org/dist/%(namelower)s/%(namelower)s-%(version)s/',
    'http://www.us.apache.org/dist/%(namelower)s/%(namelower)s-%(version)s/',
]
checksums = ['86f33f6f4fe545cb848600004144f09b6e8413af47ce02c1203c3ecda075288d']

dependencies = [
    ('Java', '1.8.0_152', '', True),
    ('Python', '3.6.3'),
]

exts_defaultclass = 'PythonPackage'

exts_default_options = {'source_urls': [PYPI_SOURCE]}

exts_list = [
    ('py4j', '0.10.4', {
        'checksums': ['b49a28c6bd96d334a39c15c3ce52225585332eff5e2659c7dc7aa223aa8bd454'],
    }),
    ('pyspark', version, {
        'source_tmpl': 'spark-%(version)s-bin-hadoop2.6.tgz',
        'start_dir': 'python',
        'checksums': ['86f33f6f4fe545cb848600004144f09b6e8413af47ce02c1203c3ecda075288d'],
    }),
]

modextrapaths = {'PYTHONPATH': ['lib/python%(pyshortver)s/site-packages']}

sanity_check_paths = {
    'files': ['bin/spark-shell', 'bin/pyspark'],
    'dirs': ['python']
}

moduleclass = 'devel'
