name = 'nvidia-compilers'
version = '25.7'

homepage = 'https://developer.nvidia.com/hpc-sdk/'
description = "C, C++ and Fortran compilers included with the NVIDIA HPC SDK"

toolchain = {'name': 'GCCcore', 'version': '13.2.0'}

# By downloading, you accept the HPC SDK Software License Agreement
# https://docs.nvidia.com/hpc-sdk/eula/index.html
local_tarball_tmpl = 'nvhpc_2025_%%(version_major)s%%(version_minor)s_Linux_%s_cuda_multi.tar.gz'
source_urls = ['https://developer.download.nvidia.com/hpc-sdk/%(version)s/']
sources = [local_tarball_tmpl % '%(arch)s']
checksums = [
    {
        local_tarball_tmpl % 'aarch64':
            'e469793534121cd4fd71fb807e482aa6522f009093f4848ceb2f7acb5d3f63a8',
        local_tarball_tmpl % 'x86_64':
            '793521410a1937ecd2e031c3e10842dffc001fdac6658806348c3caf51f8a9f2'
    }
]

builddependencies = [
    ('binutils', '2.40'),
]

local_gccver = '13.2.0'
dependencies = [
    ('CUDA', '12.4.0', '', (SYSTEM)),
    # This is necessary to avoid cases where just libnuma.so.1 is present in the system and -lnuma fails
    ('numactl', '2.0.16', '', ('GCCcore', local_gccver)),
]

# nvidia-compilers (NVHPC) needs CUDA to work. This easyconfig uses CUDA bundled in NVHPC
# Specify default CUDA version that should be used by nvidia-compilers (NVHPC),
# it should match one of the CUDA versions that are included with this version of NVHPC
# (see install_components/Linux_x86_64/*/cuda/)
# default_cuda_version = '12.9'

# (optional) Define default CUDA Compute Capability used by all easyconfigs in this toolchain
# cuda_compute_capabilities = ['5.2', '6.0', '7.0', '7.5', '8.0', '8.6', '9.0']

# this bundle serves as a compiler-only toolchain, so it should be marked as compiler (important for HMNS)
moduleclass = 'compiler'

skip_mod_files_sanity_check = True
