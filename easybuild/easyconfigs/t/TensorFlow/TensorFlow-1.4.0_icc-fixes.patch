fix issues to get TensorFlow to compile with Intel compilers
* disable use of -Werror
* enable use of -DSQLITE_DISABLE_INTRINSIC for SQLite build
* fix syntax for template function calls;
  generated changes via Perl regex commands, see also https://github.com/tensorflow/tensorflow/issues/9496)
author: Kenneth Hoste (HPC-UGent)
--- tensorflow-1.4.0/third_party/boringssl/add_boringssl_s390x.patch.orig	2017-11-09 18:39:24.388501343 +0100
+++ tensorflow-1.4.0/third_party/boringssl/add_boringssl_s390x.patch	2017-11-09 18:39:30.478561428 +0100
@@ -68,7 +68,7 @@
 +
 +        # This list of warnings should match those in the top-level CMakeLists.txt.
 +        "-Wall",
-+        "-Werror",
++        #"-Werror",
 +        "-Wformat=2",
 +        "-Wsign-compare",
 +        "-Wmissing-field-initializers",
--- tensorflow-1.4.0/third_party/sqlite.BUILD.orig	2017-11-27 13:14:30.724041380 +0100
+++ tensorflow-1.4.0/third_party/sqlite.BUILD	2017-11-27 13:15:44.064700493 +0100
@@ -10,6 +10,7 @@
     name = "sqlite",
     srcs = ["sqlite3.c"],
     hdrs = ["sqlite3.h"],
+    copts = ['-DSQLITE_DISABLE_INTRINSIC'],
     includes = ["."],
     linkopts = ["-lm"],
     visibility = ["//visibility:public"],
diff --git a/tensorflow/contrib/batching/kernels/batch_kernels.cc b/tensorflow/contrib/batching/kernels/batch_kernels.cc
index 3b7c538fc..a5ee44994 100644
--- a/tensorflow/contrib/batching/kernels/batch_kernels.cc
+++ b/tensorflow/contrib/batching/kernels/batch_kernels.cc
@@ -69,7 +69,7 @@ Status Concat(OpKernelContext* context, const gtl::ArraySlice<Tensor>& inputs,
     }
     if (input.NumElements() > 0) {
       inputs_flat.emplace_back(new typename TTypes<T, 2>::ConstMatrix(
-          input.shaped<T, 2>({1, input.NumElements()})));
+          input.template shaped<T, 2>({1, input.NumElements()})));
     }
     output_dim0 += input.dim_size(0);
   }
@@ -146,7 +146,7 @@ Status SplitCPU(OpKernelContext* context, const Tensor& input,
     suffix_dim_size *= input.shape().dim_size(i);
   }
   auto input_reshaped =
-      input.shaped<T, 3>({1, input.shape().dim_size(0), suffix_dim_size});
+      input.template shaped<T, 3>({1, input.shape().dim_size(0), suffix_dim_size});
 
   int64 position = 0;
   for (const int64 size : sizes) {
@@ -155,7 +155,7 @@ Status SplitCPU(OpKernelContext* context, const Tensor& input,
     Tensor output;
     TF_RETURN_IF_ERROR(
         context->allocate_temp(input.dtype(), output_shape, &output));
-    auto output_shaped = output.shaped<T, 3>({1, size, suffix_dim_size});
+    auto output_shaped = output.template shaped<T, 3>({1, size, suffix_dim_size});
 
     Eigen::DSizes<Eigen::DenseIndex, 3> slice_indices{0, position, 0};
     Eigen::DSizes<Eigen::DenseIndex, 3> slice_sizes{1, size, suffix_dim_size};
@@ -627,7 +627,7 @@ class UnbatchResource : public ResourceBase {
     std::vector<Tensor> split_inputs;
     if (nonempty_input) {
       auto batch_indices =
-          batch_index_t.shaped<int64, 2>({batch_index_t.dim_size(0), 3});
+          batch_index_t.template shaped<int64, 2>({batch_index_t.dim_size(0), 3});
       for (int i = 0; i < batch_index_t.dim_size(0); ++i) {
         sizes.push_back(batch_indices(i, 2) - batch_indices(i, 1));
         batch_keys.push_back(batch_indices(i, 0));
@@ -823,7 +823,7 @@ class UnbatchGradResource : public ResourceBase {
       EXCLUSIVE_LOCKS_REQUIRED(mu_) {
     const Tensor& batch_index_t = context->input(1);
     auto batch_index =
-        batch_index_t.shaped<int64, 2>({batch_index_t.dim_size(0), 3});
+        batch_index_t.template shaped<int64, 2>({batch_index_t.dim_size(0), 3});
     std::vector<Tensor> tensors;
     for (int i = 0; i < batch_index_t.dim_size(0); ++i) {
       auto available_it = available_tensors_.find(batch_index(i, 0));
@@ -873,7 +873,7 @@ class UnbatchGradResource : public ResourceBase {
       }
       std::unordered_set<int64> missing_tensors;
       const auto batch_index =
-          batch_index_t.shaped<int64, 2>({batch_index_t.dim_size(0), 3});
+          batch_index_t.template shaped<int64, 2>({batch_index_t.dim_size(0), 3});
       for (int i = 0; i < batch_index_t.dim_size(0); ++i) {
         const int64 batch_key = batch_index(i, 0);
         if (available_tensors_.find(batch_key) == available_tensors_.end()) {
diff --git a/tensorflow/contrib/factorization/kernels/wals_solver_ops.cc b/tensorflow/contrib/factorization/kernels/wals_solver_ops.cc
index bb9b83588..0e1c6270b 100644
--- a/tensorflow/contrib/factorization/kernels/wals_solver_ops.cc
+++ b/tensorflow/contrib/factorization/kernels/wals_solver_ops.cc
@@ -116,7 +116,7 @@ class WALSComputePartialLhsAndRhsOp : public OpKernel {
                    context->allocate_output(
                        0, TensorShape({block_size, factor_dim, factor_dim}),
                        &output_lhs_tensor));
-    auto output_lhs_t = output_lhs_tensor->tensor<float, 3>();
+    auto output_lhs_t = output_lhs_tensor->template tensor<float, 3>();
     output_lhs_t.setZero();
     Tensor* output_rhs_tensor;
     OP_REQUIRES_OK(context, context->allocate_output(
diff --git a/tensorflow/contrib/ffmpeg/decode_audio_op.cc b/tensorflow/contrib/ffmpeg/decode_audio_op.cc
index 4b1c8a337..7703ef13c 100644
--- a/tensorflow/contrib/ffmpeg/decode_audio_op.cc
+++ b/tensorflow/contrib/ffmpeg/decode_audio_op.cc
@@ -105,7 +105,7 @@ void Decode(OpKernelContext* context,
   OP_REQUIRES_OK(context,
                  context->allocate_output(
                      0, TensorShape({frame_count, channel_count}), &output));
-  auto matrix = output->tensor<float, 2>();
+  auto matrix = output->template tensor<float, 2>();
   for (int32 frame = 0; frame < frame_count; ++frame) {
     for (int32 channel = 0; channel < channel_count; ++channel) {
       matrix(frame, channel) = output_samples[frame * channel_count + channel];
diff --git a/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc b/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc
index 256f20086..09d40fbf4 100644
--- a/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc
+++ b/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc
@@ -268,8 +268,8 @@ Status TransformNHWCToNCHW(OpKernelContext* ctx, const Tensor& nhwc_tensor,
     TF_RETURN_IF_ERROR(ctx->allocate_temp(DataTypeToEnum<T>::value, nchw_shape,
                                           transformed_tensor));
     functor::NHWCToNCHW<GPUDevice, T, NDIMS>()(
-        ctx->eigen_device<GPUDevice>(), nhwc_tensor.tensor<T, NDIMS>(),
-        transformed_tensor->tensor<T, NDIMS>());
+        ctx->eigen_device<GPUDevice>(), nhwc_tensor.template tensor<T, NDIMS>(),
+        transformed_tensor->template tensor<T, NDIMS>());
   } else {
     // If depth <= 1, then just reshape.
     CHECK(transformed_tensor->CopyFrom(nhwc_tensor, nchw_shape));
@@ -446,8 +446,8 @@ void LaunchFusedConv2DBiasActivationOp<GPUDevice, T, BiasType, ScaleType>::
                                 FORMAT_OIHW, filter_param.shape(), FORMAT_HWIO),
                             &maybe_transformed_filter));
     functor::TransformFilter<GPUDevice, T, int, 4>()(
-        ctx->eigen_device<GPUDevice>(), To32Bit(filter_param.tensor<T, 4>()),
-        To32Bit(maybe_transformed_filter.tensor<T, 4>()));
+        ctx->eigen_device<GPUDevice>(), To32Bit(filter_param.template tensor<T, 4>()),
+        To32Bit(maybe_transformed_filter.template tensor<T, 4>()));
     filter = &maybe_transformed_filter;
   }
 
@@ -564,8 +564,8 @@ void LaunchFusedConv2DBiasActivationOp<GPUDevice, T, BiasType, ScaleType>::
   if (!is_int8x4 && (data_format == FORMAT_NHWC) && (output_depth > 1)) {
     functor::NCHWToNHWC<GPUDevice, T, 4>()(
         ctx->eigen_device<GPUDevice>(),
-        const_cast<const Tensor*>(output)->tensor<T, 4>(),
-        output_param->tensor<T, 4>());
+        const_cast<const Tensor*>(output)->template tensor<T, 4>(),
+        output_param->template tensor<T, 4>());
   }
 }
 
diff --git a/tensorflow/contrib/image/kernels/bipartite_match_op.cc b/tensorflow/contrib/image/kernels/bipartite_match_op.cc
index 7d207c388..152b98754 100644
--- a/tensorflow/contrib/image/kernels/bipartite_match_op.cc
+++ b/tensorflow/contrib/image/kernels/bipartite_match_op.cc
@@ -86,7 +86,7 @@ class BipartiteMatchOp : public OpKernel {
                                             &column_to_row_match_indices));
 
     typename TTypes<float, 2>::ConstTensor distance_mat =
-        input_distance_mat.shaped<float, 2>(
+        input_distance_mat.template shaped<float, 2>(
             {num_input_rows, num_input_columns});
 
     // Greedy bi-partite matching.
diff --git a/tensorflow/contrib/image/kernels/image_ops.cc b/tensorflow/contrib/image/kernels/image_ops.cc
index 6adf837ca..e03ddd85d 100644
--- a/tensorflow/contrib/image/kernels/image_ops.cc
+++ b/tensorflow/contrib/image/kernels/image_ops.cc
@@ -79,11 +79,11 @@ class ImageProjectiveTransform : public OpKernel {
                           ProjectiveGenerator<Device, T>::kNumParameters),
                 errors::InvalidArgument(
                     "Input transform should be num_images x 8 or 1 x 8"));
-    auto images = images_t.tensor<T, 4>();
+    auto images = images_t.template tensor<T, 4>();
     auto transform = transform_t.matrix<float>();
     Tensor* output_t;
     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, images_t.shape(), &output_t));
-    auto output = output_t->tensor<T, 4>();
+    auto output = output_t->template tensor<T, 4>();
     (FillProjectiveTransform<Device, T>(interpolation_))(
         ctx->eigen_device<Device>(), &output, images, transform);
   }
diff --git a/tensorflow/contrib/pi_examples/camera/camera.cc b/tensorflow/contrib/pi_examples/camera/camera.cc
index cb2066166..c2ca7e8a8 100644
--- a/tensorflow/contrib/pi_examples/camera/camera.cc
+++ b/tensorflow/contrib/pi_examples/camera/camera.cc
@@ -346,7 +346,7 @@ Status TensorFromFrame(uint8_t* image_data, int image_width, int image_height,
       tensorflow::DT_FLOAT,
       tensorflow::TensorShape(
           {1, wanted_height, wanted_width, wanted_channels}));
-  auto image_tensor_mapped = image_tensor.tensor<float, 4>();
+  auto image_tensor_mapped = image_tensor.template tensor<float, 4>();
   tensorflow::uint8* in = image_data;
   float* out = image_tensor_mapped.data();
   const size_t image_rowlen = image_width * image_channels;
diff --git a/tensorflow/contrib/pi_examples/label_image/label_image.cc b/tensorflow/contrib/pi_examples/label_image/label_image.cc
index 7817cd0c6..3259061d8 100644
--- a/tensorflow/contrib/pi_examples/label_image/label_image.cc
+++ b/tensorflow/contrib/pi_examples/label_image/label_image.cc
@@ -156,7 +156,7 @@ Status ReadTensorFromImageFile(string file_name, const int wanted_height,
   tensorflow::Tensor image_tensor(
       tensorflow::DT_FLOAT, tensorflow::TensorShape(
       {1, wanted_height, wanted_width, wanted_channels}));
-  auto image_tensor_mapped = image_tensor.tensor<float, 4>();
+  auto image_tensor_mapped = image_tensor.template tensor<float, 4>();
   tensorflow::uint8* in = image_data.data();
   float *out = image_tensor_mapped.data();
   const size_t image_rowlen = image_width * image_channels;
diff --git a/tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc b/tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc
index aab0f3f49..dbe113d39 100644
--- a/tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc
+++ b/tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc
@@ -77,10 +77,10 @@ class GatherTreeOp : public OpKernel {
             parent_ids.shape().DebugString()));
     Tensor* beams;
     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, step_ids_shape, &beams));
-    typename TTypes<T, 3>::ConstTensor step_ids_t = step_ids.tensor<T, 3>();
-    typename TTypes<T, 3>::ConstTensor parent_ids_t = parent_ids.tensor<T, 3>();
+    typename TTypes<T, 3>::ConstTensor step_ids_t = step_ids.template tensor<T, 3>();
+    typename TTypes<T, 3>::ConstTensor parent_ids_t = parent_ids.template tensor<T, 3>();
     typename TTypes<T>::ConstMatrix seq_len_t = sequence_length.matrix<T>();
-    typename TTypes<T, 3>::Tensor beams_t = beams->tensor<T, 3>();
+    typename TTypes<T, 3>::Tensor beams_t = beams->template tensor<T, 3>();
     functor::GatherTree<Device, T>()(ctx, device, step_ids_t, parent_ids_t,
                                      seq_len_t, beams_t);
   }
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/hard_routing_function_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/hard_routing_function_op.cc
index 76cfb4c9c..a5469a1bb 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/hard_routing_function_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/hard_routing_function_op.cc
@@ -129,12 +129,12 @@ class HardRoutingFunction : public OpKernel {
                    context->allocate_output(1, output_path_shape,
                                             &output_path));
 
-    auto out_probability = output_probability->tensor<float, 2>();
-    auto out_path = output_path->tensor<int32, 2>();
+    auto out_probability = output_probability->template tensor<float, 2>();
+    auto out_path = output_path->template tensor<int32, 2>();
 
-    const auto data = input_data.tensor<float, 2>();
-    const auto tree_parameters = tree_parameters_tensor.tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
+    const auto data = input_data.template tensor<float, 2>();
+    const auto tree_parameters = tree_parameters_tensor.template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
 
     // Deterministically traverse the tree to a leaf.
     for (int i = 0; i < num_data; i++) {
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_gradient_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_gradient_op.cc
index 28f50f1a3..c8b5da78a 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_gradient_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_gradient_op.cc
@@ -137,14 +137,14 @@ class KFeatureGradient : public OpKernel {
     tensorforest::Initialize(*out_data, 0.0f);
 
     // Compute output.
-    const auto input_data = input_data_tensor.tensor<float, 2>();
-    const auto tree_parameters = tree_parameters_tensor.tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
-    const auto routes = routing_tensor.tensor<float, 2>();
-
-    auto routes_grad = out_routes->tensor<float, 2>();
-    auto data_grad = out_data->tensor<float, 2>();
-    auto weights_grad = out_weights->tensor<float, 3>();
+    const auto input_data = input_data_tensor.template tensor<float, 2>();
+    const auto tree_parameters = tree_parameters_tensor.template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
+    const auto routes = routing_tensor.template tensor<float, 2>();
+
+    auto routes_grad = out_routes->template tensor<float, 2>();
+    auto data_grad = out_data->template tensor<float, 2>();
+    auto weights_grad = out_weights->template tensor<float, 3>();
 
     std::vector<int32> feature_set;
     for (int i = 0; i < num_data; i++) {
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_routing_function_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_routing_function_op.cc
index 9bc42eb61..54602d208 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_routing_function_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/k_feature_routing_function_op.cc
@@ -130,8 +130,8 @@ class KFeatureRoutingFunction : public OpKernel {
                    context->allocate_output(0, output_shape,
                                             &output_probabilities));
 
-    auto out_probs = output_probabilities->tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
+    auto out_probs = output_probabilities->template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
 
     // Iteratively compute the probability of reaching each leaf.
     std::vector<int32> feature_set;
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_function_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_function_op.cc
index 4027e732b..7959d4754 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_function_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_function_op.cc
@@ -112,8 +112,8 @@ class RoutingFunction : public OpKernel {
                    context->allocate_output(0, output_shape,
                                             &output_probabilities));
 
-    auto out_probs = output_probabilities->tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
+    auto out_probs = output_probabilities->template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
 
     // Iteratively compute the probability of reaching each leaf.
     for (int i = 0; i < num_data; i++) {
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_gradient_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_gradient_op.cc
index 5aca54d13..37464bc74 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_gradient_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/routing_gradient_op.cc
@@ -108,9 +108,9 @@ class RoutingGradient : public OpKernel {
 
     OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));
 
-    auto out = output->tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
-    const auto routes = routing_tensor.tensor<float, 2>();
+    auto out = output->template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
+    const auto routes = routing_tensor.template tensor<float, 2>();
 
     // A derivation of the gradient can be found at go/routingderivation.
     for (int i = 0; i < num_data; i++) {
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_function_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_function_op.cc
index 09b83e2af..feeb9ab70 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_function_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_function_op.cc
@@ -143,9 +143,9 @@ class StochasticHardRoutingFunction : public OpKernel {
                    context->allocate_output(1, output_path_shape,
                                             &output_path));
 
-    auto out_probability = output_probability->tensor<float, 2>();
-    auto out_path = output_path->tensor<int32, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
+    auto out_probability = output_probability->template tensor<float, 2>();
+    auto out_path = output_path->template tensor<int32, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
 
     // Stochastically traverse the tree to a leaf.
 
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_gradient_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_gradient_op.cc
index 0b5afe464..b35738890 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_gradient_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/stochastic_hard_routing_gradient_op.cc
@@ -163,16 +163,16 @@ class StochasticHardRoutingGradient : public OpKernel {
     tensorforest::Initialize(*output_parameters, 0.0);
     tensorforest::Initialize(*output_bias, 0.0);
 
-    auto out_routing = output_routing->tensor<float, 2>();
-    auto out_data = output_data->tensor<float, 2>();
-    auto out_parameters = output_parameters->tensor<float, 3>();
-    auto out_bias = output_bias->tensor<float, 1>();
-
-    const auto data = input_data.tensor<float, 2>();
-    const auto tree_parameters = tree_parameters_tensor.tensor<float, 2>();
-    const auto tree_biases = tree_biases_tensor.tensor<float, 1>();
-    const auto path_probability = path_probability_tensor.tensor<float, 2>();
-    const auto path = path_tensor.tensor<int32, 2>();
+    auto out_routing = output_routing->template tensor<float, 2>();
+    auto out_data = output_data->template tensor<float, 2>();
+    auto out_parameters = output_parameters->template tensor<float, 3>();
+    auto out_bias = output_bias->template tensor<float, 1>();
+
+    const auto data = input_data.template tensor<float, 2>();
+    const auto tree_parameters = tree_parameters_tensor.template tensor<float, 2>();
+    const auto tree_biases = tree_biases_tensor.template tensor<float, 1>();
+    const auto path_probability = path_probability_tensor.template tensor<float, 2>();
+    const auto path = path_tensor.template tensor<int32, 2>();
 
     for (int i = 0; i < num_data; i++) {
       const Tensor point = input_data.Slice(i, i + 1);
diff --git a/tensorflow/contrib/tensor_forest/hybrid/core/ops/unpack_path_op.cc b/tensorflow/contrib/tensor_forest/hybrid/core/ops/unpack_path_op.cc
index 9d5e1400a..42c91f377 100644
--- a/tensorflow/contrib/tensor_forest/hybrid/core/ops/unpack_path_op.cc
+++ b/tensorflow/contrib/tensor_forest/hybrid/core/ops/unpack_path_op.cc
@@ -101,10 +101,10 @@ class UnpackPath : public OpKernel {
     tensorforest::Initialize(*output, 0.0f);
     VLOG(1) << "unpack after init";
 
-    auto out = output->tensor<float, 2>();
+    auto out = output->template tensor<float, 2>();
 
-    const auto path = path_tensor.tensor<int32, 2>();
-    const auto path_values = path_values_tensor.tensor<float, 2>();
+    const auto path = path_tensor.template tensor<int32, 2>();
+    const auto path_values = path_values_tensor.template tensor<float, 2>();
 
     for (int i = 0; i < num_data; i++) {
       for (int j = 0; j < tree_depth; j++) {
diff --git a/tensorflow/contrib/tensor_forest/kernels/model_ops.cc b/tensorflow/contrib/tensor_forest/kernels/model_ops.cc
index b9aad36f3..558d155a0 100644
--- a/tensorflow/contrib/tensor_forest/kernels/model_ops.cc
+++ b/tensorflow/contrib/tensor_forest/kernels/model_ops.cc
@@ -197,7 +197,7 @@ class TreePredictionsV4Op : public OpKernel {
     output_shape.AddDim(num_outputs);
     OP_REQUIRES_OK(context, context->allocate_output(0, output_shape,
                                                      &output_predictions));
-    TTypes<float, 2>::Tensor out = output_predictions->tensor<float, 2>();
+    TTypes<float, 2>::Tensor out = output_predictions->template tensor<float, 2>();
 
     std::vector<TreePath> tree_paths(
         param_proto_.inference_tree_paths() ? num_data : 0);
@@ -297,7 +297,7 @@ class TraverseTreeV4Op : public OpKernel {
     OP_REQUIRES_OK(context, context->allocate_output(0, output_shape,
                                                      &output_predictions));
 
-    auto leaf_ids = output_predictions->tensor<int32, 1>();
+    auto leaf_ids = output_predictions->template tensor<int32, 1>();
 
     auto set_leaf_ids = [&leaf_ids](int32 i, int32 id) { leaf_ids(i) = id; };
 
diff --git a/tensorflow/contrib/tensor_forest/kernels/scatter_add_ndim_op.cc b/tensorflow/contrib/tensor_forest/kernels/scatter_add_ndim_op.cc
index dd2a98b08..713e8f00f 100644
--- a/tensorflow/contrib/tensor_forest/kernels/scatter_add_ndim_op.cc
+++ b/tensorflow/contrib/tensor_forest/kernels/scatter_add_ndim_op.cc
@@ -65,7 +65,7 @@ class ScatterAddNdim : public OpKernel {
 
     auto input = input_tensor.flat<float>();
 
-    const auto indices = indices_tensor.tensor<int32, 2>();
+    const auto indices = indices_tensor.template tensor<int32, 2>();
     const auto deltas = deltas_tensor.unaligned_flat<float>();
 
     const int32 num_dims = static_cast<int32>(
diff --git a/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc b/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc
index 94e12cea5..a41538e68 100644
--- a/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc
+++ b/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc
@@ -177,8 +177,8 @@ void GetTwoBestRegression(const Tensor& total_sums, const Tensor& total_squares,
   // unhelpful compiler errors when trying something that seems sane.  This
   // helps us do a simple thing like access the first element (the counts)
   // of these tensors so we can calculate expected value in Variance().
-  const auto splits_count_accessor = split_sums.tensor<float, 3>();
-  const auto totals_count_accessor = total_sums.tensor<float, 2>();
+  const auto splits_count_accessor = split_sums.template tensor<float, 3>();
+  const auto totals_count_accessor = total_sums.template tensor<float, 2>();
 
   Eigen::array<int, 1> bcast;
   bcast[0] = num_splits;
@@ -239,8 +239,8 @@ int MakeBootstrapWeights(const Tensor& total_counts, const Tensor& split_counts,
   const int32 num_classes =
       static_cast<int32>(split_counts.shape().dim_size(2)) - 1;
 
-  auto tc = total_counts.tensor<float, 2>();
-  auto lc = split_counts.tensor<float, 3>();
+  auto tc = total_counts.template tensor<float, 2>();
+  auto lc = split_counts.template tensor<float, 3>();
 
   int n = tc(accumulator, 0);
 
@@ -350,8 +350,8 @@ double DirichletCovarianceTrace(const Tensor& total_counts,
   const int32 num_classes =
       static_cast<int32>(split_counts.shape().dim_size(2)) - 1;
 
-  auto tc = total_counts.tensor<float, 2>();
-  auto lc = split_counts.tensor<float, 3>();
+  auto tc = total_counts.template tensor<float, 2>();
+  auto lc = split_counts.template tensor<float, 3>();
 
   double leftc = 0.0;
   double leftc2 = 0.0;
@@ -378,8 +378,8 @@ void getDirichletMean(const Tensor& total_counts, const Tensor& split_counts,
       static_cast<int32>(split_counts.shape().dim_size(2)) - 1;
 
   mu->resize(num_classes * 2);
-  auto tc = total_counts.tensor<float, 2>();
-  auto lc = split_counts.tensor<float, 3>();
+  auto tc = total_counts.template tensor<float, 2>();
+  auto lc = split_counts.template tensor<float, 3>();
 
   double total = tc(accumulator, 0);
 
diff --git a/tensorflow/contrib/tensor_forest/kernels/tree_utils_test.cc b/tensorflow/contrib/tensor_forest/kernels/tree_utils_test.cc
index 7485a695d..6ff0ccfb7 100644
--- a/tensorflow/contrib/tensor_forest/kernels/tree_utils_test.cc
+++ b/tensorflow/contrib/tensor_forest/kernels/tree_utils_test.cc
@@ -56,7 +56,7 @@ TEST(TestInitialize, Basic) {
 
   Initialize<float>(t, 42.0);
 
-  const auto vals = t.tensor<float, 2>();
+  const auto vals = t.template tensor<float, 2>();
   EXPECT_FLOAT_EQ(vals(0, 0), 42);
   EXPECT_FLOAT_EQ(vals(1, 1), 42);
   EXPECT_FLOAT_EQ(vals(3, 0), 42);
diff --git a/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc b/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc
index 14cb19d36..aa2aeed27 100644
--- a/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc
+++ b/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc
@@ -108,14 +108,14 @@ void TensorDataSet::set_input_tensors(const Tensor& dense,
                                       const Tensor& sparse_values,
                                       const Tensor& sparse_shape) {
   if (dense.shape().dims() == 2) {
-    dense_data_.reset(new DenseStorageType(dense.tensor<float, 2>()));
+    dense_data_.reset(new DenseStorageType(dense.template tensor<float, 2>()));
   }
   if (sparse_indices.shape().dims() == 2) {
     sparse_indices_.reset(new SparseIndicesStorageType(
-        sparse_indices.tensor<int64, 2>()));
+        sparse_indices.template tensor<int64, 2>()));
     sparse_values_.reset(new SparseValuesStorageType(
-        sparse_values.tensor<float, 1>()));
-    sparse_batch_size_ = sparse_shape.tensor<int64, 1>()(0);
+        sparse_values.template tensor<float, 1>()));
+    sparse_batch_size_ = sparse_shape.template tensor<int64, 1>()(0);
   }
   original_dense_tensor_ = dense;
 }
diff --git a/tensorflow/core/framework/tensor.h b/tensorflow/core/framework/tensor.h
index 3a7df6a47..3bfe4f531 100644
--- a/tensorflow/core/framework/tensor.h
+++ b/tensorflow/core/framework/tensor.h
@@ -229,9 +229,9 @@ class Tensor {
   ///     typedef float T;
   ///     Tensor my_mat(...built with Shape{rows: 3, cols: 5}...);
   ///     auto mat = my_mat.matrix<T>();    // 2D Eigen::Tensor, 3 x 5.
-  ///     auto mat = my_mat.tensor<T, 2>(); // 2D Eigen::Tensor, 3 x 5.
+  ///     auto mat = my_mat.template tensor<T, 2>(); // 2D Eigen::Tensor, 3 x 5.
   ///     auto vec = my_mat.vec<T>();       // CHECK fails as my_mat is 2D.
-  ///     auto vec = my_mat.tensor<T, 3>(); // CHECK fails as my_mat is 2D.
+  ///     auto vec = my_mat.template tensor<T, 3>(); // CHECK fails as my_mat is 2D.
   ///     auto mat = my_mat.matrix<int32>();// CHECK fails as type mismatch.
   ///
   /// ```
@@ -286,11 +286,11 @@ class Tensor {
   ///     // 2D Eigen::Tensor 12 x 5:
   ///     auto inner = my_ten.flat_inner_dims<T>();
   ///     // 2D Eigen::Tensor 4 x 15:
-  ///     auto outer = my_ten.shaped<T, 2>({4, 15});
+  ///     auto outer = my_ten.template shaped<T, 2>({4, 15});
   ///     // CHECK fails, bad num elements:
-  ///     auto outer = my_ten.shaped<T, 2>({4, 8});
+  ///     auto outer = my_ten.template shaped<T, 2>({4, 8});
   ///     // 3D Eigen::Tensor 6 x 5 x 2:
-  ///     auto weird = my_ten.shaped<T, 3>({6, 5, 2});
+  ///     auto weird = my_ten.template shaped<T, 3>({6, 5, 2});
   ///     // CHECK fails, type mismatch:
   ///     auto bad   = my_ten.flat<int32>();
   ///
diff --git a/tensorflow/core/framework/tensor_test.cc b/tensorflow/core/framework/tensor_test.cc
index 47ff29fbe..a35672486 100644
--- a/tensorflow/core/framework/tensor_test.cc
+++ b/tensorflow/core/framework/tensor_test.cc
@@ -324,7 +324,7 @@ class TensorReshapeTest : public ::testing::Test {
     EXPECT_TRUE(t.shape().IsSameSize(TensorShape({2, 3, 4, 5})));
     EXPECT_TRUE(zero_t.shape().IsSameSize(TensorShape({3, 0, 2, 0, 5})));
 
-    auto tensor = t.tensor<float, 4>();
+    auto tensor = t.template tensor<float, 4>();
     EXPECT_EQ(2, tensor.dimension(0));
     EXPECT_EQ(3, tensor.dimension(1));
     EXPECT_EQ(4, tensor.dimension(2));
@@ -339,20 +339,20 @@ class TensorReshapeTest : public ::testing::Test {
 TEST_F(TensorReshapeTest, Reshape) {
   LOG(INFO) << "shaped";
   {
-    auto shaped = t.shaped<float, 1>({120});
+    auto shaped = t.template shaped<float, 1>({120});
     EXPECT_EQ(120, shaped.dimension(0));
     EXPECT_EQ(shaped(0), 0.01f);
     EXPECT_EQ(shaped(119), 0.02f);
   }
   {
-    auto shaped = t.shaped<float, 2>({6, 20});
+    auto shaped = t.template shaped<float, 2>({6, 20});
     EXPECT_EQ(6, shaped.dimension(0));
     EXPECT_EQ(20, shaped.dimension(1));
     EXPECT_EQ(shaped(0, 0), 0.01f);
     EXPECT_EQ(shaped(5, 19), 0.02f);
   }
   {
-    auto shaped = t.shaped<float, 3>({6, 4, 5});
+    auto shaped = t.template shaped<float, 3>({6, 4, 5});
     EXPECT_EQ(6, shaped.dimension(0));
     EXPECT_EQ(4, shaped.dimension(1));
     EXPECT_EQ(5, shaped.dimension(2));
@@ -360,7 +360,7 @@ TEST_F(TensorReshapeTest, Reshape) {
     EXPECT_EQ(shaped(5, 3, 4), 0.02f);
   }
   {
-    auto shaped = t.shaped<float, 4>({2, 3, 4, 5});
+    auto shaped = t.template shaped<float, 4>({2, 3, 4, 5});
     EXPECT_EQ(2, shaped.dimension(0));
     EXPECT_EQ(3, shaped.dimension(1));
     EXPECT_EQ(4, shaped.dimension(2));
@@ -609,9 +609,9 @@ TEST(ReinterpretLastDimension, Reinterpret_NCHW_VECT_C_as_NCHW) {
   LOG(INFO) << "reinterpret_last_dimension";
   {
     Tensor t_nchw_vect_c(DT_QINT8, TensorShape({2, 3, 5, 7, 4}));
-    auto nchw_vect_c = t_nchw_vect_c.tensor<qint8, 5>();
+    auto nchw_vect_c = t_nchw_vect_c.template tensor<qint8, 5>();
     Tensor t_expected_nchw(DT_INT32, TensorShape({2, 3, 5, 7}));
-    auto expected_nchw = t_expected_nchw.tensor<int32, 4>();
+    auto expected_nchw = t_expected_nchw.template tensor<int32, 4>();
     int8 val = 0;
     for (int n = 0; n < t_nchw_vect_c.shape().dim_size(0); ++n) {
       for (int c = 0; c < t_nchw_vect_c.shape().dim_size(1); ++c) {
@@ -724,9 +724,9 @@ TEST(Tensor_Float, Reshape_And_Slice_Assignment) {
   EXPECT_TRUE(t.shape().IsSameSize(TensorShape({10, 4, 3, 2})));
 
   // Get the N dimensional tensor (N==4 here)
-  auto e_t = t.tensor<float, 4>();
+  auto e_t = t.template tensor<float, 4>();
   // Reshape to view it as a two-dimensional tensor
-  auto e_2d = t.shaped<float, 2>({10, 4 * 3 * 2});
+  auto e_2d = t.template shaped<float, 2>({10, 4 * 3 * 2});
   for (int i = 0; i < 10; i++) {
     // Assign a 1 x 4*3*2 matrix (really vector) to a slice of size
     // 1 x 4*3*2 in e_t.
@@ -1041,8 +1041,8 @@ TEST(Tensor, Slice_Basic) {
     // A simple slice along dim0.
     Tensor y = x.Slice(4, 8);
     EXPECT_TRUE(y.shape().IsSameSize(TensorShape({4, 4, 34})));
-    auto tx = x.tensor<float, 3>();
-    auto ty = y.tensor<float, 3>();
+    auto tx = x.template tensor<float, 3>();
+    auto ty = y.template tensor<float, 3>();
     for (int i = 0; i < 4; ++i) {
       for (int j = 0; j < 4; ++j) {
         for (int k = 0; k < 34; ++k) {
@@ -1059,7 +1059,7 @@ TEST(Tensor, Slice_Basic) {
 
     // A slice of a slice.
     auto z = x.Slice(4, 8).Slice(2, 3);
-    auto tz = z.tensor<float, 3>();
+    auto tz = z.template tensor<float, 3>();
     EXPECT_EQ(1, z.dim_size(0));
     for (int j = 0; j < 4; ++j) {
       for (int k = 0; k < 34; ++k) {
@@ -1072,7 +1072,7 @@ TEST(Tensor, Slice_Basic) {
   }
   {
     EXPECT_EQ(1, saved.dim_size(0));
-    auto tsaved = saved.tensor<float, 3>();
+    auto tsaved = saved.template tensor<float, 3>();
     for (int j = 0; j < 4; ++j) {
       for (int k = 0; k < 34; ++k) {
         EXPECT_EQ(tsaved(0, j, k), 6.0);
diff --git a/tensorflow/core/kernels/adjust_contrast_op.cc b/tensorflow/core/kernels/adjust_contrast_op.cc
index 37976f718..58a4cabfa 100644
--- a/tensorflow/core/kernels/adjust_contrast_op.cc
+++ b/tensorflow/core/kernels/adjust_contrast_op.cc
@@ -78,9 +78,9 @@ class AdjustContrastOp : public OpKernel {
       const int64 batch = input.NumElements() / (height * width * channels);
       const int64 shape[4] = {batch, height, width, channels};
       functor::AdjustContrast<Device, T>()(
-          context->eigen_device<Device>(), input.shaped<T, 4>(shape),
+          context->eigen_device<Device>(), input.template shaped<T, 4>(shape),
           factor.scalar<float>(), min_value.scalar<float>(),
-          max_value.scalar<float>(), mean_values.shaped<float, 4>(shape),
+          max_value.scalar<float>(), mean_values.template shaped<float, 4>(shape),
           output->shaped<float, 4>(shape));
     }
   }
@@ -214,7 +214,7 @@ class AdjustContrastOpv2<CPUDevice> : public AdjustContrastOpV2Base {
                                 TensorShape({batch, channels}), &mean_values));
     // TODO(zhengxq): for multiple batches, shard them into different batches.
     auto input_data = input->shaped<float, 3>({batch, image_size, channels});
-    auto mean_data = mean_values.tensor<float, 2>();
+    auto mean_data = mean_values.template tensor<float, 2>();
     auto output_data = output->shaped<float, 3>({batch, image_size, channels});
 
     // Calculate the mean of the inputs.
diff --git a/tensorflow/core/kernels/argmax_op.cc b/tensorflow/core/kernels/argmax_op.cc
index 49cd997fe..791bffcb3 100644
--- a/tensorflow/core/kernels/argmax_op.cc
+++ b/tensorflow/core/kernels/argmax_op.cc
@@ -79,8 +79,8 @@ class ArgOp : public OpKernel {
 #define HANDLE_DIM(NDIM)                                        \
   case NDIM:                                                    \
     ArgFunctor::Reduce##NDIM(context->eigen_device<Device>(),   \
-                             input.tensor<T, NDIM>(), axis,     \
-                             output->tensor<Tout, NDIM - 1>()); \
+                             input.template tensor<T, NDIM>(), axis,     \
+                             output->template tensor<Tout, NDIM - 1>()); \
     break;
 
     switch (input_dims) {
diff --git a/tensorflow/core/kernels/attention_ops.cc b/tensorflow/core/kernels/attention_ops.cc
index cc8f122ca..26e529d48 100644
--- a/tensorflow/core/kernels/attention_ops.cc
+++ b/tensorflow/core/kernels/attention_ops.cc
@@ -58,8 +58,8 @@ class ExtractGlimpseOp : public OpKernel {
                     "input must be a vector of size 2 (height, width)",
                     window_size.shape().DebugString()));
 
-    const int64 output_height = window_size.tensor<int, 1>()(0);
-    const int64 output_width = window_size.tensor<int, 1>()(1);
+    const int64 output_height = window_size.template tensor<int, 1>()(0);
+    const int64 output_width = window_size.template tensor<int, 1>()(1);
     TensorShape output_shape = input_shape;
     output_shape.set_dim(1, output_height);
     output_shape.set_dim(2, output_width);
@@ -86,16 +86,16 @@ class ExtractGlimpseOp : public OpKernel {
     std::vector<Eigen::IndexPair<float> > offset_vec;
     offset_vec.reserve(batch_size);
     for (int i = 0; i < batch_size; ++i) {
-      float offset_y = offsets.tensor<float, 2>()(i, 0);
-      float offset_x = offsets.tensor<float, 2>()(i, 1);
+      float offset_y = offsets.template tensor<float, 2>()(i, 0);
+      float offset_x = offsets.template tensor<float, 2>()(i, 1);
       // Eigen::ExtractGlimpses expects offsets as (x,y), whereas the
       // calling TensorFlow operates with (y,x) as indices.
       offset_vec.push_back(Eigen::IndexPair<float>(offset_x, offset_y));
     }
 
-    output->tensor<float, 4>().swap_layout().device(
+    output->template tensor<float, 4>().swap_layout().device(
         context->eigen_cpu_device()) =
-        Eigen::ExtractGlimpses(input.tensor<float, 4>().swap_layout(),
+        Eigen::ExtractGlimpses(input.template tensor<float, 4>().swap_layout(),
                                output_width, output_height, offset_vec,
                                normalized_, centered_, uniform_noise_);
   }
diff --git a/tensorflow/core/kernels/avgpooling_op.cc b/tensorflow/core/kernels/avgpooling_op.cc
index af629d0de..114a93636 100644
--- a/tensorflow/core/kernels/avgpooling_op.cc
+++ b/tensorflow/core/kernels/avgpooling_op.cc
@@ -160,8 +160,8 @@ class AvgPoolingOp<GPUDevice, T> : public UnaryOp<T> {
                      context->allocate_output(0, output_shape, &output));
       Eigen::PaddingType pt = BrainPadding2EigenPadding(padding_);
       functor::SpatialAvgPooling<Device, T>()(
-          context->eigen_device<Device>(), output->tensor<T, 4>(),
-          tensor_in.tensor<T, 4>(), params.window_rows, params.window_cols,
+          context->eigen_device<Device>(), output->template tensor<T, 4>(),
+          tensor_in.template tensor<T, 4>(), params.window_rows, params.window_cols,
           params.row_stride, params.col_stride, pt);
     }
   }
diff --git a/tensorflow/core/kernels/batch_matmul_op_impl.h b/tensorflow/core/kernels/batch_matmul_op_impl.h
index 93c391831..e53718907 100644
--- a/tensorflow/core/kernels/batch_matmul_op_impl.h
+++ b/tensorflow/core/kernels/batch_matmul_op_impl.h
@@ -67,7 +67,7 @@ template <typename Scalar, bool IsComplex = true>
 struct ParallelMatMulKernel {
   static void Conjugate(const OpKernelContext* context, Tensor* out) {
     const Eigen::ThreadPoolDevice d = context->eigen_cpu_device();
-    auto z = out->tensor<Scalar, 3>();
+    auto z = out->template tensor<Scalar, 3>();
     z.device(d) = z.conjugate();
   }
 
@@ -75,9 +75,9 @@ struct ParallelMatMulKernel {
                   const Tensor in_y, bool adj_x, bool adj_y, Tensor* out,
                   int start, int limit) {
     static_assert(IsComplex, "Complex type expected.");
-    auto Tx = in_x.tensor<Scalar, 3>();
-    auto Ty = in_y.tensor<Scalar, 3>();
-    auto Tz = out->tensor<Scalar, 3>();
+    auto Tx = in_x.template tensor<Scalar, 3>();
+    auto Ty = in_y.template tensor<Scalar, 3>();
+    auto Tz = out->template tensor<Scalar, 3>();
     // We use the identities
     //   conj(a) * conj(b) = conj(a * b)
     //   conj(a) * b = conj(a * conj(b))
@@ -110,9 +110,9 @@ struct ParallelMatMulKernel<Scalar, false> {
   static void Run(const OpKernelContext* context, const Tensor& in_x,
                   const Tensor& in_y, bool adj_x, bool adj_y, Tensor* out,
                   int start, int limit) {
-    auto Tx = in_x.tensor<Scalar, 3>();
-    auto Ty = in_y.tensor<Scalar, 3>();
-    auto Tz = out->tensor<Scalar, 3>();
+    auto Tx = in_x.template tensor<Scalar, 3>();
+    auto Ty = in_y.template tensor<Scalar, 3>();
+    auto Tz = out->template tensor<Scalar, 3>();
     Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_pairs;
     contract_pairs[0] = ContractionDims(adj_x, adj_y);
     const Eigen::ThreadPoolDevice d = context->eigen_cpu_device();
@@ -410,9 +410,9 @@ struct ParallelMatMulKernelSYCL {
   static void Run(const OpKernelContext* context, const Tensor& in_x,
                   const Tensor& in_y, bool adj_x, bool adj_y, Tensor* out,
                   int start, int limit) {
-    auto Tx = in_x.tensor<Scalar, 3>();
-    auto Ty = in_y.tensor<Scalar, 3>();
-    auto Tz = out->tensor<Scalar, 3>();
+    auto Tx = in_x.template tensor<Scalar, 3>();
+    auto Ty = in_y.template tensor<Scalar, 3>();
+    auto Tz = out->template tensor<Scalar, 3>();
     Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_pairs;
     contract_pairs[0] = ContractionDims(adj_x, adj_y);
     auto d = context->eigen_sycl_device();
diff --git a/tensorflow/core/kernels/batch_norm_op.cc b/tensorflow/core/kernels/batch_norm_op.cc
index d3ed617f7..b959a6ce8 100644
--- a/tensorflow/core/kernels/batch_norm_op.cc
+++ b/tensorflow/core/kernels/batch_norm_op.cc
@@ -72,9 +72,9 @@ class BatchNormOp : public OpKernel {
                    context->allocate_output(0, input.shape(), &output));
 
     functor::BatchNorm<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(), mean.vec<T>(),
+        context->eigen_device<Device>(), input.template tensor<T, 4>(), mean.vec<T>(),
         var.vec<T>(), beta.vec<T>(), gamma.vec<T>(), variance_epsilon_,
-        scale_after_normalization_, output->tensor<T, 4>());
+        scale_after_normalization_, output->template tensor<T, 4>());
   }
 
  private:
@@ -148,9 +148,9 @@ class BatchNormGradOp : public OpKernel {
                                 TensorShape({input.dim_size(3)}), &scratch2));
 
     functor::BatchNormGrad<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(), mean.vec<T>(),
-        var.vec<T>(), gamma.vec<T>(), out_backprop.tensor<T, 4>(),
-        variance_epsilon_, scale_after_normalization_, dx->tensor<T, 4>(),
+        context->eigen_device<Device>(), input.template tensor<T, 4>(), mean.vec<T>(),
+        var.vec<T>(), gamma.vec<T>(), out_backprop.template tensor<T, 4>(),
+        variance_epsilon_, scale_after_normalization_, dx->template tensor<T, 4>(),
         dm->vec<T>(), dv->vec<T>(), db->vec<T>(), dg->vec<T>(),
         scratch1.vec<T>(), scratch2.vec<T>());
   }
diff --git a/tensorflow/core/kernels/batchtospace_op.cc b/tensorflow/core/kernels/batchtospace_op.cc
index 99b5d3daa..04e0d1737 100644
--- a/tensorflow/core/kernels/batchtospace_op.cc
+++ b/tensorflow/core/kernels/batchtospace_op.cc
@@ -190,7 +190,7 @@ static void BatchToSpaceOpCompute(OpKernelContext* context,
             output_tensor->shaped<T, NUM_BLOCK_DIMS + 2>(                 \
                 internal_output_shape.dim_sizes()),                       \
             internal_block_shape, internal_crops,                         \
-            orig_input_tensor.shaped<T, NUM_BLOCK_DIMS + 2>(              \
+            orig_input_tensor.template shaped<T, NUM_BLOCK_DIMS + 2>(              \
                 internal_input_shape.dim_sizes()))));                     \
   } break;                                                                \
     /**/
diff --git a/tensorflow/core/kernels/betainc_op.cc b/tensorflow/core/kernels/betainc_op.cc
index e1fab18d1..dd80332f1 100644
--- a/tensorflow/core/kernels/betainc_op.cc
+++ b/tensorflow/core/kernels/betainc_op.cc
@@ -91,9 +91,9 @@ class BetaincOp : public OpKernel {
 #define CASE(NDIM)                                                        \
   case NDIM: {                                                            \
     functor::Betainc<Device, T, NDIM> functor;                            \
-    auto a_value = a.shaped<T, NDIM>(a_shaper.x_reshape());               \
-    auto b_value = b.shaped<T, NDIM>(b_shaper.x_reshape());               \
-    auto x_value = x.shaped<T, NDIM>(x_shaper.x_reshape());               \
+    auto a_value = a.template shaped<T, NDIM>(a_shaper.x_reshape());               \
+    auto b_value = b.template shaped<T, NDIM>(b_shaper.x_reshape());               \
+    auto x_value = x.template shaped<T, NDIM>(x_shaper.x_reshape());               \
     functor.BCast(ctx->eigen_device<Device>(), a_value,                   \
                   BCast::ToIndexArray<NDIM>(a_shaper.x_bcast()), b_value, \
                   BCast::ToIndexArray<NDIM>(b_shaper.x_bcast()), x_value, \
diff --git a/tensorflow/core/kernels/bias_op.cc b/tensorflow/core/kernels/bias_op.cc
index 1a22bb3ce..9059c2e21 100644
--- a/tensorflow/core/kernels/bias_op.cc
+++ b/tensorflow/core/kernels/bias_op.cc
@@ -137,8 +137,8 @@ class BiasOp : public BinaryOp<T> {
       Eigen::DSizes<int32, 4> four_dims(1, channel, 1, 1);
       Eigen::DSizes<int32, 4> broad_cast_dims(batch, 1, height, width);
       const Device& d = context->eigen_device<Device>();
-      output->tensor<T, 4>().device(d) = input.tensor<T, 4>() +
-          bias.tensor<T, 1>().reshape(four_dims).broadcast(broad_cast_dims);
+      output->template tensor<T, 4>().device(d) = input.template tensor<T, 4>() +
+          bias.template tensor<T, 1>().reshape(four_dims).broadcast(broad_cast_dims);
       return;
     } // End of code by intel_tf.
 
@@ -167,8 +167,8 @@ class BiasOp : public BinaryOp<T> {
   void Compute(OpKernelContext* ctx, const Tensor& input, const Tensor& bias,
                Tensor* output) {
     functor::Bias<Device, T, Dims> functor;
-    functor(ctx->eigen_device<Device>(), input.tensor<T, Dims>(), bias.vec<T>(),
-            output->tensor<T, Dims>());
+    functor(ctx->eigen_device<Device>(), input.template tensor<T, Dims>(), bias.vec<T>(),
+            output->template tensor<T, Dims>());
   }
 
  private:
diff --git a/tensorflow/core/kernels/colorspace_op.cc b/tensorflow/core/kernels/colorspace_op.cc
index ba100b32e..2280dab1a 100644
--- a/tensorflow/core/kernels/colorspace_op.cc
+++ b/tensorflow/core/kernels/colorspace_op.cc
@@ -71,7 +71,7 @@ class RGBToHSVOp : public OpKernel {
                                         TensorShape({input_data.dimension(0)}),
                                         &trange));
 
-    typename TTypes<T, 1>::Tensor range = trange.tensor<T, 1>();
+    typename TTypes<T, 1>::Tensor range = trange.template tensor<T, 1>();
 
     functor::RGBToHSV<Device, T>()(context->eigen_device<Device>(), input_data,
                                    range, output_data);
diff --git a/tensorflow/core/kernels/concat_op.cc b/tensorflow/core/kernels/concat_op.cc
index 8e480aa99..d39f637f0 100644
--- a/tensorflow/core/kernels/concat_op.cc
+++ b/tensorflow/core/kernels/concat_op.cc
@@ -113,7 +113,7 @@ class ConcatBaseOp : public OpKernel {
       if (in.NumElements() > 0) {
         int64 inputs_flat_dim1 = in.NumElements() / inputs_flat_dim0;
         inputs_flat.emplace_back(new typename TTypes<T, 2>::ConstMatrix(
-            in.shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
+            in.template shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
       }
       // TODO(irving): Remove check once !allow_legacy_scalars().
       output_concat_dim += in.dims() > 0 ? in.dim_size(axis) : 1;
diff --git a/tensorflow/core/kernels/conv_grad_filter_ops.cc b/tensorflow/core/kernels/conv_grad_filter_ops.cc
index 5e09963d2..321dd8a60 100644
--- a/tensorflow/core/kernels/conv_grad_filter_ops.cc
+++ b/tensorflow/core/kernels/conv_grad_filter_ops.cc
@@ -99,8 +99,8 @@ struct LaunchConv2DBackpropInputOp<CPUDevice, T> {
                   Tensor* filter_backprop, TensorFormat data_format) {
     const CPUDevice& d = ctx->eigen_device<CPUDevice>();
     functor::SpatialConvolutionBackwardInput<CPUDevice, T>()(
-        d, filter_backprop->tensor<T, 4>(), input.tensor<T, 4>(),
-        out_backprop.tensor<T, 4>(), filter_backprop->dim_size(0),
+        d, filter_backprop->template tensor<T, 4>(), input.template tensor<T, 4>(),
+        out_backprop.template tensor<T, 4>(), filter_backprop->dim_size(0),
         filter_backprop->dim_size(1), row_stride, col_stride);
   }
 };
@@ -239,8 +239,8 @@ class Conv2DFastBackpropFilterOp : public OpKernel {
 
     if (pad_left == pad_right && pad_top == pad_bottom) {
       if (LaunchXsmmBackwardFilter<Device, T>()(
-              context, context->eigen_device<Device>(), input.tensor<T, 4>(),
-              filter_backprop->tensor<T, 4>(), out_backprop.tensor<T, 4>(),
+              context, context->eigen_device<Device>(), input.template tensor<T, 4>(),
+              filter_backprop->template tensor<T, 4>(), out_backprop.template tensor<T, 4>(),
               dims.spatial_dims[0].input_size, dims.spatial_dims[1].input_size,
               static_cast<int>(dims.spatial_dims[0].stride),
               static_cast<int>(dims.spatial_dims[1].stride),
@@ -330,8 +330,8 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {
 #if defined TENSORFLOW_USE_LIBXSMM && defined TENSORFLOW_USE_LIBXSMM_BACKWARD
     if (pad_left == pad_right && pad_top == pad_bottom) {
       if (LaunchXsmmBackwardFilter<Device, T>()(
-              context, context->eigen_device<Device>(), input.tensor<T, 4>(),
-              filter_backprop->tensor<T, 4>(), out_backprop.tensor<T, 4>(),
+              context, context->eigen_device<Device>(), input.template tensor<T, 4>(),
+              filter_backprop->template tensor<T, 4>(), out_backprop.template tensor<T, 4>(),
               dims.spatial_dims[0].input_size, dims.spatial_dims[1].input_size,
               static_cast<int>(dims.spatial_dims[0].stride),
               static_cast<int>(dims.spatial_dims[1].stride),
@@ -687,9 +687,9 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
                  &compatible_input));
 
     functor::PadInput<GPUDevice, T, int, 4>()(
-        ctx->template eigen_device<GPUDevice>(), To32Bit(input.tensor<T, 4>()),
+        ctx->template eigen_device<GPUDevice>(), To32Bit(input.template tensor<T, 4>()),
         {{0, 0}}, {{rows_odd, cols_odd}},
-        To32Bit(compatible_input.tensor<T, 4>()), data_format);
+        To32Bit(compatible_input.template tensor<T, 4>()), data_format);
   } else {
     compatible_input = input;
   }
@@ -752,8 +752,8 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
                      ctx->allocate_temp(DataTypeToEnum<T>::value, nchw_shape,
                                         &transformed_out_backprop));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
-          ctx->eigen_device<GPUDevice>(), out_backprop.tensor<T, 4>(),
-          transformed_out_backprop.tensor<T, 4>());
+          ctx->eigen_device<GPUDevice>(), out_backprop.template tensor<T, 4>(),
+          transformed_out_backprop.template tensor<T, 4>());
     } else {
       // If depth <= 1, just reshape.
       CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));
@@ -774,8 +774,8 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
                                              nchw_shape, &transformed_input));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
           ctx->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(compatible_input).tensor<T, 4>(),
-          transformed_input.tensor<T, 4>());
+          const_cast<const Tensor&>(compatible_input).template tensor<T, 4>(),
+          transformed_input.template tensor<T, 4>());
     } else {
       // If depth <= 1, just reshape.
       CHECK(transformed_input.CopyFrom(compatible_input, nchw_shape));
@@ -884,7 +884,7 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
   functor::ReverseTransformFilter<GPUDevice, T, 4>()(
       ctx->eigen_device<GPUDevice>(),
       toConstTensor(pre_transformed_filter_backprop).template tensor<T, 4>(),
-      filter_backprop->tensor<T, 4>());
+      filter_backprop->template tensor<T, 4>());
 }
 
 // Forward declarations of the functor specializations for GPU.
diff --git a/tensorflow/core/kernels/conv_grad_input_ops.cc b/tensorflow/core/kernels/conv_grad_input_ops.cc
index 0b2d01afa..30452cb1b 100644
--- a/tensorflow/core/kernels/conv_grad_input_ops.cc
+++ b/tensorflow/core/kernels/conv_grad_input_ops.cc
@@ -105,8 +105,8 @@ struct LaunchConv2DBackpropInputOp<CPUDevice, T> {
                   Tensor* in_backprop, TensorFormat data_format) {
     const CPUDevice& d = ctx->eigen_device<CPUDevice>();
     functor::SpatialConvolutionBackwardInput<CPUDevice, T>()(
-        d, in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),
-        out_backprop.tensor<T, 4>(), in_backprop->dim_size(1),
+        d, in_backprop->template tensor<T, 4>(), filter.template tensor<T, 4>(),
+        out_backprop.template tensor<T, 4>(), in_backprop->dim_size(1),
         in_backprop->dim_size(2), row_stride, col_stride);
   }
 };
@@ -244,8 +244,8 @@ class Conv2DFastBackpropInputOp : public OpKernel {
     if (pad_left == pad_right && pad_top == pad_bottom) {
       if (LaunchXsmmBackwardInputConvolution<Device, T>()(
               context, context->eigen_device<Device>(),
-              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),
-              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,
+              in_backprop->template tensor<T, 4>(), filter.template tensor<T, 4>(),
+              out_backprop.template tensor<T, 4>(), dims.spatial_dims[0].input_size,
               dims.spatial_dims[1].input_size,
               static_cast<int>(dims.spatial_dims[0].stride),
               static_cast<int>(dims.spatial_dims[1].stride),
@@ -339,8 +339,8 @@ class Conv2DCustomBackpropInputOp : public OpKernel {
     if (pad_left == pad_right && pad_top == pad_bottom) {
       if (LaunchXsmmBackwardInputConvolution<Device, T>()(
               context, context->eigen_device<Device>(),
-              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),
-              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,
+              in_backprop->template tensor<T, 4>(), filter.template tensor<T, 4>(),
+              out_backprop.template tensor<T, 4>(), dims.spatial_dims[0].input_size,
               dims.spatial_dims[1].input_size,
               static_cast<int>(dims.spatial_dims[0].stride),
               static_cast<int>(dims.spatial_dims[1].stride),
@@ -801,8 +801,8 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
                               &transformed_filter));
 
   functor::TransformFilter<GPUDevice, T, int, 4>()(
-      ctx->eigen_device<GPUDevice>(), To32Bit(filter.tensor<T, 4>()),
-      To32Bit(transformed_filter.tensor<T, 4>()));
+      ctx->eigen_device<GPUDevice>(), To32Bit(filter.template tensor<T, 4>()),
+      To32Bit(transformed_filter.template tensor<T, 4>()));
 
   Tensor transformed_out_backprop;
   if (data_format == FORMAT_NHWC) {
@@ -814,8 +814,8 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
                      ctx->allocate_temp(DataTypeToEnum<T>::value, nchw_shape,
                                         &transformed_out_backprop));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
-          ctx->eigen_device<GPUDevice>(), out_backprop.tensor<T, 4>(),
-          transformed_out_backprop.tensor<T, 4>());
+          ctx->eigen_device<GPUDevice>(), out_backprop.template tensor<T, 4>(),
+          transformed_out_backprop.template tensor<T, 4>());
     } else {
       // If depth <= 1, then just reshape.
       CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));
@@ -947,9 +947,9 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
     functor::PadInput<GPUDevice, T, int, 4>()(
         ctx->template eigen_device<GPUDevice>(),
         To32Bit(const_cast<const Tensor&>(pre_transformed_in_backprop)
-                    .tensor<T, 4>()),
+                    .template tensor<T, 4>()),
         {{0, 0}}, {{-rows_odd, -cols_odd}},
-        To32Bit(in_backprop_remove_padding.tensor<T, 4>()), FORMAT_NCHW);
+        To32Bit(in_backprop_remove_padding.template tensor<T, 4>()), FORMAT_NCHW);
 
     pre_transformed_in_backprop = in_backprop_remove_padding;
   }
@@ -959,7 +959,7 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
     functor::NCHWToNHWC<GPUDevice, T, 4>()(
         ctx->eigen_device<GPUDevice>(),
         toConstTensor(pre_transformed_in_backprop).template tensor<T, 4>(),
-        in_backprop->tensor<T, 4>());
+        in_backprop->template tensor<T, 4>());
   } else {
     *in_backprop = pre_transformed_in_backprop;
   }
diff --git a/tensorflow/core/kernels/conv_grad_ops_3d.cc b/tensorflow/core/kernels/conv_grad_ops_3d.cc
index 21f5cb171..4ffff4d93 100644
--- a/tensorflow/core/kernels/conv_grad_ops_3d.cc
+++ b/tensorflow/core/kernels/conv_grad_ops_3d.cc
@@ -197,8 +197,8 @@ class Conv3DBackpropInputOp : public OpKernel {
     Eigen::DSizes<Eigen::DenseIndex, 5> eigen_strides{1, strides[0], strides[1],
                                                       strides[2], 1};
     functor::InflatePadAndShuffle<Device, T, 5, Eigen::DenseIndex>()(
-        context->eigen_device<Device>(), out_backprop.tensor<T, 5>(),
-        eigen_strides, pad_dims, no_op_shuffle, padded_output.tensor<T, 5>());
+        context->eigen_device<Device>(), out_backprop.template tensor<T, 5>(),
+        eigen_strides, pad_dims, no_op_shuffle, padded_output.template tensor<T, 5>());
     const Tensor& padded_output_cref = padded_output;
 
     // Fill a new "reverted" filter. We need to transpose the in_depth and
@@ -211,14 +211,14 @@ class Conv3DBackpropInputOp : public OpKernel {
     Eigen::DSizes<Eigen::DenseIndex, 5> filter_order{0, 1, 2, 4, 3};
     Eigen::array<bool, 5> filter_rev_dims{true, true, true, false, false};
     functor::ShuffleAndReverse<Device, T, 5, Eigen::DenseIndex>()(
-        context->eigen_device<Device>(), filter.tensor<T, 5>(), filter_order,
-        filter_rev_dims, r_filter.tensor<T, 5>());
+        context->eigen_device<Device>(), filter.template tensor<T, 5>(), filter_order,
+        filter_rev_dims, r_filter.template tensor<T, 5>());
     const Tensor& r_filter_cref = r_filter;
 
     // Now we can call conv_3d directly.
     functor::CuboidConvolution<Device, T>()(
-        context->eigen_device<Device>(), in_backprop->tensor<T, 5>(),
-        padded_output_cref.tensor<T, 5>(), r_filter_cref.tensor<T, 5>(), 1, 1,
+        context->eigen_device<Device>(), in_backprop->template tensor<T, 5>(),
+        padded_output_cref.template tensor<T, 5>(), r_filter_cref.template tensor<T, 5>(), 1, 1,
         1, BrainPadding2EigenPadding(VALID));
   }
 
@@ -318,8 +318,8 @@ class Conv3DBackpropFilterOp : public OpKernel {
     Eigen::DSizes<Eigen::DenseIndex, 5> eigen_strides{1, strides[0], strides[1],
                                                       strides[2], 1};
     functor::InflatePadAndShuffle<Device, T, 5, Eigen::DenseIndex>()(
-        context->eigen_device<Device>(), out_backprop.tensor<T, 5>(),
-        eigen_strides, pad_dims, out_order, padded_output.tensor<T, 5>());
+        context->eigen_device<Device>(), out_backprop.template tensor<T, 5>(),
+        eigen_strides, pad_dims, out_order, padded_output.template tensor<T, 5>());
     const Tensor& padded_output_cref = padded_output;
 
     // For the backprop of the filter, we need to transpose the input.
@@ -337,8 +337,8 @@ class Conv3DBackpropFilterOp : public OpKernel {
     // No need for reversing this time.
     Eigen::array<bool, 5> no_reverse{false, false, false, false, false};
     functor::ShuffleAndReverse<Device, T, 5, Eigen::DenseIndex>()(
-        context->eigen_device<Device>(), input.tensor<T, 5>(), in_order,
-        no_reverse, in_shuffle.tensor<T, 5>());
+        context->eigen_device<Device>(), input.template tensor<T, 5>(), in_order,
+        no_reverse, in_shuffle.template tensor<T, 5>());
     const Tensor& in_shuffle_cref = in_shuffle;
 
     // The output of the conv_3d would be
@@ -355,8 +355,8 @@ class Conv3DBackpropFilterOp : public OpKernel {
         context, context->allocate_temp(DataTypeToEnum<T>::v(),
                                         filter_shuffle_shape, &filter_shuffle));
     functor::CuboidConvolution<Device, T>()(
-        context->eigen_device<Device>(), filter_shuffle.tensor<T, 5>(),
-        padded_output_cref.tensor<T, 5>(), in_shuffle_cref.tensor<T, 5>(), 1, 1,
+        context->eigen_device<Device>(), filter_shuffle.template tensor<T, 5>(),
+        padded_output_cref.template tensor<T, 5>(), in_shuffle_cref.template tensor<T, 5>(), 1, 1,
         1, BrainPadding2EigenPadding(VALID));
 
     // Now copy the filter_backprop back to the destination.
@@ -364,8 +364,8 @@ class Conv3DBackpropFilterOp : public OpKernel {
     Eigen::array<bool, 5> filter_rev_dims{true, true, true, false, false};
     const Tensor& filter_shuffle_cref = filter_shuffle;
     functor::ShuffleAndReverse<Device, T, 5, Eigen::DenseIndex>()(
-        context->eigen_device<Device>(), filter_shuffle_cref.tensor<T, 5>(),
-        filter_order, filter_rev_dims, filter_backprop->tensor<T, 5>());
+        context->eigen_device<Device>(), filter_shuffle_cref.template tensor<T, 5>(),
+        filter_order, filter_rev_dims, filter_backprop->template tensor<T, 5>());
   }
 
  private:
@@ -593,8 +593,8 @@ class Conv3DBackpropInputOp<GPUDevice, T> : public OpKernel {
                                             filter_size[1], filter_size[2]}),
                                &transformed_filter));
     functor::TransformFilter<GPUDevice, T, int, 5>()(
-        context->eigen_device<GPUDevice>(), To32Bit(filter.tensor<T, 5>()),
-        To32Bit(transformed_filter.tensor<T, 5>()));
+        context->eigen_device<GPUDevice>(), To32Bit(filter.template tensor<T, 5>()),
+        To32Bit(transformed_filter.template tensor<T, 5>()));
 
     // Shape: batch, filters, z, y, x.
     Tensor transformed_out_backprop;
@@ -606,8 +606,8 @@ class Conv3DBackpropInputOp<GPUDevice, T> : public OpKernel {
                                     DataTypeToEnum<T>::value, nchw_shape,
                                     &transformed_out_backprop));
         functor::NHWCToNCHW<GPUDevice, T, 5>()(
-            context->eigen_device<GPUDevice>(), out_backprop.tensor<T, 5>(),
-            transformed_out_backprop.tensor<T, 5>());
+            context->eigen_device<GPUDevice>(), out_backprop.template tensor<T, 5>(),
+            transformed_out_backprop.template tensor<T, 5>());
       } else {
         CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));
       }
@@ -728,9 +728,9 @@ class Conv3DBackpropInputOp<GPUDevice, T> : public OpKernel {
       functor::PadInput<GPUDevice, T, int, 5>()(
           context->eigen_device<GPUDevice>(),
           To32Bit(const_cast<const Tensor&>(pre_transformed_in_backprop)
-                      .tensor<T, 5>()),
+                      .template tensor<T, 5>()),
           {{0, 0, 0}}, {{-planes_odd, -rows_odd, -cols_odd}},
-          To32Bit(in_backprop_remove_padding.tensor<T, 5>()), FORMAT_NCHW);
+          To32Bit(in_backprop_remove_padding.template tensor<T, 5>()), FORMAT_NCHW);
 
       pre_transformed_in_backprop = in_backprop_remove_padding;
     }
@@ -740,7 +740,7 @@ class Conv3DBackpropInputOp<GPUDevice, T> : public OpKernel {
       functor::NCHWToNHWC<GPUDevice, T, 5>()(
           context->eigen_device<GPUDevice>(),
           toConstTensor(pre_transformed_in_backprop).template tensor<T, 5>(),
-          in_backprop->tensor<T, 5>());
+          in_backprop->template tensor<T, 5>());
     } else {
       *in_backprop = pre_transformed_in_backprop;
     }
@@ -901,9 +901,9 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {
                                   &compatible_input));
       functor::PadInput<GPUDevice, T, int, 5>()(
           context->template eigen_device<GPUDevice>(),
-          To32Bit(input.tensor<T, 5>()), {{0, 0, 0}},
+          To32Bit(input.template tensor<T, 5>()), {{0, 0, 0}},
           {{planes_odd, rows_odd, cols_odd}},
-          To32Bit(compatible_input.tensor<T, 5>()), data_format_);
+          To32Bit(compatible_input.template tensor<T, 5>()), data_format_);
     } else {
       compatible_input = input;
     }
@@ -959,8 +959,8 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {
                                           &transformed_out_backprop));
       if (out_depth > 1) {
         functor::NHWCToNCHW<GPUDevice, T, 5>()(
-            context->eigen_device<GPUDevice>(), out_backprop.tensor<T, 5>(),
-            transformed_out_backprop.tensor<T, 5>());
+            context->eigen_device<GPUDevice>(), out_backprop.template tensor<T, 5>(),
+            transformed_out_backprop.template tensor<T, 5>());
       } else {
         CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));
       }
@@ -978,8 +978,8 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {
                                               nchw_shape, &transformed_input));
         functor::NHWCToNCHW<GPUDevice, T, 5>()(
             context->eigen_device<GPUDevice>(),
-            const_cast<const Tensor&>(compatible_input).tensor<T, 5>(),
-            transformed_input.tensor<T, 5>());
+            const_cast<const Tensor&>(compatible_input).template tensor<T, 5>(),
+            transformed_input.template tensor<T, 5>());
       } else {
         CHECK(transformed_input.CopyFrom(compatible_input, nchw_shape));
       }
@@ -1087,7 +1087,7 @@ class Conv3DBackpropFilterOp<GPUDevice, T> : public OpKernel {
     functor::ReverseTransformFilter<GPUDevice, T, 5>()(
         context->eigen_device<GPUDevice>(),
         toConstTensor(pre_transformed_filter_backprop).template tensor<T, 5>(),
-        filter_backprop->tensor<T, 5>());
+        filter_backprop->template tensor<T, 5>());
   }
 
  private:
diff --git a/tensorflow/core/kernels/conv_ops.cc b/tensorflow/core/kernels/conv_ops.cc
index bb67113fb..f81c8c649 100644
--- a/tensorflow/core/kernels/conv_ops.cc
+++ b/tensorflow/core/kernels/conv_ops.cc
@@ -82,8 +82,8 @@ struct LaunchGeneric {
       functor::MatMulConvFunctor<Device, T>()(
           ctx->eigen_device<Device>(),
           output->shaped<T, 2>({conv_width, filter.dim_size(3)}),
-          input.shaped<T, 2>({conv_width, filter.dim_size(2)}),
-          filter.shaped<T, 2>({filter.dim_size(2), filter.dim_size(3)}),
+          input.template shaped<T, 2>({conv_width, filter.dim_size(2)}),
+          filter.template shaped<T, 2>({filter.dim_size(2), filter.dim_size(3)}),
           dim_pair);
     } else if (filter.dim_size(0) == input.dim_size(1) &&
                filter.dim_size(1) == input.dim_size(2) && padding == VALID) {
@@ -97,12 +97,12 @@ struct LaunchGeneric {
       functor::MatMulConvFunctor<Device, T>()(
           ctx->eigen_device<Device>(),
           output->shaped<T, 2>({input.dim_size(0), filter.dim_size(3)}),
-          input.shaped<T, 2>({input.dim_size(0), k}),
-          filter.shaped<T, 2>({k, filter.dim_size(3)}), dim_pair);
+          input.template shaped<T, 2>({input.dim_size(0), k}),
+          filter.template shaped<T, 2>({k, filter.dim_size(3)}), dim_pair);
     } else {
       functor::SpatialConvolution<Device, T>()(
-          ctx->eigen_device<Device>(), output->tensor<T, 4>(),
-          input.tensor<T, 4>(), filter.tensor<T, 4>(), row_stride, col_stride,
+          ctx->eigen_device<Device>(), output->template tensor<T, 4>(),
+          input.template tensor<T, 4>(), filter.template tensor<T, 4>(), row_stride, col_stride,
           BrainPadding2EigenPadding(padding));
     }
   }
@@ -555,9 +555,9 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
                              &transformed_input));
 
       functor::PadInput<GPUDevice, T, int, 4>()(
-          ctx->eigen_device<GPUDevice>(), To32Bit(input_param.tensor<T, 4>()),
+          ctx->eigen_device<GPUDevice>(), To32Bit(input_param.template tensor<T, 4>()),
           {{0, 0}}, {{rows_odd, cols_odd}},
-          To32Bit(transformed_input.tensor<T, 4>()), data_format);
+          To32Bit(transformed_input.template tensor<T, 4>()), data_format);
 
       input = transformed_input;
       in_rows = new_in_rows;
@@ -575,8 +575,8 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
                                              nchw_shape, &transformed_input));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
           ctx->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(input).tensor<T, 4>(),
-          transformed_input.tensor<T, 4>());
+          const_cast<const Tensor&>(input).template tensor<T, 4>(),
+          transformed_input.template tensor<T, 4>());
       input = transformed_input;
     } else {
       // If depth <= 1, then just reshape.
@@ -618,8 +618,8 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
                           &transformed_filter));
 
   functor::TransformFilter<GPUDevice, T, int, 4>()(
-      ctx->eigen_device<GPUDevice>(), To32Bit(filter.tensor<T, 4>()),
-      To32Bit(transformed_filter.tensor<T, 4>()));
+      ctx->eigen_device<GPUDevice>(), To32Bit(filter.template tensor<T, 4>()),
+      To32Bit(transformed_filter.template tensor<T, 4>()));
 
   Tensor transformed_output;
   OP_REQUIRES_OK(
@@ -727,8 +727,8 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
   if (data_format == FORMAT_NHWC) {
     functor::NCHWToNHWC<GPUDevice, T, 4>()(
         ctx->eigen_device<GPUDevice>(),
-        const_cast<const Tensor&>(transformed_output).tensor<T, 4>(),
-        output->tensor<T, 4>());
+        const_cast<const Tensor&>(transformed_output).template tensor<T, 4>(),
+        output->template tensor<T, 4>());
   } else {
     *output = transformed_output;
   }
diff --git a/tensorflow/core/kernels/conv_ops_3d.cc b/tensorflow/core/kernels/conv_ops_3d.cc
index 8a89d564d..7c152874b 100644
--- a/tensorflow/core/kernels/conv_ops_3d.cc
+++ b/tensorflow/core/kernels/conv_ops_3d.cc
@@ -56,8 +56,8 @@ struct LaunchConvOp<CPUDevice, T> {
                                         "currently only supports the NHWC "
                                         "tensor format."));
     functor::CuboidConvolution<CPUDevice, T>()(
-        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),
-        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],
+        context->eigen_device<CPUDevice>(), output->template tensor<T, 5>(),
+        input.template tensor<T, 5>(), filter.template tensor<T, 5>(), strides[2], strides[1],
         strides[0], BrainPadding2EigenPadding(padding));
   }
 };
@@ -275,9 +275,9 @@ struct LaunchConvOp<GPUDevice, T> {
                                     &transformed_input));
 
         functor::PadInput<GPUDevice, T, int, 5>()(
-            ctx->eigen_device<GPUDevice>(), To32Bit(input_param.tensor<T, 5>()),
+            ctx->eigen_device<GPUDevice>(), To32Bit(input_param.template tensor<T, 5>()),
             {{0, 0, 0}}, {{planes_odd, rows_odd, cols_odd}},
-            To32Bit(transformed_input.tensor<T, 5>()), data_format);
+            To32Bit(transformed_input.template tensor<T, 5>()), data_format);
         input = transformed_input;
         in_rows = new_in_rows;
         in_cols = new_in_cols;
@@ -297,8 +297,8 @@ struct LaunchConvOp<GPUDevice, T> {
         // NCDHW is the only format universally supported by cuDNN.
         functor::NHWCToNCHW<GPUDevice, T, 5>()(
             ctx->eigen_device<GPUDevice>(),
-            const_cast<const Tensor&>(input).tensor<T, 5>(),
-            transformed_input.tensor<T, 5>());
+            const_cast<const Tensor&>(input).template tensor<T, 5>(),
+            transformed_input.template tensor<T, 5>());
         input = transformed_input;
       } else {
         CHECK(input.CopyFrom(input, nchw_shape));
@@ -345,8 +345,8 @@ struct LaunchConvOp<GPUDevice, T> {
     // filter: [x, y, z, in, out]
     // t_filter: [out, in, x, y, z]
     functor::TransformFilter<GPUDevice, T, int, 5>()(
-        ctx->eigen_device<GPUDevice>(), To32Bit(filter.tensor<T, 5>()),
-        To32Bit(transformed_filter.tensor<T, 5>()));
+        ctx->eigen_device<GPUDevice>(), To32Bit(filter.template tensor<T, 5>()),
+        To32Bit(transformed_filter.template tensor<T, 5>()));
 
     Tensor transformed_output;
     OP_REQUIRES_OK(
@@ -454,8 +454,8 @@ struct LaunchConvOp<GPUDevice, T> {
       // output: [b, x, y, z, out]
       functor::NCHWToNHWC<GPUDevice, T, 5>()(
           ctx->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(transformed_output).tensor<T, 5>(),
-          output->tensor<T, 5>());
+          const_cast<const Tensor&>(transformed_output).template tensor<T, 5>(),
+          output->template tensor<T, 5>());
     } else {
       *output = transformed_output;
     }
diff --git a/tensorflow/core/kernels/crop_and_resize_op.cc b/tensorflow/core/kernels/crop_and_resize_op.cc
index 45cc2fbbb..2d9c68a1b 100644
--- a/tensorflow/core/kernels/crop_and_resize_op.cc
+++ b/tensorflow/core/kernels/crop_and_resize_op.cc
@@ -178,16 +178,16 @@ class CropAndResizeOp : public AsyncOpKernel {
       const Tensor& boxes = context->input(1);
       const Tensor& box_index = context->input(2);
       const bool status = functor::CropAndResize<Device, T>()(
-          context, image.tensor<T, 4>(), boxes.tensor<float, 2>(),
-          box_index.tensor<int32, 1>(), extrapolation_value_,
-          output->tensor<float, 4>());
+          context, image.template tensor<T, 4>(), boxes.template tensor<float, 2>(),
+          box_index.template tensor<int32, 1>(), extrapolation_value_,
+          output->template tensor<float, 4>());
       if (!status) {
         context->SetStatus(
             errors::Internal("Failed launch CropAndResizeKernel."));
       }
     };
 
-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),
+    RunIfBoxIndexIsValid<Device>(context, box_index.template tensor<int32, 1>(),
                                  batch_size, std::move(compute_callback),
                                  std::move(done));
   }
@@ -378,16 +378,16 @@ class CropAndResizeGradImageOp : public AsyncOpKernel {
       const Tensor& boxes = context->input(1);
       const Tensor& box_index = context->input(2);
       const bool status = functor::CropAndResizeBackpropImage<Device, T>()(
-          context->eigen_device<Device>(), grads.tensor<float, 4>(),
-          boxes.tensor<float, 2>(), box_index.tensor<int32, 1>(),
-          output->tensor<T, 4>());
+          context->eigen_device<Device>(), grads.template tensor<float, 4>(),
+          boxes.template tensor<float, 2>(), box_index.template tensor<int32, 1>(),
+          output->template tensor<T, 4>());
       if (!status) {
         context->SetStatus(errors::Internal(
             "Failed launch CropAndResizeBackpropImage kernel."));
       }
     };
 
-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),
+    RunIfBoxIndexIsValid<Device>(context, box_index.template tensor<int32, 1>(),
                                  batch_size, std::move(compute_callback),
                                  std::move(done));
   }
@@ -543,16 +543,16 @@ class CropAndResizeGradBoxesOp : public AsyncOpKernel {
       const Tensor& boxes = context->input(2);
       const Tensor& box_index = context->input(3);
       const bool status = functor::CropAndResizeBackpropBoxes<Device, T>()(
-          context->eigen_device<Device>(), grads.tensor<float, 4>(),
-          image.tensor<T, 4>(), boxes.tensor<float, 2>(),
-          box_index.tensor<int32, 1>(), output->tensor<float, 2>());
+          context->eigen_device<Device>(), grads.template tensor<float, 4>(),
+          image.template tensor<T, 4>(), boxes.template tensor<float, 2>(),
+          box_index.template tensor<int32, 1>(), output->template tensor<float, 2>());
       if (!status) {
         context->SetStatus(errors::Internal(
             "Failed launch CropAndResizeBackpropBoxes kernel."));
       }
     };
 
-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),
+    RunIfBoxIndexIsValid<Device>(context, box_index.template tensor<int32, 1>(),
                                  batch_size, std::move(compute_callback),
                                  std::move(done));
   }
@@ -732,7 +732,7 @@ inline void RunIfBoxIndexIsValid<GPUDevice>(
                              &isvalid_dev_tensor),
       done);
   typename TTypes<bool, 0>::Tensor isvalid_dev =
-      isvalid_dev_tensor.tensor<bool, 0>();
+      isvalid_dev_tensor.template tensor<bool, 0>();
 
   // Run the actual box check on the device.
   functor::CheckValidBoxIndexHelper<GPUDevice>()(
diff --git a/tensorflow/core/kernels/ctc_decoder_ops.cc b/tensorflow/core/kernels/ctc_decoder_ops.cc
index 73ee31060..2a3f0e639 100644
--- a/tensorflow/core/kernels/ctc_decoder_ops.cc
+++ b/tensorflow/core/kernels/ctc_decoder_ops.cc
@@ -196,7 +196,7 @@ class CTCGreedyDecoderOp : public OpKernel {
         errors::InvalidArgument("num_classes cannot exceed max int"));
     const int num_classes = static_cast<const int>(num_classes_raw);
 
-    auto inputs_t = inputs->tensor<float, 3>();
+    auto inputs_t = inputs->template tensor<float, 3>();
 
     for (std::size_t t = 0; t < max_time; ++t) {
       input_list_t.emplace_back(inputs_t.data() + t * batch_size * num_classes,
@@ -264,7 +264,7 @@ class CTCBeamSearchDecoderOp : public OpKernel {
                             ctx, &inputs, &seq_len, &log_prob, &decoded_indices,
                             &decoded_values, &decoded_shape));
 
-    auto inputs_t = inputs->tensor<float, 3>();
+    auto inputs_t = inputs->template tensor<float, 3>();
     auto seq_len_t = seq_len->vec<int32>();
     auto log_prob_t = log_prob->matrix<float>();
 
diff --git a/tensorflow/core/kernels/ctc_loss_op.cc b/tensorflow/core/kernels/ctc_loss_op.cc
index fb03adb7a..a09d551df 100644
--- a/tensorflow/core/kernels/ctc_loss_op.cc
+++ b/tensorflow/core/kernels/ctc_loss_op.cc
@@ -140,8 +140,8 @@ class CTCLossOp : public OpKernel {
     Tensor* gradient;
     OP_REQUIRES_OK(ctx,
                    ctx->allocate_output("gradient", inputs_shape, &gradient));
-    auto gradient_t = gradient->tensor<float, 3>();
-    auto inputs_t = inputs->tensor<float, 3>();
+    auto gradient_t = gradient->template tensor<float, 3>();
+    auto inputs_t = inputs->template tensor<float, 3>();
     std::vector<OutputMap> gradient_list_t;
     std::vector<InputMap> input_list_t;
 
diff --git a/tensorflow/core/kernels/cudnn_pooling_gpu.cc b/tensorflow/core/kernels/cudnn_pooling_gpu.cc
index 5939ecdf6..d4044e196 100644
--- a/tensorflow/core/kernels/cudnn_pooling_gpu.cc
+++ b/tensorflow/core/kernels/cudnn_pooling_gpu.cc
@@ -51,8 +51,8 @@ void DnnPooling3dOp<T>::Compute(
                                                 data_format),
                                 &transformed_input));
     functor::NHWCToNCHW<GPUDevice, T, 5>()(context->eigen_device<GPUDevice>(),
-                                           tensor_in.tensor<T, 5>(),
-                                           transformed_input.tensor<T, 5>());
+                                           tensor_in.template tensor<T, 5>(),
+                                           transformed_input.template tensor<T, 5>());
   } else {
     transformed_input = tensor_in;
   }
@@ -109,7 +109,7 @@ void DnnPooling3dOp<T>::Compute(
     functor::NCHWToNHWC<GPUDevice, T, 5>()(
         context->eigen_device<GPUDevice>(),
         toConstTensor(transformed_output).template tensor<T, 5>(),
-        output->tensor<T, 5>());
+        output->template tensor<T, 5>());
   }
 }
 
@@ -173,17 +173,17 @@ void DnnPooling3dGradOp<T>::Compute(
   if (data_format == FORMAT_NHWC) {
     if (tensor_in != nullptr) {
       functor::NHWCToNCHW<GPUDevice, T, 5>()(context->eigen_device<GPUDevice>(),
-                                             tensor_in->tensor<T, 5>(),
-                                             transformed_input.tensor<T, 5>());
+                                             tensor_in->template tensor<T, 5>(),
+                                             transformed_input.template tensor<T, 5>());
     }
     if (tensor_out != nullptr) {
       functor::NHWCToNCHW<GPUDevice, T, 5>()(context->eigen_device<GPUDevice>(),
-                                             tensor_out->tensor<T, 5>(),
-                                             transformed_output.tensor<T, 5>());
+                                             tensor_out->template tensor<T, 5>(),
+                                             transformed_output.template tensor<T, 5>());
     }
     functor::NHWCToNCHW<GPUDevice, T, 5>()(
-        context->eigen_device<GPUDevice>(), out_backprop.tensor<T, 5>(),
-        transformed_output_backprop.tensor<T, 5>());
+        context->eigen_device<GPUDevice>(), out_backprop.template tensor<T, 5>(),
+        transformed_output_backprop.template tensor<T, 5>());
   }
 
   perftools::gputools::dnn::PoolingDescriptor pooling_desc(3);
@@ -239,7 +239,7 @@ void DnnPooling3dGradOp<T>::Compute(
     functor::NCHWToNHWC<GPUDevice, T, 5>()(
         context->eigen_device<GPUDevice>(),
         toConstTensor(transformed_input_backprop).template tensor<T, 5>(),
-        input_backprop->tensor<T, 5>());
+        input_backprop->template tensor<T, 5>());
   }
 }
 
diff --git a/tensorflow/core/kernels/depthtospace_op.cc b/tensorflow/core/kernels/depthtospace_op.cc
index 4cf7de0df..fbc7a714e 100644
--- a/tensorflow/core/kernels/depthtospace_op.cc
+++ b/tensorflow/core/kernels/depthtospace_op.cc
@@ -109,8 +109,8 @@ class DepthToSpaceOp : public OpKernel {
                        ShapeFromFormat(data_format_, batch_size, output_height,
                                        output_width, output_depth),
                        &outputs_tensor));
-    auto Tinput = input.tensor<T, kRequiredDims>();
-    auto Toutput = outputs_tensor->tensor<T, kRequiredDims>();
+    auto Tinput = input.template tensor<T, kRequiredDims>();
+    auto Toutput = outputs_tensor->template tensor<T, kRequiredDims>();
 
     if (std::is_same<Device, GPUDevice>::value && data_format_ == FORMAT_NCHW) {
       functor::DepthToSpaceOpFunctor<Device, T, FORMAT_NCHW> functor;
diff --git a/tensorflow/core/kernels/diag_op.cc b/tensorflow/core/kernels/diag_op.cc
index c800859d9..9ebfd5987 100644
--- a/tensorflow/core/kernels/diag_op.cc
+++ b/tensorflow/core/kernels/diag_op.cc
@@ -39,7 +39,7 @@ class DiagonalGenerator {
       }
       index[i] = coordinates[i];
     }
-    return diagonal_.tensor<T, NumDims>()(index);
+    return diagonal_.template tensor<T, NumDims>()(index);
   }
 
  private:
@@ -60,7 +60,7 @@ class DiagonalExtractor {
     for (size_t j = NumDims; j < 2 * NumDims; ++j){
       index[j] = index[j - NumDims];
     }
-    return tensor_.tensor<T, 2 * NumDims>()(index);
+    return tensor_.template tensor<T, 2 * NumDims>()(index);
   }
 
  private:
@@ -95,15 +95,15 @@ class DiagOp : public OpKernel {
                    context->allocate_output(0, out_shape, &output_tensor));
     switch (num_dims) {
       case 1:
-        output_tensor->tensor<T, 2>() = output_tensor->tensor<T, 2>().generate(
+        output_tensor->template tensor<T, 2>() = output_tensor->template tensor<T, 2>().generate(
             DiagonalGenerator<T, 1, 2>(diagonal));
         break;
       case 2:
-        output_tensor->tensor<T, 4>() = output_tensor->tensor<T, 4>().generate(
+        output_tensor->template tensor<T, 4>() = output_tensor->template tensor<T, 4>().generate(
             DiagonalGenerator<T, 2, 4>(diagonal));
         break;
       case 3:
-        output_tensor->tensor<T, 6>() = output_tensor->tensor<T, 6>().generate(
+        output_tensor->template tensor<T, 6>() = output_tensor->template tensor<T, 6>().generate(
             DiagonalGenerator<T, 3, 6>(diagonal));
         break;
       default:
@@ -163,15 +163,15 @@ class DiagPartOp : public OpKernel {
 
     switch (num_dims) {
       case 2:
-        output->tensor<T, 1>() = output->tensor<T, 1>().generate(
+        output->template tensor<T, 1>() = output->template tensor<T, 1>().generate(
           DiagonalExtractor<T, 1>(tensor));
         break; 
       case 4:
-        output->tensor<T, 2>() = output->tensor<T, 2>().generate(
+        output->template tensor<T, 2>() = output->template tensor<T, 2>().generate(
           DiagonalExtractor<T, 2>(tensor));
         break;
       case 6:
-        output->tensor<T, 3>() = output->tensor<T, 3>().generate(
+        output->template tensor<T, 3>() = output->template tensor<T, 3>().generate(
           DiagonalExtractor<T, 3>(tensor));
         break;      
       default:
diff --git a/tensorflow/core/kernels/dilation_ops.cc b/tensorflow/core/kernels/dilation_ops.cc
index 6f5c0e915..901e6faf4 100644
--- a/tensorflow/core/kernels/dilation_ops.cc
+++ b/tensorflow/core/kernels/dilation_ops.cc
@@ -147,9 +147,9 @@ class DilationOp : public OpKernel {
     }
 
     functor::Dilation<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(),
-        filter.tensor<T, 3>(), stride_rows, stride_cols, rate_rows, rate_cols,
-        pad_top, pad_left, output->tensor<T, 4>());
+        context->eigen_device<Device>(), input.template tensor<T, 4>(),
+        filter.template tensor<T, 3>(), stride_rows, stride_cols, rate_rows, rate_cols,
+        pad_top, pad_left, output->template tensor<T, 4>());
   }
 
   std::vector<int32> strides_;
@@ -252,10 +252,10 @@ class DilationBackpropInputOp : public OpKernel {
     }
 
     functor::DilationBackpropInput<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(),
-        filter.tensor<T, 3>(), out_backprop.tensor<T, 4>(), stride_rows,
+        context->eigen_device<Device>(), input.template tensor<T, 4>(),
+        filter.template tensor<T, 3>(), out_backprop.template tensor<T, 4>(), stride_rows,
         stride_cols, rate_rows, rate_cols, pad_top, pad_left,
-        in_backprop->tensor<T, 4>());
+        in_backprop->template tensor<T, 4>());
   }
 
   std::vector<int32> strides_;
@@ -371,10 +371,10 @@ class DilationBackpropFilterOp : public OpKernel {
     }
 
     functor::DilationBackpropFilter<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(),
-        filter.tensor<T, 3>(), out_backprop.tensor<T, 4>(), stride_rows,
+        context->eigen_device<Device>(), input.template tensor<T, 4>(),
+        filter.template tensor<T, 3>(), out_backprop.template tensor<T, 4>(), stride_rows,
         stride_cols, rate_rows, rate_cols, pad_top, pad_left,
-        filter_backprop->tensor<T, 3>());
+        filter_backprop->template tensor<T, 3>());
   }
 
   std::vector<int32> strides_;
diff --git a/tensorflow/core/kernels/draw_bounding_box_op.cc b/tensorflow/core/kernels/draw_bounding_box_op.cc
index a8818b738..63d778f6c 100644
--- a/tensorflow/core/kernels/draw_bounding_box_op.cc
+++ b/tensorflow/core/kernels/draw_bounding_box_op.cc
@@ -84,12 +84,12 @@ class DrawBoundingBoxesOp : public OpKernel {
         context->allocate_output(
             0, TensorShape({batch_size, height, width, depth}), &output));
 
-    output->tensor<T, 4>() = images.tensor<T, 4>();
-    auto canvas = output->tensor<T, 4>();
+    output->template tensor<T, 4>() = images.template tensor<T, 4>();
+    auto canvas = output->template tensor<T, 4>();
 
     for (int64 b = 0; b < batch_size; ++b) {
       const int64 num_boxes = boxes.dim_size(1);
-      const auto tboxes = boxes.tensor<T, 3>();
+      const auto tboxes = boxes.template tensor<T, 3>();
       for (int64 bb = 0; bb < num_boxes; ++bb) {
         int64 color_index = bb % color_table_length;
         const int64 min_box_row =
diff --git a/tensorflow/core/kernels/dynamic_stitch_op.cc b/tensorflow/core/kernels/dynamic_stitch_op.cc
index f018499f6..f3c23a2b0 100644
--- a/tensorflow/core/kernels/dynamic_stitch_op.cc
+++ b/tensorflow/core/kernels/dynamic_stitch_op.cc
@@ -244,7 +244,7 @@ class DynamicStitchOpImplCPU : public DynamicStitchOpImplBase<T> {
         auto indices_vec = indices.flat<int32>();
         const Tensor& data = data_inputs[input_num];
         auto data_flat =
-            data.shaped<T, 2>({indices_vec.dimension(0), slice_size});
+            data.template shaped<T, 2>({indices_vec.dimension(0), slice_size});
 
         if (DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) {
           T* merged_base = &merged_flat(0, 0);
diff --git a/tensorflow/core/kernels/extract_image_patches_op.cc b/tensorflow/core/kernels/extract_image_patches_op.cc
index 68631d14d..b6bf3492a 100644
--- a/tensorflow/core/kernels/extract_image_patches_op.cc
+++ b/tensorflow/core/kernels/extract_image_patches_op.cc
@@ -105,9 +105,9 @@ class ExtractImagePatchesOp : public UnaryOp<T> {
     }
 
     functor::ExtractImagePatchesForward<Device, T>()(
-        context->eigen_device<Device>(), input.tensor<T, 4>(), ksize_rows,
+        context->eigen_device<Device>(), input.template tensor<T, 4>(), ksize_rows,
         ksize_cols, stride_rows, stride_cols, rate_rows, rate_cols,
-        BrainPadding2EigenPadding(padding_), output->tensor<T, 4>());
+        BrainPadding2EigenPadding(padding_), output->template tensor<T, 4>());
   }
 
  private:
diff --git a/tensorflow/core/kernels/extract_jpeg_shape_op.cc b/tensorflow/core/kernels/extract_jpeg_shape_op.cc
index 60d798af5..724c048d8 100644
--- a/tensorflow/core/kernels/extract_jpeg_shape_op.cc
+++ b/tensorflow/core/kernels/extract_jpeg_shape_op.cc
@@ -57,7 +57,7 @@ class ExtractJpegShapeOp : public OpKernel {
     Tensor* image_shape = nullptr;
     OP_REQUIRES_OK(context,
                    context->allocate_output(0, TensorShape({3}), &image_shape));
-    auto image_shape_data = image_shape->tensor<T, 1>();
+    auto image_shape_data = image_shape->template tensor<T, 1>();
     image_shape_data(0) = height;
     image_shape_data(1) = width;
     image_shape_data(2) = components;
diff --git a/tensorflow/core/kernels/fused_batch_norm_op.cc b/tensorflow/core/kernels/fused_batch_norm_op.cc
index 0ecb829f3..081811488 100644
--- a/tensorflow/core/kernels/fused_batch_norm_op.cc
+++ b/tensorflow/core/kernels/fused_batch_norm_op.cc
@@ -62,13 +62,13 @@ struct FusedBatchNorm<CPUDevice, T, U> {
     OP_REQUIRES(context, tensor_format == FORMAT_NHWC,
                 errors::Internal("The CPU implementation of FusedBatchNorm "
                                  "only supports NHWC tensor format for now."));
-    typename TTypes<T, 4>::ConstTensor x(x_input.tensor<T, 4>());
+    typename TTypes<T, 4>::ConstTensor x(x_input.template tensor<T, 4>());
     typename TTypes<T>::ConstVec scale(scale_input.vec<T>());
     typename TTypes<T>::ConstVec offset(offset_input.vec<T>());
     typename TTypes<T>::ConstVec estimated_mean(estimated_mean_input.vec<T>());
     typename TTypes<T>::ConstVec estimated_variance(
         estimated_variance_input.vec<T>());
-    typename TTypes<T, 4>::Tensor y(y_output->tensor<T, 4>());
+    typename TTypes<T, 4>::Tensor y(y_output->template tensor<T, 4>());
     typename TTypes<T>::Vec batch_mean(batch_mean_output->vec<T>());
     typename TTypes<T>::Vec batch_var(batch_var_output->vec<T>());
     typename TTypes<T>::Vec saved_mean(saved_mean_output->vec<T>());
@@ -145,12 +145,12 @@ struct FusedBatchNormGrad<CPUDevice, T, U> {
                 errors::Internal("The CPU implementation of FusedBatchNormGrad "
                                  "only supports NHWC tensor format for now."));
     typename TTypes<T, 4>::ConstTensor y_backprop(
-        y_backprop_input.tensor<T, 4>());
-    typename TTypes<T, 4>::ConstTensor x(x_input.tensor<T, 4>());
+        y_backprop_input.template tensor<T, 4>());
+    typename TTypes<T, 4>::ConstTensor x(x_input.template tensor<T, 4>());
     typename TTypes<T>::ConstVec scale(scale_input.vec<T>());
     typename TTypes<T>::ConstVec mean(mean_input.vec<T>());
     typename TTypes<T>::ConstVec variance(variance_input.vec<T>());
-    typename TTypes<T, 4>::Tensor x_backprop(x_backprop_output->tensor<T, 4>());
+    typename TTypes<T, 4>::Tensor x_backprop(x_backprop_output->template tensor<T, 4>());
     typename TTypes<T>::Vec scale_backprop(scale_backprop_output->vec<T>());
     typename TTypes<T>::Vec offset_backprop(offset_backprop_output->vec<T>());
 
@@ -258,8 +258,8 @@ struct FusedBatchNorm<GPUDevice, T, U> {
                                   &x_transformed));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
           context->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(x_maybe_transformed).tensor<T, 4>(),
-          x_transformed.tensor<T, 4>());
+          const_cast<const Tensor&>(x_maybe_transformed).template tensor<T, 4>(),
+          x_transformed.template tensor<T, 4>());
       x_maybe_transformed = x_transformed;
 
       OP_REQUIRES_OK(context, context->allocate_temp(
@@ -348,8 +348,8 @@ struct FusedBatchNorm<GPUDevice, T, U> {
     if (tensor_format == FORMAT_NHWC) {
       functor::NCHWToNHWC<GPUDevice, T, 4>()(
           context->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(y_transformed).tensor<T, 4>(),
-          y->tensor<T, 4>());
+          const_cast<const Tensor&>(y_transformed).template tensor<T, 4>(),
+          y->template tensor<T, 4>());
     }
   }
 };
@@ -399,8 +399,8 @@ struct FusedBatchNormGrad<GPUDevice, T, U> {
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
           context->eigen_device<GPUDevice>(),
           const_cast<const Tensor&>(y_backprop_maybe_transformed)
-              .tensor<T, 4>(),
-          y_backprop_transformed.tensor<T, 4>());
+              .template tensor<T, 4>(),
+          y_backprop_transformed.template tensor<T, 4>());
       y_backprop_maybe_transformed = y_backprop_transformed;
 
       OP_REQUIRES_OK(context, context->allocate_temp(
@@ -410,8 +410,8 @@ struct FusedBatchNormGrad<GPUDevice, T, U> {
                                   &x_transformed));
       functor::NHWCToNCHW<GPUDevice, T, 4>()(
           context->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(x_maybe_transformed).tensor<T, 4>(),
-          x_transformed.tensor<T, 4>());
+          const_cast<const Tensor&>(x_maybe_transformed).template tensor<T, 4>(),
+          x_transformed.template tensor<T, 4>());
       x_maybe_transformed = x_transformed;
 
       // Allocate memory for transformed outputs in 'NCHW'
@@ -471,8 +471,8 @@ struct FusedBatchNormGrad<GPUDevice, T, U> {
     if (tensor_format == FORMAT_NHWC) {
       functor::NCHWToNHWC<GPUDevice, T, 4>()(
           context->eigen_device<GPUDevice>(),
-          const_cast<const Tensor&>(x_backprop_transformed).tensor<T, 4>(),
-          x_backprop->tensor<T, 4>());
+          const_cast<const Tensor&>(x_backprop_transformed).template tensor<T, 4>(),
+          x_backprop->template tensor<T, 4>());
     }
   }
 };
diff --git a/tensorflow/core/kernels/fused_batch_norm_op.h b/tensorflow/core/kernels/fused_batch_norm_op.h
index 38b24d701..64fdfc061 100644
--- a/tensorflow/core/kernels/fused_batch_norm_op.h
+++ b/tensorflow/core/kernels/fused_batch_norm_op.h
@@ -64,12 +64,12 @@ struct FusedBatchNormFreezeGrad {
                   typename TTypes<U>::Vec scratch1,
                   typename TTypes<U>::Vec scratch2) {
     typename TTypes<T, 4>::ConstTensor y_backprop(
-        y_backprop_input.tensor<T, 4>());
-    typename TTypes<T, 4>::ConstTensor input(x_input.tensor<T, 4>());
+        y_backprop_input.template tensor<T, 4>());
+    typename TTypes<T, 4>::ConstTensor input(x_input.template tensor<T, 4>());
     typename TTypes<U>::ConstVec scale(scale_input.vec<U>());
     typename TTypes<U>::ConstVec pop_mean(pop_mean_input.vec<U>());
     typename TTypes<U>::ConstVec pop_var(pop_variance_input.vec<U>());
-    typename TTypes<T, 4>::Tensor x_backprop(x_backprop_output->tensor<T, 4>());
+    typename TTypes<T, 4>::Tensor x_backprop(x_backprop_output->template tensor<T, 4>());
     typename TTypes<U>::Vec scale_backprop(scale_backprop_output->vec<U>());
     typename TTypes<U>::Vec offset_backprop(offset_backprop_output->vec<U>());
 
diff --git a/tensorflow/core/kernels/gather_op.cc b/tensorflow/core/kernels/gather_op.cc
index e649c54fa..0b802f69b 100644
--- a/tensorflow/core/kernels/gather_op.cc
+++ b/tensorflow/core/kernels/gather_op.cc
@@ -101,7 +101,7 @@ class GatherOp : public OpKernel {
     OP_REQUIRES_OK(c, c->allocate_output(0, result_shape, &out));
     if (N > 0 && outer_size > 0 && inner_size > 0) {
       auto params_flat =
-          params.shaped<T, 3>({outer_size, gather_dim_size, inner_size});
+          params.template shaped<T, 3>({outer_size, gather_dim_size, inner_size});
       auto indices_flat = indices.flat<Index>();
       auto out_flat = out->shaped<T, 3>({outer_size, N, inner_size});
 
diff --git a/tensorflow/core/kernels/inplace_ops.cc b/tensorflow/core/kernels/inplace_ops.cc
index 01ae5a83c..176816704 100644
--- a/tensorflow/core/kernels/inplace_ops.cc
+++ b/tensorflow/core/kernels/inplace_ops.cc
@@ -34,7 +34,7 @@ namespace functor {
 template <typename Device, typename T>
 Status DoParallelConcatUpdate(const Device& d, const Tensor& value,
                               int32 loc, Tensor* output) {
-  auto Tvalue = value.shaped<T, 2>({1, value.NumElements()});
+  auto Tvalue = value.template shaped<T, 2>({1, value.NumElements()});
   auto Toutput = output->flat_outer_dims<T>();
   auto nrows = Toutput.dimension(0);
   auto r = (loc % nrows + nrows) % nrows;  // Guard index range.
diff --git a/tensorflow/core/kernels/lookup_table_op.cc b/tensorflow/core/kernels/lookup_table_op.cc
index e774c771b..39c4ea88e 100644
--- a/tensorflow/core/kernels/lookup_table_op.cc
+++ b/tensorflow/core/kernels/lookup_table_op.cc
@@ -352,7 +352,7 @@ class MutableDenseHashTable final : public LookupInterface {
                                      expected_shape.DebugString(), " got ",
                                      key.shape().DebugString());
     }
-    const auto key_matrix = key.shaped<K, 2>({num_elements, key_size});
+    const auto key_matrix = key.template shaped<K, 2>({num_elements, key_size});
     auto value_matrix = value->shaped<V, 2>({num_elements, value_size});
     const auto default_flat = default_value.flat<V>();
 
@@ -505,8 +505,8 @@ class MutableDenseHashTable final : public LookupInterface {
     const int64 num_elements = key.dim_size(0);
     const int64 value_size = value_shape_.num_elements();
     const int64 key_size = key_shape_.num_elements();
-    const auto key_matrix = key.shaped<K, 2>({num_elements, key_size});
-    auto value_matrix = value.shaped<V, 2>({num_elements, value_size});
+    const auto key_matrix = key.template shaped<K, 2>({num_elements, key_size});
+    auto value_matrix = value.template shaped<V, 2>({num_elements, value_size});
 
     auto key_buckets_matrix =
         key_buckets_.AccessTensor(ctx)->template matrix<K>();
diff --git a/tensorflow/core/kernels/lrn_op.cc b/tensorflow/core/kernels/lrn_op.cc
index c905ebc84..a492cf83a 100644
--- a/tensorflow/core/kernels/lrn_op.cc
+++ b/tensorflow/core/kernels/lrn_op.cc
@@ -90,7 +90,7 @@ struct LaunchLRN<CPUDevice, T> {
       return;
     }
 
-    auto in_shaped = in.shaped<T, 2>({nodes * batch, depth});
+    auto in_shaped = in.template shaped<T, 2>({nodes * batch, depth});
 
     // Multiplying the input with the band matrix has the effect of reducing the
     // correct patch along the depth.
@@ -316,9 +316,9 @@ struct LaunchLRNGrad<CPUDevice, T> {
     const int64 cols = in_grads.dim_size(2);
     const int64 depth = in_grads.dim_size(3);
     const auto nodes = cols * rows;
-    auto grads_shaped = in_grads.shaped<T, 2>({nodes * batch, depth});
-    auto in_shaped = in_image.shaped<T, 2>({nodes * batch, depth});
-    auto activations = out_image.shaped<T, 2>({nodes * batch, depth});
+    auto grads_shaped = in_grads.template shaped<T, 2>({nodes * batch, depth});
+    auto in_shaped = in_image.template shaped<T, 2>({nodes * batch, depth});
+    auto activations = out_image.template shaped<T, 2>({nodes * batch, depth});
 
     auto out_shaped = output->shaped<T, 2>({nodes * batch, depth});
     out_shaped.setZero();
diff --git a/tensorflow/core/kernels/lrn_op_test.cc b/tensorflow/core/kernels/lrn_op_test.cc
index 9c8a1dfa9..c8a6106b0 100644
--- a/tensorflow/core/kernels/lrn_op_test.cc
+++ b/tensorflow/core/kernels/lrn_op_test.cc
@@ -65,7 +65,7 @@ class LRNFloatTest : public OpsTestBase {
     Eigen::Tensor<float, 4, Eigen::RowMajor> expected(batch_size, rows, cols,
                                                       depth);
     auto out = expected.reshape(Eigen::DSizes<int64, 2>{rest, depth});
-    auto in = input.shaped<float, 2>({rest, depth});
+    auto in = input.template shaped<float, 2>({rest, depth});
 
     for (int64 i = 0; i < rest; ++i) {
       Eigen::Tensor<float, 1, Eigen::RowMajor> out_col(depth);
@@ -80,7 +80,7 @@ class LRNFloatTest : public OpsTestBase {
       }
       out.chip<0>(i) = out_col;
     }
-    auto actual = GetOutput(0)->tensor<float, 4>();
+    auto actual = GetOutput(0)->template tensor<float, 4>();
     Eigen::Tensor<float, 0, Eigen::RowMajor> sum =
         ((expected - actual).abs() > actual.constant(tol_))
             .select(actual.constant(1), actual.constant(0))
@@ -104,7 +104,7 @@ TEST_F(LRNFloatTest, Depth96) {
   AddInput<float>(TensorShape({1, 1, 1, 96}),
                   [this](int i) -> float { return i + 1; });
   TF_ASSERT_OK(RunOpKernel());
-  auto actual = GetOutput(0)->tensor<float, 4>();
+  auto actual = GetOutput(0)->template tensor<float, 4>();
 
   // Output for Node 0 with Value 1:
   // 1 / (1 + 0.1*(1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2))^2
@@ -140,7 +140,7 @@ TEST_F(LRNFloatTest, Depth16) {
   AddInput<float>(TensorShape({1, 1, 1, 16}),
                   [this](int i) -> float { return i + 1; });
   TF_ASSERT_OK(RunOpKernel());
-  auto actual = GetOutput(0)->tensor<float, 4>();
+  auto actual = GetOutput(0)->template tensor<float, 4>();
 
   // Output for Node 0 with Value 1:
   // 1 / (1 + 0.1*(1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2))^2
diff --git a/tensorflow/core/kernels/mirror_pad_op.cc b/tensorflow/core/kernels/mirror_pad_op.cc
index e3643f944..b40200dac 100644
--- a/tensorflow/core/kernels/mirror_pad_op.cc
+++ b/tensorflow/core/kernels/mirror_pad_op.cc
@@ -122,8 +122,8 @@ class MirrorPadOp : public OpKernel {
 #define MIRROR_PAD_CASE(i)                                                \
   case i: {                                                               \
     functor::MirrorPad<Device, T, i>()(                                   \
-        context->eigen_device<Device>(), To32Bit(output->tensor<T, i>()), \
-        To32Bit(in0.tensor<T, i>()), paddings, offset_);                  \
+        context->eigen_device<Device>(), To32Bit(output->template tensor<T, i>()), \
+        To32Bit(in0.template tensor<T, i>()), paddings, offset_);                  \
     break;                                                                \
   }
 
@@ -309,9 +309,9 @@ class MirrorPadGradOp : public OpKernel {
 #define MIRROR_PAD_GRAD_CASE(k)                                           \
   case k: {                                                               \
     functor::MirrorPadGrad<Device, T, k>()(                               \
-        context->eigen_device<Device>(), To32Bit(output->tensor<T, k>()), \
-        To32Bit(in0.tensor<T, k>()), paddings, offset_,                   \
-        To32Bit(scratch.tensor<T, k>()));                                 \
+        context->eigen_device<Device>(), To32Bit(output->template tensor<T, k>()), \
+        To32Bit(in0.template tensor<T, k>()), paddings, offset_,                   \
+        To32Bit(scratch.template tensor<T, k>()));                                 \
     break;                                                                \
   }
 
diff --git a/tensorflow/core/kernels/mkl_concat_op.cc b/tensorflow/core/kernels/mkl_concat_op.cc
index e6673b2ff..34974354b 100644
--- a/tensorflow/core/kernels/mkl_concat_op.cc
+++ b/tensorflow/core/kernels/mkl_concat_op.cc
@@ -118,7 +118,7 @@ class EigenConcatBaseOp : public OpKernel {
       if (in.NumElements() > 0) {
         int64 inputs_flat_dim1 = in.NumElements() / inputs_flat_dim0;
         inputs_flat.emplace_back(new typename TTypes<T, 2>::ConstMatrix(
-            in.shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
+            in.template shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
       }
       // TODO(irving): Remove check once !allow_legacy_scalars().
       output_concat_dim += in.dims() > 0 ? in.dim_size(axis) : 1;
diff --git a/tensorflow/core/kernels/mkl_lrn_op.cc b/tensorflow/core/kernels/mkl_lrn_op.cc
index aa08e9392..ac704f5e5 100644
--- a/tensorflow/core/kernels/mkl_lrn_op.cc
+++ b/tensorflow/core/kernels/mkl_lrn_op.cc
@@ -276,7 +276,7 @@ class MklLRNOp : public OpKernel {
       const int depth = static_cast<int>(input.dim_size(3));
       const int nodes = cols * rows;
 
-      auto in_shaped = input.shaped<T, 2>({nodes * batch, depth});
+      auto in_shaped = input.template shaped<T, 2>({nodes * batch, depth});
       // Multiplying the input with the band matrix has the effect of reducing
       // the
       // correct patch along the depth.
@@ -647,9 +647,9 @@ class MklLRNGradOp : public OpKernel {
       const int64 depth = static_cast<int64>(in_grads.dim_size(3));
       const auto nodes = cols * rows;
 
-      auto grads_shaped = in_grads.shaped<T, 2>({nodes * batch, depth});
-      auto in_shaped = in_image.shaped<T, 2>({nodes * batch, depth});
-      auto activations = out_image.shaped<T, 2>({nodes * batch, depth});
+      auto grads_shaped = in_grads.template shaped<T, 2>({nodes * batch, depth});
+      auto in_shaped = in_image.template shaped<T, 2>({nodes * batch, depth});
+      auto activations = out_image.template shaped<T, 2>({nodes * batch, depth});
 
       Tensor* output;
       MklShape mkl_output_mkl_shape;
diff --git a/tensorflow/core/kernels/mkl_transpose_op.cc b/tensorflow/core/kernels/mkl_transpose_op.cc
index 50d25ac51..f14f9f647 100644
--- a/tensorflow/core/kernels/mkl_transpose_op.cc
+++ b/tensorflow/core/kernels/mkl_transpose_op.cc
@@ -31,8 +31,8 @@ namespace tensorflow {
 // Specifically, the returned tensor output meets the following condition:
 // 1) output.dims() == input.dims();
 // 2) output.dim_size(i) == input.dim_size(perm[i]);
-// 3) output.tensor<T, N>(i_0, i_1, ..., i_N-1) ==
-//      input.tensor<T, N>(j_0, j_1, ..., j_N-1),
+// 3) output.template tensor<T, N>(i_0, i_1, ..., i_N-1) ==
+//      input.template tensor<T, N>(j_0, j_1, ..., j_N-1),
 //    where i_s == j_{perm[s]}
 //
 // REQUIRES: perm is a vector of int32.
diff --git a/tensorflow/core/kernels/non_max_suppression_op.cc b/tensorflow/core/kernels/non_max_suppression_op.cc
index 64bdef000..9cf7996c6 100644
--- a/tensorflow/core/kernels/non_max_suppression_op.cc
+++ b/tensorflow/core/kernels/non_max_suppression_op.cc
@@ -109,7 +109,7 @@ void DoNonMaxSuppressionOp(OpKernelContext* context,
   const int output_size =
       std::min(max_output_size.scalar<int>()(), num_boxes);
   typename TTypes<float, 2>::ConstTensor boxes_data =
-      boxes.tensor<float, 2>();
+      boxes.template tensor<float, 2>();
 
   std::vector<float> scores_data(num_boxes);
   std::copy_n(scores.flat<float>().data(), num_boxes, scores_data.begin());
@@ -143,7 +143,7 @@ void DoNonMaxSuppressionOp(OpKernelContext* context,
   TensorShape output_shape({static_cast<int>(selected.size())});
   OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));
   typename TTypes<int, 1>::Tensor selected_indices_data =
-      output->tensor<int, 1>();
+      output->template tensor<int, 1>();
   std::copy_n(selected.begin(), selected.size(), selected_indices_data.data());
 }
 
diff --git a/tensorflow/core/kernels/one_hot_op.cc b/tensorflow/core/kernels/one_hot_op.cc
index c66a812cd..a95f545ea 100644
--- a/tensorflow/core/kernels/one_hot_op.cc
+++ b/tensorflow/core/kernels/one_hot_op.cc
@@ -107,7 +107,7 @@ class OneHotOp : public OpKernel {
 
       // Split indices into matrix of size prefix_dim_size x suffix_dim_size
       auto indices_t =
-          indices.shaped<TI, 2>({prefix_dim_size, suffix_dim_size});
+          indices.template shaped<TI, 2>({prefix_dim_size, suffix_dim_size});
       // Split output into 3-Tensor of size:
       //   prefix_dim_size x depth x suffix_dim_size.
       auto output_t =
diff --git a/tensorflow/core/kernels/pack_op.cc b/tensorflow/core/kernels/pack_op.cc
index 814128d99..15ae5e995 100644
--- a/tensorflow/core/kernels/pack_op.cc
+++ b/tensorflow/core/kernels/pack_op.cc
@@ -110,7 +110,7 @@ class PackOp : public OpKernel {
       inputs_flat.reserve(num);
       for (int i = 0; i < num; ++i) {
         inputs_flat.emplace_back(new typename TTypes<T, 2>::ConstMatrix(
-            values[i].shaped<T, 2>({before_dim, after_dim})));
+            values[i].template shaped<T, 2>({before_dim, after_dim})));
       }
 #if GOOGLE_CUDA
       if (std::is_same<Device, GPUDevice>::value) {
diff --git a/tensorflow/core/kernels/pad_op.cc b/tensorflow/core/kernels/pad_op.cc
index 6196c5ed9..255fba014 100644
--- a/tensorflow/core/kernels/pad_op.cc
+++ b/tensorflow/core/kernels/pad_op.cc
@@ -109,7 +109,7 @@ class PadOp : public OpKernel {
     // Invoke the dims-specific implementation.
     switch (fixed_dims) {
       case 0:
-        Operate<0>(context, in0.tensor<T, 0>(), paddings, pad_value, output);
+        Operate<0>(context, in0.template tensor<T, 0>(), paddings, pad_value, output);
         break;
       case 1:
         // TODO(irving): Once Pad doesn't need a scalar special case,
@@ -117,19 +117,19 @@ class PadOp : public OpKernel {
         Operate<1>(context, in0.flat<T>(), paddings, pad_value, output);
         break;
       case 2:
-        Operate<2>(context, in0.tensor<T, 2>(), paddings, pad_value, output);
+        Operate<2>(context, in0.template tensor<T, 2>(), paddings, pad_value, output);
         break;
       case 3:
-        Operate<3>(context, in0.tensor<T, 3>(), paddings, pad_value, output);
+        Operate<3>(context, in0.template tensor<T, 3>(), paddings, pad_value, output);
         break;
       case 4:
-        Operate<4>(context, in0.tensor<T, 4>(), paddings, pad_value, output);
+        Operate<4>(context, in0.template tensor<T, 4>(), paddings, pad_value, output);
         break;
       case 5:
-        Operate<5>(context, in0.tensor<T, 5>(), paddings, pad_value, output);
+        Operate<5>(context, in0.template tensor<T, 5>(), paddings, pad_value, output);
         break;
       case 6:
-        Operate<6>(context, in0.tensor<T, 6>(), paddings, pad_value, output);
+        Operate<6>(context, in0.template tensor<T, 6>(), paddings, pad_value, output);
         break;
       default:
         OP_REQUIRES(context, false,
@@ -151,7 +151,7 @@ class PadOp : public OpKernel {
       paddings_array[i] = {paddings(i, 0), paddings(i, 1)};
     }
     functor::Pad<Device, T, Dims> functor;
-    functor(context->eigen_device<Device>(), output->tensor<T, Dims>(), input,
+    functor(context->eigen_device<Device>(), output->template tensor<T, Dims>(), input,
             paddings_array, pad_value);
   }
 };
diff --git a/tensorflow/core/kernels/padded_batch_dataset_op.cc b/tensorflow/core/kernels/padded_batch_dataset_op.cc
index 7737f57b6..565bb5777 100644
--- a/tensorflow/core/kernels/padded_batch_dataset_op.cc
+++ b/tensorflow/core/kernels/padded_batch_dataset_op.cc
@@ -49,8 +49,8 @@ Status HandleElementToLargerSlice(const Tensor& element, Tensor* parent,
   if (element.NumElements() == 0) {
     return Status::OK();
   }
-  auto element_t = element.tensor<T, NDIMS>();
-  auto parent_t = parent->tensor<T, NDIMS + 1>();
+  auto element_t = element.template tensor<T, NDIMS>();
+  auto parent_t = parent->template tensor<T, NDIMS + 1>();
   Eigen::DSizes<Eigen::DenseIndex, NDIMS + 1> slice_indices;
   slice_indices[0] = index;
   Eigen::DSizes<Eigen::DenseIndex, NDIMS + 1> slice_size;
diff --git a/tensorflow/core/kernels/padding_fifo_queue.cc b/tensorflow/core/kernels/padding_fifo_queue.cc
index d0f7683f3..d31a56c75 100644
--- a/tensorflow/core/kernels/padding_fifo_queue.cc
+++ b/tensorflow/core/kernels/padding_fifo_queue.cc
@@ -315,8 +315,8 @@ Status HandleElementToLargerSlice(const Tensor& element, Tensor* parent,
   if (element.NumElements() == 0) {
     return Status::OK();
   }
-  auto element_t = element.tensor<T, NDIMS>();
-  auto parent_t = parent->tensor<T, NDIMS + 1>();
+  auto element_t = element.template tensor<T, NDIMS>();
+  auto parent_t = parent->template tensor<T, NDIMS + 1>();
   Eigen::DSizes<Eigen::DenseIndex, NDIMS + 1> slice_indices;
   slice_indices[0] = index;
   Eigen::DSizes<Eigen::DenseIndex, NDIMS + 1> slice_size;
diff --git a/tensorflow/core/kernels/pooling_ops_3d.cc b/tensorflow/core/kernels/pooling_ops_3d.cc
index a40631721..59bb137b8 100644
--- a/tensorflow/core/kernels/pooling_ops_3d.cc
+++ b/tensorflow/core/kernels/pooling_ops_3d.cc
@@ -105,8 +105,8 @@ struct LaunchPoolingOp<CPUDevice, T, AVG> {
                      const std::array<int64, 3>& padding,
                      TensorFormat data_format, Padding padding_type,
                      Tensor* output) {
-    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =
-        Eigen::CuboidAvgPooling(tensor_in.tensor<T, 5>(), window[0], window[1],
+    output->template tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =
+        Eigen::CuboidAvgPooling(tensor_in.template tensor<T, 5>(), window[0], window[1],
                                 window[2], stride[0], stride[1], stride[2],
                                 BrainPadding2EigenPadding(padding_type));
   }
@@ -120,8 +120,8 @@ struct LaunchPoolingOp<CPUDevice, T, MAX> {
                      const std::array<int64, 3>& padding,
                      TensorFormat data_format, Padding padding_type,
                      Tensor* output) {
-    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =
-        Eigen::CuboidMaxPooling(tensor_in.tensor<T, 5>(), window[0], window[1],
+    output->template tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =
+        Eigen::CuboidMaxPooling(tensor_in.template tensor<T, 5>(), window[0], window[1],
                                 window[2], stride[0], stride[1], stride[2],
                                 BrainPadding2EigenPadding(padding_type));
   }
@@ -268,17 +268,17 @@ struct LaunchMaxPooling3dGradOp<CPUDevice, T> {
           // Slice from tensor_in.
           Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_in_slice(dst_sizes);
           tensor_in_slice.device(context->eigen_cpu_device()) =
-              tensor_in.tensor<T, 5>().slice(dst_indices, dst_sizes);
+              tensor_in.template tensor<T, 5>().slice(dst_indices, dst_sizes);
 
           // Slice from tensor_out.
           Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_out_slice(src_sizes);
           tensor_out_slice.device(context->eigen_cpu_device()) =
-              tensor_out.tensor<T, 5>().slice(src_indices, src_sizes);
+              tensor_out.template tensor<T, 5>().slice(src_indices, src_sizes);
 
           // Backprop slice.
           Eigen::Tensor<T, 5, Eigen::RowMajor> out_backprop_slice(src_sizes);
           out_backprop_slice.device(context->eigen_cpu_device()) =
-              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);
+              out_backprop.template tensor<T, 5>().slice(src_indices, src_sizes);
 
           // The true backprop slice: if an element is the max, choose
           // the backprop slice; otherwise set to 0.
@@ -290,7 +290,7 @@ struct LaunchMaxPooling3dGradOp<CPUDevice, T> {
                tensor_in_slice.constant(1e-5))
                   .select(out_backprop_slice.broadcast(bcast), mat0);
 
-          output->tensor<T, 5>()
+          output->template tensor<T, 5>()
               .slice(dst_indices, dst_sizes)
               .device(context->eigen_cpu_device()) += select_slice;
         }
@@ -439,12 +439,12 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {
 #endif
           Eigen::Tensor<T, 5, Eigen::RowMajor> slices(src_sizes);
           slices.device(context->eigen_cpu_device()) =
-              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);
+              out_backprop.template tensor<T, 5>().slice(src_indices, src_sizes);
           // Divide by the size of the actual patch (psize * rsize * csize).
           float divide_size = rsize * csize * psize * 1.0f;
           slices *= slices.constant(1.0f / divide_size);
 
-          output->tensor<T, 5>()
+          output->template tensor<T, 5>()
               .slice(dst_indices, dst_sizes)
               .device(context->eigen_cpu_device()) += slices.broadcast(bcast);
         }
diff --git a/tensorflow/core/kernels/pooling_ops_common.cc b/tensorflow/core/kernels/pooling_ops_common.cc
index 7dee751c4..527e58694 100644
--- a/tensorflow/core/kernels/pooling_ops_common.cc
+++ b/tensorflow/core/kernels/pooling_ops_common.cc
@@ -164,8 +164,8 @@ void DnnPoolingOp<T>::Compute(
                                                 data_format),
                                 &transformed_input));
     functor::NHWCToNCHW<GPUDevice, T, 4>()(context->eigen_device<Device>(),
-                                           tensor_in.tensor<T, 4>(),
-                                           transformed_input.tensor<T, 4>());
+                                           tensor_in.template tensor<T, 4>(),
+                                           transformed_input.template tensor<T, 4>());
   } else {
     transformed_input = tensor_in;
   }
@@ -226,7 +226,7 @@ void DnnPoolingOp<T>::Compute(
     functor::NCHWToNHWC<GPUDevice, T, 4>()(
         context->eigen_device<Device>(),
         toConstTensor(transformed_output).template tensor<T, 4>(),
-        tensor_out->tensor<T, 4>());
+        tensor_out->template tensor<T, 4>());
   }
 }
 
@@ -303,20 +303,20 @@ void DnnPoolingGradOp<T>::Compute(
       // cudnn still requires them to run, although they do not affect the
       // results.
       functor::NHWCToNCHW<GPUDevice, T, 4>()(context->eigen_device<Device>(),
-                                             tensor_in->tensor<T, 4>(),
-                                             transformed_input.tensor<T, 4>());
+                                             tensor_in->template tensor<T, 4>(),
+                                             transformed_input.template tensor<T, 4>());
     }
     if (tensor_out) {
       // For AvgPoolGrad, the original output tensor is not necessary. However,
       // cudnn still requires them to run, although they do not affect the
       // results.
       functor::NHWCToNCHW<GPUDevice, T, 4>()(context->eigen_device<Device>(),
-                                             tensor_out->tensor<T, 4>(),
-                                             transformed_output.tensor<T, 4>());
+                                             tensor_out->template tensor<T, 4>(),
+                                             transformed_output.template tensor<T, 4>());
     }
     functor::NHWCToNCHW<GPUDevice, T, 4>()(
-        context->eigen_device<Device>(), out_backprop.tensor<T, 4>(),
-        transformed_output_backprop.tensor<T, 4>());
+        context->eigen_device<Device>(), out_backprop.template tensor<T, 4>(),
+        transformed_output_backprop.template tensor<T, 4>());
   }
 
   /// Get ready to call cudnn
@@ -374,7 +374,7 @@ void DnnPoolingGradOp<T>::Compute(
     functor::NCHWToNHWC<GPUDevice, T, 4>()(
         context->eigen_device<Device>(),
         toConstTensor(transformed_input_backprop).template tensor<T, 4>(),
-        input_backprop->tensor<T, 4>());
+        input_backprop->template tensor<T, 4>());
   }
 }
 
diff --git a/tensorflow/core/kernels/pooling_ops_common.h b/tensorflow/core/kernels/pooling_ops_common.h
index 75a6fc371..51d9bd8f6 100644
--- a/tensorflow/core/kernels/pooling_ops_common.h
+++ b/tensorflow/core/kernels/pooling_ops_common.h
@@ -162,8 +162,8 @@ class MaxPoolingOp : public OpKernel {
     if (std::is_same<Device, GPUDevice>::value) {
       Eigen::PaddingType pt = BrainPadding2EigenPadding(padding);
       functor::SpatialMaxPooling<Device, T>()(
-          context->eigen_device<Device>(), output->tensor<T, 4>(),
-          tensor_in.tensor<T, 4>(), params.window_rows, params.window_cols,
+          context->eigen_device<Device>(), output->template tensor<T, 4>(),
+          tensor_in.template tensor<T, 4>(), params.window_rows, params.window_cols,
           params.row_stride, params.col_stride, pt);
     } else {
       typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>
@@ -407,8 +407,8 @@ class MaxPoolingV2Op : public OpKernel {
             context, params, tensor_in, output);
       } else {
         functor::SpatialMaxPooling<Device, T>()(
-            context->eigen_device<Device>(), output->tensor<T, 4>(),
-            tensor_in.tensor<T, 4>(), params.window_rows, params.window_cols,
+            context->eigen_device<Device>(), output->template tensor<T, 4>(),
+            tensor_in.template tensor<T, 4>(), params.window_rows, params.window_cols,
             params.row_stride, params.col_stride, pt);
       }
     } else
diff --git a/tensorflow/core/kernels/quantized_batch_norm_op_test.cc b/tensorflow/core/kernels/quantized_batch_norm_op_test.cc
index 78e4fb861..a02ffc60a 100644
--- a/tensorflow/core/kernels/quantized_batch_norm_op_test.cc
+++ b/tensorflow/core/kernels/quantized_batch_norm_op_test.cc
@@ -226,10 +226,10 @@ TEST_F(QuantizedBatchNormOpTest, SameAsFloat) {
   const Tensor& const_beta_float = beta_float;
   const Tensor& const_gamma_float = gamma_float;
   functor::BatchNorm<Eigen::ThreadPoolDevice, float>()(
-      eigen_cpu_device, const_input_float.tensor<float, 4>(),
+      eigen_cpu_device, const_input_float.template tensor<float, 4>(),
       const_mean_float.vec<float>(), const_variance_float.vec<float>(),
       const_beta_float.vec<float>(), const_gamma_float.vec<float>(), 0.001,
-      false, expected_float.tensor<float, 4>());
+      false, expected_float.template tensor<float, 4>());
 
   const Tensor& output_quantized = *GetOutput(0);
   const float output_min = GetOutput(1)->flat<float>()(0);
diff --git a/tensorflow/core/kernels/quantized_concat_op.cc b/tensorflow/core/kernels/quantized_concat_op.cc
index ee573f1bb..5842eaa0e 100644
--- a/tensorflow/core/kernels/quantized_concat_op.cc
+++ b/tensorflow/core/kernels/quantized_concat_op.cc
@@ -151,7 +151,7 @@ class QuantizedConcatOp : public OpKernel {
       if (in.NumElements() > 0) {
         int64 inputs_flat_dim1 = in.NumElements() / inputs_flat_dim0;
         inputs_flat->emplace_back(new typename TTypes<T, 2>::ConstMatrix(
-            in.shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
+            in.template shaped<T, 2>({inputs_flat_dim0, inputs_flat_dim1})));
       }
       *output_concat_dim += in.dims() > 0 ? in.dim_size(concat_dim) : 1;
     }
diff --git a/tensorflow/core/kernels/quantized_instance_norm.cc b/tensorflow/core/kernels/quantized_instance_norm.cc
index c29f534f3..21601b0e0 100644
--- a/tensorflow/core/kernels/quantized_instance_norm.cc
+++ b/tensorflow/core/kernels/quantized_instance_norm.cc
@@ -283,7 +283,7 @@ class QuantizedInstanceNorm : public OpKernel {
         errors::InvalidArgument("input_min must be less than input_max : ",
                                 input_min, " >= ", input_max));
 
-    auto input_tensor = input.tensor<quint8, 4>();
+    auto input_tensor = input.template tensor<quint8, 4>();
     auto N = input_tensor.dimension(0);
     auto H = input_tensor.dimension(1);
     auto W = input_tensor.dimension(2);
@@ -385,7 +385,7 @@ class QuantizedInstanceNorm : public OpKernel {
       auto instance_normed_quantized =
           QUANTIZE_WITH_EIGEN(instance_normed, output_f2q, quint8);
 
-      output->tensor<quint8, 4>().device(
+      output->template tensor<quint8, 4>().device(
           context->template eigen_device<CPUDevice>()) =
           instance_normed_quantized;
       output_min->flat<float>()(0) = normed_min();
diff --git a/tensorflow/core/kernels/quantized_resize_bilinear_op.cc b/tensorflow/core/kernels/quantized_resize_bilinear_op.cc
index fb2faede2..97285d8ec 100644
--- a/tensorflow/core/kernels/quantized_resize_bilinear_op.cc
+++ b/tensorflow/core/kernels/quantized_resize_bilinear_op.cc
@@ -697,8 +697,8 @@ class QuantizedResizeBilinearOp : public OpKernel {
     // Return if the output is empty.
     if (st.output->NumElements() == 0) return;
 
-    typename TTypes<T, 4>::ConstTensor image_data = input.tensor<T, 4>();
-    typename TTypes<T, 4>::Tensor output_data = st.output->tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor image_data = input.template tensor<T, 4>();
+    typename TTypes<T, 4>::Tensor output_data = st.output->template tensor<T, 4>();
 
     ResizeBilinear<T>(image_data, st.height_scale, st.width_scale, in_min,
                       in_max, &output_data);
diff --git a/tensorflow/core/kernels/random_crop_op.cc b/tensorflow/core/kernels/random_crop_op.cc
index ba94d6be5..ea69026ec 100644
--- a/tensorflow/core/kernels/random_crop_op.cc
+++ b/tensorflow/core/kernels/random_crop_op.cc
@@ -92,8 +92,8 @@ class RandomCropOp : public OpKernel {
 
     // TODO(shlens): Do this more efficiently with memcpy once padding is
     // available for smaller images.
-    typename TTypes<T, 3>::ConstTensor input_data = input.tensor<T, 3>();
-    typename TTypes<T, 3>::Tensor output_data = output->tensor<T, 3>();
+    typename TTypes<T, 3>::ConstTensor input_data = input.template tensor<T, 3>();
+    typename TTypes<T, 3>::Tensor output_data = output->template tensor<T, 3>();
 
     for (int y = 0; y < target_height; ++y) {
       for (int x = 0; x < target_width; ++x) {
diff --git a/tensorflow/core/kernels/reduction_ops_common.h b/tensorflow/core/kernels/reduction_ops_common.h
index 71af9d88d..e11479374 100644
--- a/tensorflow/core/kernels/reduction_ops_common.h
+++ b/tensorflow/core/kernels/reduction_ops_common.h
@@ -106,7 +106,7 @@ class ReductionHelper {
   // The input is reshaped.
   template <typename T, int N>
   typename TTypes<T, N>::ConstTensor in(const Tensor& data) {
-    return data.shaped<T, N>(data_reshape_);
+    return data.template shaped<T, N>(data_reshape_);
   }
 
   // Shape of shuffled input
@@ -224,7 +224,7 @@ class ReductionOp : public OpKernel {
       const int64 reduced = shuffled.NumElements() / unreduced;
       const Tensor& const_shuffled = shuffled;
       Functor::Reduce(ctx, tmp_out.flat<T>(),
-                      const_shuffled.shaped<T, 2>({unreduced, reduced}),
+                      const_shuffled.template shaped<T, 2>({unreduced, reduced}),
                       constants.kOne, reducer);
     }
 
diff --git a/tensorflow/core/kernels/resize_area_op.cc b/tensorflow/core/kernels/resize_area_op.cc
index ada50dfb7..46fbb0b41 100644
--- a/tensorflow/core/kernels/resize_area_op.cc
+++ b/tensorflow/core/kernels/resize_area_op.cc
@@ -149,7 +149,7 @@ class ResizeAreaOp : public OpKernel {
 
     if (!context->status().ok()) return;
 
-    typename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor input_data = input.template tensor<T, 4>();
 
     // Precompute values used when iterating over x coordinates within a row.
     // Note that it may be useful to cache x_interps for a given
@@ -191,7 +191,7 @@ class ResizeAreaOp : public OpKernel {
                    const std::vector<CachedInterpolation>& x_interps,
                    typename TTypes<T, 4>::ConstTensor input_data) {
     typename TTypes<float, 4>::Tensor output_data =
-        st.output->tensor<float, 4>();
+        st.output->template tensor<float, 4>();
 
     // When using this algorithm for downsizing, the target pixel value is the
     // weighted average of all the source pixels. The weight is determined by
diff --git a/tensorflow/core/kernels/resize_area_op_test.cc b/tensorflow/core/kernels/resize_area_op_test.cc
index cc5244d3a..c2bdea8c7 100644
--- a/tensorflow/core/kernels/resize_area_op_test.cc
+++ b/tensorflow/core/kernels/resize_area_op_test.cc
@@ -153,7 +153,7 @@ class ResizeAreaOpTest : public OpsTestBase {
         new Tensor(device_->GetAllocator(AllocatorAttributes()),
                    DataTypeToEnum<float>::v(),
                    TensorShape({1, target_height, target_width, channels})));
-    ResizeAreaBaseline(input->tensor<float, 4>(), expected->tensor<float, 4>());
+    ResizeAreaBaseline(input->template tensor<float, 4>(), expected->template tensor<float, 4>());
     test::ExpectTensorNear<float>(*expected, *GetOutput(0), 0.00001);
   }
 
diff --git a/tensorflow/core/kernels/resize_bicubic_op.cc b/tensorflow/core/kernels/resize_bicubic_op.cc
index 1c43e77e7..0b7685e55 100644
--- a/tensorflow/core/kernels/resize_bicubic_op.cc
+++ b/tensorflow/core/kernels/resize_bicubic_op.cc
@@ -465,9 +465,9 @@ class ResizeBicubicOp : public OpKernel {
 
     if (!context->status().ok()) return;
 
-    typename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor input_data = input.template tensor<T, 4>();
     typename TTypes<float, 4>::Tensor output_data =
-        st.output->tensor<float, 4>();
+        st.output->template tensor<float, 4>();
 
     interpolate_with_caching<T>(input_data, st, output_data);
   }
@@ -496,8 +496,8 @@ class ResizeBicubicOpGrad : public OpKernel {
     if (!context->status().ok()) return;
 
     typename TTypes<float, 4>::ConstTensor input_grad =
-        input.tensor<float, 4>();
-    typename TTypes<T, 4>::Tensor output_grad = st.output->tensor<T, 4>();
+        input.template tensor<float, 4>();
+    typename TTypes<T, 4>::Tensor output_grad = st.output->template tensor<T, 4>();
 
     ResizeBicubicGrad<T>(input_grad, st, output_grad);
   }
diff --git a/tensorflow/core/kernels/resize_bicubic_op_test.cc b/tensorflow/core/kernels/resize_bicubic_op_test.cc
index ae14d2804..8e3317080 100644
--- a/tensorflow/core/kernels/resize_bicubic_op_test.cc
+++ b/tensorflow/core/kernels/resize_bicubic_op_test.cc
@@ -172,8 +172,8 @@ class ResizeBicubicOpTest : public OpsTestBase {
         DataTypeToEnum<float>::v(),
         TensorShape({batch_size, target_height, target_width, channels})));
 
-    ResizeBicubicBaseline(input->tensor<float, 4>(),
-                          expected->tensor<float, 4>());
+    ResizeBicubicBaseline(input->template tensor<float, 4>(),
+                          expected->template tensor<float, 4>());
     // Note: the baseline implementation reduces first in the x direction, and
     // then in the y direction. The optimized version reduces first in the y
     // direction, and then the X direction. As a result, there may be
diff --git a/tensorflow/core/kernels/resize_bilinear_op.cc b/tensorflow/core/kernels/resize_bilinear_op.cc
index d9cb993a4..21cabf847 100644
--- a/tensorflow/core/kernels/resize_bilinear_op.cc
+++ b/tensorflow/core/kernels/resize_bilinear_op.cc
@@ -51,9 +51,9 @@ class ResizeBilinearOp : public OpKernel {
     // Return if the output is empty.
     if (st.output->NumElements() == 0) return;
 
-    typename TTypes<T, 4>::ConstTensor image_data = input.tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor image_data = input.template tensor<T, 4>();
     typename TTypes<float, 4>::Tensor output_data =
-        st.output->tensor<float, 4>();
+        st.output->template tensor<float, 4>();
 
     functor::ResizeBilinear<Device, T>()(context->eigen_device<Device>(),
                                          image_data, st.height_scale,
@@ -259,8 +259,8 @@ class ResizeBilinearOpGrad : public OpKernel {
     if (!context->status().ok()) return;
 
     typename TTypes<float, 4>::ConstTensor input_grad =
-        input.tensor<float, 4>();
-    typename TTypes<T, 4>::Tensor output_grad = st.output->tensor<T, 4>();
+        input.template tensor<float, 4>();
+    typename TTypes<T, 4>::Tensor output_grad = st.output->template tensor<T, 4>();
 
     functor::ResizeBilinearGrad<Device, T>()(context->eigen_device<Device>(),
                                              input_grad, st.height_scale,
diff --git a/tensorflow/core/kernels/resize_bilinear_op_test.cc b/tensorflow/core/kernels/resize_bilinear_op_test.cc
index a920e6028..1fa1d2666 100644
--- a/tensorflow/core/kernels/resize_bilinear_op_test.cc
+++ b/tensorflow/core/kernels/resize_bilinear_op_test.cc
@@ -119,8 +119,8 @@ class ResizeBilinearOpTest : public OpsTestBase {
         device_->GetAllocator(AllocatorAttributes()),
         DataTypeToEnum<float>::v(),
         TensorShape({batch_size, output_width, output_height, channels})));
-    ResizeBilinearBaseline(input->tensor<float, 4>(),
-                           expected->tensor<float, 4>());
+    ResizeBilinearBaseline(input->template tensor<float, 4>(),
+                           expected->template tensor<float, 4>());
     test::ExpectTensorEqual<float>(*expected, *GetOutput(0));
   }
 
@@ -190,8 +190,8 @@ TEST_F(ResizeBilinearOpTest, TestBilinearRandom2x2To1x1) {
   std::unique_ptr<Tensor> expected(
       new Tensor(device_->GetAllocator(AllocatorAttributes()),
                  DataTypeToEnum<float>::v(), TensorShape({1, 1, 1, 1})));
-  ResizeBilinearBaseline(input->tensor<float, 4>(),
-                         expected->tensor<float, 4>());
+  ResizeBilinearBaseline(input->template tensor<float, 4>(),
+                         expected->template tensor<float, 4>());
   EXPECT_EQ(input->flat<float>()(0), output->flat<float>()(0));
   test::ExpectTensorEqual<float>(*expected, *output);
 }
diff --git a/tensorflow/core/kernels/resize_nearest_neighbor_op.cc b/tensorflow/core/kernels/resize_nearest_neighbor_op.cc
index bfd29b7ec..4dc76298e 100644
--- a/tensorflow/core/kernels/resize_nearest_neighbor_op.cc
+++ b/tensorflow/core/kernels/resize_nearest_neighbor_op.cc
@@ -56,8 +56,8 @@ class ResizeNearestNeighborOp : public OpKernel {
     // Return if the output is empty.
     if (st.output->NumElements() == 0) return;
 
-    typename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();
-    typename TTypes<T, 4>::Tensor output_data = st.output->tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor input_data = input.template tensor<T, 4>();
+    typename TTypes<T, 4>::Tensor output_data = st.output->template tensor<T, 4>();
 
     bool status;
     if (align_corners_) {
@@ -162,8 +162,8 @@ class ResizeNearestNeighborOpGrad : public OpKernel {
     // Return if the output is empty.
     if (output->NumElements() == 0) return;
 
-    typename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();
-    typename TTypes<T, 4>::Tensor output_data = output->tensor<T, 4>();
+    typename TTypes<T, 4>::ConstTensor input_data = input.template tensor<T, 4>();
+    typename TTypes<T, 4>::Tensor output_data = output->template tensor<T, 4>();
 
     const float height_scale =
         CalculateResizeScale(out_height, in_height, align_corners_);
diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc
index e45abb6c5..51ed9240b 100644
--- a/tensorflow/core/kernels/resource_variable_ops.cc
+++ b/tensorflow/core/kernels/resource_variable_ops.cc
@@ -405,7 +405,7 @@ class ResourceGatherOp : public OpKernel {
       for (int i = 1; i < params.dims(); i++) {
         inner_size *= params.dim_size(i);
       }
-      auto params_flat = params.shaped<T, 3>({1, gather_dim_size, inner_size});
+      auto params_flat = params.template shaped<T, 3>({1, gather_dim_size, inner_size});
       auto indices_flat = indices.flat<Index>();
       auto out_flat = out->shaped<T, 3>({1, N, out->NumElements() / N});
 
@@ -487,7 +487,7 @@ class ResourceScatterUpdateOp : public OpKernel {
     if (N > 0) {
       auto indices_flat = indices.flat<Index>();
       auto params_flat = params->flat_outer_dims<T>();
-      auto updates_flat = updates.shaped<T, 2>({N, updates.NumElements() / N});
+      auto updates_flat = updates.template shaped<T, 2>({N, updates.NumElements() / N});
 
       functor::ScatterFunctor<Device, T, Index, op> functor;
       const Index bad_i = functor(c, c->template eigen_device<Device>(),
diff --git a/tensorflow/core/kernels/reverse_op.cc b/tensorflow/core/kernels/reverse_op.cc
index 4f2afa525..2ca365d68 100644
--- a/tensorflow/core/kernels/reverse_op.cc
+++ b/tensorflow/core/kernels/reverse_op.cc
@@ -105,8 +105,8 @@ void HandleReverseCase(OpKernelContext* context,
     axes_di[i] = dims(i);
   }
   functor::Reverse<Device, T, NDIMS>()(context->eigen_device<Device>(),
-                                       input.tensor<T, NDIMS>(), axes_di,
-                                       result->tensor<T, NDIMS>());
+                                       input.template tensor<T, NDIMS>(), axes_di,
+                                       result->template tensor<T, NDIMS>());
 }
 
 template <typename Device, typename T>
@@ -182,8 +182,8 @@ void HandleReverseV2Case(OpKernelContext* context,
     axes_di[i] = axes[i];
   }
   functor::Reverse<Device, T, NDIMS>()(context->eigen_device<Device>(),
-                                       input.tensor<T, NDIMS>(), axes_di,
-                                       result->tensor<T, NDIMS>());
+                                       input.template tensor<T, NDIMS>(), axes_di,
+                                       result->template tensor<T, NDIMS>());
 }
 
 template <typename Device, typename T>
diff --git a/tensorflow/core/kernels/reverse_sequence_op.cc b/tensorflow/core/kernels/reverse_sequence_op.cc
index 505c512cc..7698571e3 100644
--- a/tensorflow/core/kernels/reverse_sequence_op.cc
+++ b/tensorflow/core/kernels/reverse_sequence_op.cc
@@ -139,8 +139,8 @@ class ReverseSequenceOp : public OpKernel {
 #define HANDLE_DIM(NDIM)                                                      \
   case NDIM:                                                                  \
     functor::ReverseSequence<Device, T, Tlen, NDIM>::Compute(                 \
-        context->eigen_device<Device>(), input.tensor<T, NDIM>(), batch_dim_, \
-        seq_dim_, seq_lens_t, output->tensor<T, NDIM>());                     \
+        context->eigen_device<Device>(), input.template tensor<T, NDIM>(), batch_dim_, \
+        seq_dim_, seq_lens_t, output->template tensor<T, NDIM>());                     \
     break;
 
     switch (input_dims) {
diff --git a/tensorflow/core/kernels/sample_distorted_bounding_box_op.cc b/tensorflow/core/kernels/sample_distorted_bounding_box_op.cc
index 44a817a5c..34fa2fb7a 100644
--- a/tensorflow/core/kernels/sample_distorted_bounding_box_op.cc
+++ b/tensorflow/core/kernels/sample_distorted_bounding_box_op.cc
@@ -387,9 +387,9 @@ class SampleDistortedBoundingBoxV2Op : public OpKernel {
     OP_REQUIRES_OK(
         context, context->allocate_output(2, TensorShape({1, 1, 4}), &bboxes));
 
-    typename TTypes<T, 1>::Tensor begin_data = begin->tensor<T, 1>();
-    typename TTypes<T, 1>::Tensor size_data = size->tensor<T, 1>();
-    typename TTypes<float, 3>::Tensor bboxes_data = bboxes->tensor<float, 3>();
+    typename TTypes<T, 1>::Tensor begin_data = begin->template tensor<T, 1>();
+    typename TTypes<T, 1>::Tensor size_data = size->template tensor<T, 1>();
+    typename TTypes<float, 3>::Tensor bboxes_data = bboxes->template tensor<float, 3>();
 
     begin_data(0) = T(offset_height);
     size_data(0) = T(target_height);
diff --git a/tensorflow/core/kernels/scan_ops.cc b/tensorflow/core/kernels/scan_ops.cc
index cc434ab0a..2023fac76 100644
--- a/tensorflow/core/kernels/scan_ops.cc
+++ b/tensorflow/core/kernels/scan_ops.cc
@@ -78,7 +78,7 @@ class ScanOp : public OpKernel {
       reduced_shape[2] *= input.dim_size(i);
     }
 
-    functor::Scan<Device, Reducer, T>()(d, input.shaped<T, 3>(reduced_shape),
+    functor::Scan<Device, Reducer, T>()(d, input.template shaped<T, 3>(reduced_shape),
                                         output->shaped<T, 3>(reduced_shape),
                                         reducer, reverse_, exclusive_);
   }
diff --git a/tensorflow/core/kernels/scatter_nd_op.cc b/tensorflow/core/kernels/scatter_nd_op.cc
index 484932ab0..3d8342ecc 100644
--- a/tensorflow/core/kernels/scatter_nd_op.cc
+++ b/tensorflow/core/kernels/scatter_nd_op.cc
@@ -400,7 +400,7 @@ Status DoScatterNd(OpKernelContext* c, const Tensor& indices,
 
   IndexFlattener<Device, Index> index_flattener;
   auto indices_flat = index_flattener(c, indices);
-  auto updates_flat = updates.shaped<T, 2>({num_updates, slice_size});
+  auto updates_flat = updates.template shaped<T, 2>({num_updates, slice_size});
 
   if (allocate) {
     TF_RETURN_IF_ERROR(c->allocate_temp(DataTypeToEnum<T>::value, shape, out));
diff --git a/tensorflow/core/kernels/scatter_op.cc b/tensorflow/core/kernels/scatter_op.cc
index 8607c7f95..c4671ee82 100644
--- a/tensorflow/core/kernels/scatter_op.cc
+++ b/tensorflow/core/kernels/scatter_op.cc
@@ -121,7 +121,7 @@ class ScatterUpdateOp : public OpKernel {
     if (N > 0) {
       auto indices_flat = indices.flat<Index>();
       auto params_flat = params.flat_outer_dims<T>();
-      auto updates_flat = updates.shaped<T, 2>({N, updates.NumElements() / N});
+      auto updates_flat = updates.template shaped<T, 2>({N, updates.NumElements() / N});
 
       functor::ScatterFunctor<Device, T, Index, op> functor;
       const Index bad_i = functor(c, c->template eigen_device<Device>(),
@@ -193,7 +193,7 @@ class ScatterUpdateOp <SYCLDevice, T, Index, op> : public OpKernel {
 
       auto indices_flat = indices_host.flat<Index>();
       auto params_flat = params.flat_outer_dims<T>();
-      auto updates_flat = updates.shaped<T, 2>({N, updates.NumElements() / N});
+      auto updates_flat = updates.template shaped<T, 2>({N, updates.NumElements() / N});
 
       functor::ScatterFunctorSYCL<T, Index, op> functor;
       const Index bad_i = functor(c, c->template eigen_device<SYCLDevice>(),
diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc
index 5042cfafc..e65c92688 100644
--- a/tensorflow/core/kernels/sdca_internal.cc
+++ b/tensorflow/core/kernels/sdca_internal.cc
@@ -116,7 +116,7 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {
     deltas.setZero();
     sparse_weights_.emplace_back(FeatureWeightsSparseStorage{
         sparse_indices_inputs[i].flat<int64>(),
-        sparse_weights_inputs[i].shaped<float, 2>(
+        sparse_weights_inputs[i].template shaped<float, 2>(
             {1, sparse_weights_inputs[i].NumElements()}),
         deltas});
   }
@@ -133,7 +133,7 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {
       auto deltas = delta_t->shaped<float, 2>({1, delta_t->NumElements()});
       deltas.setZero();
       feature_weights->emplace_back(
-          FeatureWeightsDenseStorage{weight_inputs[i].shaped<float, 2>(
+          FeatureWeightsDenseStorage{weight_inputs[i].template shaped<float, 2>(
                                          {1, weight_inputs[i].NumElements()}),
                                      deltas});
     }
diff --git a/tensorflow/core/kernels/slice_op.cc b/tensorflow/core/kernels/slice_op.cc
index d46701749..78bdae3f3 100644
--- a/tensorflow/core/kernels/slice_op.cc
+++ b/tensorflow/core/kernels/slice_op.cc
@@ -176,8 +176,8 @@ class SliceOp : public OpKernel {
     if (output_shape.num_elements() > 0) {
       if (std::is_same<Device, CPUDevice>::value && input_dims == 2 &&
           DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) {
-        auto input = context->input(0).tensor<T, 2>();
-        auto output = result->tensor<T, 2>();
+        auto input = context->input(0).template tensor<T, 2>();
+        auto output = result->template tensor<T, 2>();
         // TODO(agarwal): Consider multi-threading this loop for cases where
         // size[0] is very large.
         for (int i = 0; i < size[0]; ++i) {
@@ -223,8 +223,8 @@ class SliceOp : public OpKernel {
     }
 
     functor::Slice<Device, T, NDIM>()(
-        context->eigen_device<Device>(), result->tensor<T, NDIM>(),
-        context->input(0).tensor<T, NDIM>(), indices, sizes);
+        context->eigen_device<Device>(), result->template tensor<T, NDIM>(),
+        context->input(0).template tensor<T, NDIM>(), indices, sizes);
   }
 };
 
@@ -250,8 +250,8 @@ class MklSliceOp : public OpKernel {
     if (output_shape.num_elements() > 0) {
       if (std::is_same<Device, CPUDevice>::value && input_dims == 2 &&
           DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) {
-        auto input = context->input(0).tensor<T, 2>();
-        auto output = result->tensor<T, 2>();
+        auto input = context->input(0).template tensor<T, 2>();
+        auto output = result->template tensor<T, 2>();
         // TODO(agarwal): Consider multi-threading this loop for cases where
         // size[0] is very large.
         for (int i = 0; i < size[0]; ++i) {
@@ -411,8 +411,8 @@ class MklSliceOp : public OpKernel {
     }
 
     functor::Slice<Device, T, NDIM>()(
-        context->eigen_device<Device>(), result->tensor<T, NDIM>(),
-        context->input(0).tensor<T, NDIM>(), indices, sizes);
+        context->eigen_device<Device>(), result->template tensor<T, NDIM>(),
+        context->input(0).template tensor<T, NDIM>(), indices, sizes);
   }
 };
 #endif
diff --git a/tensorflow/core/kernels/spacetobatch_op.cc b/tensorflow/core/kernels/spacetobatch_op.cc
index c51368391..f4762c266 100644
--- a/tensorflow/core/kernels/spacetobatch_op.cc
+++ b/tensorflow/core/kernels/spacetobatch_op.cc
@@ -186,7 +186,7 @@ void SpaceToBatchOpCompute(OpKernelContext* context,
         context,                                                           \
         (functor::SpaceToBatchFunctor<Device, T, NUM_BLOCK_DIMS, false>()( \
             context->eigen_device<Device>(),                               \
-            orig_input_tensor.shaped<T, NUM_BLOCK_DIMS + 2>(               \
+            orig_input_tensor.template shaped<T, NUM_BLOCK_DIMS + 2>(               \
                 internal_input_shape.dim_sizes()),                         \
             internal_block_shape, internal_paddings,                       \
             output_tensor->shaped<T, NUM_BLOCK_DIMS + 2>(                  \
diff --git a/tensorflow/core/kernels/spacetodepth_op.cc b/tensorflow/core/kernels/spacetodepth_op.cc
index 14510add5..7146863e6 100644
--- a/tensorflow/core/kernels/spacetodepth_op.cc
+++ b/tensorflow/core/kernels/spacetodepth_op.cc
@@ -108,8 +108,8 @@ class SpaceToDepthOp : public OpKernel {
                                        output_width, output_depth),
                        &outputs_tensor));
 
-    auto Toutput = outputs_tensor->tensor<T, 4>();
-    auto Tinput = input.tensor<T, 4>();
+    auto Toutput = outputs_tensor->template tensor<T, 4>();
+    auto Tinput = input.template tensor<T, 4>();
 
     if (std::is_same<Device, GPUDevice>::value && data_format_ == FORMAT_NCHW) {
       functor::SpaceToDepthOpFunctor<Device, T, FORMAT_NCHW> functor;
diff --git a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc
index 0b664fc35..34124812b 100644
--- a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc
+++ b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc
@@ -90,8 +90,8 @@ class SparseTensorDenseAddOp : public OpKernel {
     switch (ndims) {
 #define NDIMS_CASE(N)                                                     \
   case N: {                                                               \
-    auto out_tensor = out_t->tensor<T, N>();                              \
-    out_tensor.device(ctx->eigen_device<Device>()) = b->tensor<T, N>();   \
+    auto out_tensor = out_t->template tensor<T, N>();                              \
+    out_tensor.device(ctx->eigen_device<Device>()) = b->template tensor<T, N>();   \
     const Index result =                                                  \
         functor::ScatterNdFunctor<Device, T, Index, N,                    \
                                   scatter_op::UpdateOp::ADD>()(           \
diff --git a/tensorflow/core/kernels/sparse_to_dense_op.cc b/tensorflow/core/kernels/sparse_to_dense_op.cc
index 6a6cc3d81..3237b7f91 100644
--- a/tensorflow/core/kernels/sparse_to_dense_op.cc
+++ b/tensorflow/core/kernels/sparse_to_dense_op.cc
@@ -98,7 +98,7 @@ class SparseToDense : public OpKernel {
       CHECK(indices_shaped.CopyFrom(indices, ix_shape));
     } else {
       indices_shaped.matrix<int64>() =
-          indices.shaped<Index, 2>(ix_shape.dim_sizes()).template cast<int64>();
+          indices.template shaped<Index, 2>(ix_shape.dim_sizes()).template cast<int64>();
     }
 
     // If we received a scalar, we'll need to create a new
diff --git a/tensorflow/core/kernels/sparse_to_dense_op_test.cc b/tensorflow/core/kernels/sparse_to_dense_op_test.cc
index f0d19da80..b41699a7b 100644
--- a/tensorflow/core/kernels/sparse_to_dense_op_test.cc
+++ b/tensorflow/core/kernels/sparse_to_dense_op_test.cc
@@ -123,9 +123,9 @@ TEST_F(SparseToDenseTest, TwoD_OneValue) {
 
   Tensor expected(allocator(), DT_FLOAT, {3, 4});
   expected.flat<float>().setConstant(-2);
-  expected.tensor<float, 2>()(0, 1) = 2;
-  expected.tensor<float, 2>()(0, 2) = 2;
-  expected.tensor<float, 2>()(2, 3) = 2;
+  expected.template tensor<float, 2>()(0, 1) = 2;
+  expected.template tensor<float, 2>()(0, 2) = 2;
+  expected.template tensor<float, 2>()(2, 3) = 2;
   test::ExpectTensorEqual<float>(expected, *GetOutput(0));
 }
 
@@ -145,9 +145,9 @@ TEST_F(SparseToDenseTest, TwoD_MultValues) {
 
   Tensor expected(allocator(), DT_FLOAT, {3, 4});
   expected.flat<float>().setConstant(-2);
-  expected.tensor<float, 2>()(0, 1) = 3;
-  expected.tensor<float, 2>()(0, 2) = 4;
-  expected.tensor<float, 2>()(2, 3) = 5;
+  expected.template tensor<float, 2>()(0, 1) = 3;
+  expected.template tensor<float, 2>()(0, 2) = 4;
+  expected.template tensor<float, 2>()(2, 3) = 5;
   test::ExpectTensorEqual<float>(expected, *GetOutput(0));
 }
 
@@ -167,9 +167,9 @@ TEST_F(SparseToDenseTest, ThreeD_OneValue) {
 
   Tensor expected(allocator(), DT_FLOAT, {3, 4, 2});
   expected.flat<float>().setConstant(-2);
-  expected.tensor<float, 3>()(0, 1, 1) = 2;
-  expected.tensor<float, 3>()(0, 2, 0) = 2;
-  expected.tensor<float, 3>()(2, 3, 1) = 2;
+  expected.template tensor<float, 3>()(0, 1, 1) = 2;
+  expected.template tensor<float, 3>()(0, 2, 0) = 2;
+  expected.template tensor<float, 3>()(2, 3, 1) = 2;
   test::ExpectTensorEqual<float>(expected, *GetOutput(0));
 }
 
@@ -189,9 +189,9 @@ TEST_F(SparseToDenseTest, ThreeD_MultValues) {
 
   Tensor expected(allocator(), DT_FLOAT, {3, 4, 2});
   expected.flat<float>().setConstant(-2);
-  expected.tensor<float, 3>()(0, 1, 1) = 3;
-  expected.tensor<float, 3>()(0, 2, 0) = 4;
-  expected.tensor<float, 3>()(2, 3, 1) = 5;
+  expected.template tensor<float, 3>()(0, 1, 1) = 3;
+  expected.template tensor<float, 3>()(0, 2, 0) = 4;
+  expected.template tensor<float, 3>()(2, 3, 1) = 5;
   test::ExpectTensorEqual<float>(expected, *GetOutput(0));
 }
 
diff --git a/tensorflow/core/kernels/split_op.cc b/tensorflow/core/kernels/split_op.cc
index 4d2100c59..1fd8428f6 100644
--- a/tensorflow/core/kernels/split_op.cc
+++ b/tensorflow/core/kernels/split_op.cc
@@ -154,7 +154,7 @@ class SplitOpCPU : public SplitOpBase<CPUDevice, T> {
     std::tie(prefix_dim_size, split_dim_size, suffix_dim_size) =
         Base::template SetDims<Eigen::DenseIndex>(input_shape, split_dim);
     auto input_reshaped =
-        input.shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
+        input.template shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
 
     const int64 split_dim_output_size = split_dim_size / num_split;
     TensorShape output_shape(input_shape);
@@ -316,7 +316,7 @@ class SplitOpSYCL : public SplitOpBase<SYCLDevice, T> {
     std::tie(prefix_dim_size, split_dim_size, suffix_dim_size) =
         Base::template SetDims<Eigen::DenseIndex>(input_shape, split_dim);
     auto input_reshaped =
-        input.shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
+        input.template shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
 
     const int64 split_dim_output_size = split_dim_size / num_split;
     TensorShape output_shape(input_shape);
diff --git a/tensorflow/core/kernels/split_v_op.cc b/tensorflow/core/kernels/split_v_op.cc
index e2dd66da1..51210849d 100644
--- a/tensorflow/core/kernels/split_v_op.cc
+++ b/tensorflow/core/kernels/split_v_op.cc
@@ -209,7 +209,7 @@ class SplitVOpCPU : public SplitVOpBase<CPUDevice, T, Tlen> {
     std::tie(prefix_dim_size, split_dim_size, suffix_dim_size) =
         Base::template SetDims<Eigen::DenseIndex>(input_shape, split_dim);
     auto input_reshaped =
-        input.shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
+        input.template shaped<T, 3>({prefix_dim_size, split_dim_size, suffix_dim_size});
 
     Eigen::DSizes<Eigen::DenseIndex, 3> indices{0, 0, 0};
     std::vector<int64> split_start_points(num_split);
@@ -362,7 +362,7 @@ class SplitVOpGPU : public SplitVOpBase<GPUDevice, T, Tlen> {
 
       std::tie(prefix_dim_size, split_dim_size, suffix_dim_size) =
           Base::template SetDims<Eigen::DenseIndex>(input_shape, split_dim);
-      auto input_reshaped = input.shaped<T, 2>(
+      auto input_reshaped = input.template shaped<T, 2>(
           {prefix_dim_size, split_dim_size * suffix_dim_size});
 
       Eigen::DSizes<Eigen::DenseIndex, 2> indices{0, 0};
diff --git a/tensorflow/core/kernels/strided_slice_op.cc b/tensorflow/core/kernels/strided_slice_op.cc
index 8fc40db3c..9ccc1542a 100644
--- a/tensorflow/core/kernels/strided_slice_op.cc
+++ b/tensorflow/core/kernels/strided_slice_op.cc
@@ -47,8 +47,8 @@ struct MemCpyFunctor {
   bool Copy(const Tensor& input, const gtl::InlinedVector<int64, 4>& begin,
             const gtl::InlinedVector<int64, 4>& end, Tensor* result) {
     if (DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) {
-      auto in = input.tensor<T, 2>();
-      auto output = result->tensor<T, 2>();
+      auto in = input.template tensor<T, 2>();
+      auto output = result->template tensor<T, 2>();
       // TODO(agarwal): Consider multi-threading if size[0] is large
       for (int row_in = begin[0], row_out = 0; row_in < end[0];
            ++row_in, ++row_out) {
diff --git a/tensorflow/core/kernels/substr_op.cc b/tensorflow/core/kernels/substr_op.cc
index 5c72c9e1a..2adee62db 100644
--- a/tensorflow/core/kernels/substr_op.cc
+++ b/tensorflow/core/kernels/substr_op.cc
@@ -106,17 +106,17 @@ class SubstrOp : public OpKernel {
       switch (ndims) {
         case 1: {
           // Reshape tensors according to BCast results
-          auto input = input_tensor.shaped<string, 1>(bcast.x_reshape());
+          auto input = input_tensor.template shaped<string, 1>(bcast.x_reshape());
           auto output = output_tensor->shaped<string, 1>(bcast.result_shape());
-          auto pos_shaped = pos_tensor.shaped<T, 1>(bcast.y_reshape());
-          auto len_shaped = len_tensor.shaped<T, 1>(bcast.y_reshape());
+          auto pos_shaped = pos_tensor.template shaped<T, 1>(bcast.y_reshape());
+          auto len_shaped = len_tensor.template shaped<T, 1>(bcast.y_reshape());
 
           // Allocate temporary buffer for broadcasted input tensor
           Tensor input_buffer;
           OP_REQUIRES_OK(context, context->allocate_temp(
                                       DT_STRING, output_shape, &input_buffer));
           typename TTypes<string, 1>::Tensor input_bcast =
-              input_buffer.shaped<string, 1>(bcast.result_shape());
+              input_buffer.template shaped<string, 1>(bcast.result_shape());
           input_bcast =
               input.broadcast(BCast::ToIndexArray<1>(bcast.x_bcast()));
 
@@ -126,7 +126,7 @@ class SubstrOp : public OpKernel {
                          context->allocate_temp(DataTypeToEnum<T>::v(),
                                                 output_shape, &pos_buffer));
           typename TTypes<T, 1>::Tensor pos_bcast =
-              pos_buffer.shaped<T, 1>(bcast.result_shape());
+              pos_buffer.template shaped<T, 1>(bcast.result_shape());
           pos_bcast =
               pos_shaped.broadcast(BCast::ToIndexArray<1>(bcast.y_bcast()));
 
@@ -136,7 +136,7 @@ class SubstrOp : public OpKernel {
                          context->allocate_temp(DataTypeToEnum<T>::v(),
                                                 output_shape, &len_buffer));
           typename TTypes<T, 1>::Tensor len_bcast =
-              len_buffer.shaped<T, 1>(bcast.result_shape());
+              len_buffer.template shaped<T, 1>(bcast.result_shape());
           len_bcast =
               len_shaped.broadcast(BCast::ToIndexArray<1>(bcast.y_bcast()));
 
@@ -155,17 +155,17 @@ class SubstrOp : public OpKernel {
         }
         case 2: {
           // Reshape tensors according to BCast results
-          auto input = input_tensor.shaped<string, 2>(bcast.x_reshape());
+          auto input = input_tensor.template shaped<string, 2>(bcast.x_reshape());
           auto output = output_tensor->shaped<string, 2>(bcast.result_shape());
-          auto pos_shaped = pos_tensor.shaped<T, 2>(bcast.y_reshape());
-          auto len_shaped = len_tensor.shaped<T, 2>(bcast.y_reshape());
+          auto pos_shaped = pos_tensor.template shaped<T, 2>(bcast.y_reshape());
+          auto len_shaped = len_tensor.template shaped<T, 2>(bcast.y_reshape());
 
           // Allocate temporary buffer for broadcasted input tensor
           Tensor input_buffer;
           OP_REQUIRES_OK(context, context->allocate_temp(
                                       DT_STRING, output_shape, &input_buffer));
           typename TTypes<string, 2>::Tensor input_bcast =
-              input_buffer.shaped<string, 2>(bcast.result_shape());
+              input_buffer.template shaped<string, 2>(bcast.result_shape());
           input_bcast =
               input.broadcast(BCast::ToIndexArray<2>(bcast.x_bcast()));
 
@@ -175,7 +175,7 @@ class SubstrOp : public OpKernel {
                          context->allocate_temp(DataTypeToEnum<T>::v(),
                                                 output_shape, &pos_buffer));
           typename TTypes<T, 2>::Tensor pos_bcast =
-              pos_buffer.shaped<T, 2>(bcast.result_shape());
+              pos_buffer.template shaped<T, 2>(bcast.result_shape());
           pos_bcast =
               pos_shaped.broadcast(BCast::ToIndexArray<2>(bcast.y_bcast()));
 
@@ -185,7 +185,7 @@ class SubstrOp : public OpKernel {
                          context->allocate_temp(DataTypeToEnum<T>::v(),
                                                 output_shape, &len_buffer));
           typename TTypes<T, 2>::Tensor len_bcast =
-              len_buffer.shaped<T, 2>(bcast.result_shape());
+              len_buffer.template shaped<T, 2>(bcast.result_shape());
           len_bcast =
               len_shaped.broadcast(BCast::ToIndexArray<2>(bcast.y_bcast()));
 
diff --git a/tensorflow/core/kernels/summary_audio_op.cc b/tensorflow/core/kernels/summary_audio_op.cc
index f5ddb9081..cbf86c787 100644
--- a/tensorflow/core/kernels/summary_audio_op.cc
+++ b/tensorflow/core/kernels/summary_audio_op.cc
@@ -76,7 +76,7 @@ class SummaryAudioOp : public OpKernel {
       sa->set_content_type("audio/wav");
 
       auto values =
-          tensor.shaped<float, 3>({batch_size, length_frames, num_channels});
+          tensor.template shaped<float, 3>({batch_size, length_frames, num_channels});
       auto channels_by_frames = typename TTypes<float>::ConstMatrix(
           &values(i, 0, 0),
           Eigen::DSizes<Eigen::DenseIndex, 2>(length_frames, num_channels));
diff --git a/tensorflow/core/kernels/summary_image_op.cc b/tensorflow/core/kernels/summary_image_op.cc
index 233b824bc..6cef3cb0d 100644
--- a/tensorflow/core/kernels/summary_image_op.cc
+++ b/tensorflow/core/kernels/summary_image_op.cc
@@ -80,7 +80,7 @@ class SummaryImageOp : public OpKernel {
     if (tensor.dtype() == DT_UINT8) {
       // For uint8 input, no normalization is necessary
       auto ith_image = [&tensor, batch_size, hw, depth](int i) {
-        auto values = tensor.shaped<uint8, 3>({batch_size, hw, depth});
+        auto values = tensor.template shaped<uint8, 3>({batch_size, hw, depth});
         return typename TTypes<uint8>::ConstMatrix(
             &values(i, 0, 0), Eigen::DSizes<Eigen::DenseIndex, 2>(hw, depth));
       };
diff --git a/tensorflow/core/kernels/summary_interface.cc b/tensorflow/core/kernels/summary_interface.cc
index e95a4c7b8..f5196b406 100644
--- a/tensorflow/core/kernels/summary_interface.cc
+++ b/tensorflow/core/kernels/summary_interface.cc
@@ -316,7 +316,7 @@ class SummaryWriterImpl : public SummaryWriterInterface {
     if (tensor.dtype() == DT_UINT8) {
       // For uint8 input, no normalization is necessary
       auto ith_image = [&tensor, batch_size, hw, depth](int i) {
-        auto values = tensor.shaped<uint8, 3>({batch_size, hw, depth});
+        auto values = tensor.template shaped<uint8, 3>({batch_size, hw, depth});
         return typename TTypes<uint8>::ConstMatrix(
             &values(i, 0, 0), Eigen::DSizes<Eigen::DenseIndex, 2>(hw, depth));
       };
@@ -363,7 +363,7 @@ class SummaryWriterImpl : public SummaryWriterInterface {
       sa->set_content_type("audio/wav");
 
       auto values =
-          tensor.shaped<float, 3>({batch_size, length_frames, num_channels});
+          tensor.template shaped<float, 3>({batch_size, length_frames, num_channels});
       auto channels_by_frames = typename TTypes<float>::ConstMatrix(
           &values(i, 0, 0),
           Eigen::DSizes<Eigen::DenseIndex, 2>(length_frames, num_channels));
diff --git a/tensorflow/core/kernels/tile_functor.h b/tensorflow/core/kernels/tile_functor.h
index 28af2dace..edead9ac1 100644
--- a/tensorflow/core/kernels/tile_functor.h
+++ b/tensorflow/core/kernels/tile_functor.h
@@ -32,8 +32,8 @@ void TileSimple(const Device& d, Tensor* out, const Tensor& in);
 template <typename Device, typename T, int NDIM>
 void TileUsingEigen(const Device& d, Tensor* out, const Tensor& in,
                     const gtl::ArraySlice<int32>& broadcast_array) {
-  auto x = in.tensor<T, NDIM>();
-  auto y = out->tensor<T, NDIM>();
+  auto x = in.template tensor<T, NDIM>();
+  auto y = out->template tensor<T, NDIM>();
 
   Eigen::array<int32, NDIM> b;
   for (int i = 0; i < NDIM; ++i) b[i] = broadcast_array[i];
@@ -48,8 +48,8 @@ void TileUsingEigen(const Device& d, Tensor* out, const Tensor& in,
 template <typename Device, typename T>
 void TileUsingEigen(const Device& d, Tensor* out, const Tensor& in,
                     const gtl::ArraySlice<int32>&) {
-  auto x = in.tensor<T, 0>();
-  auto y = out->tensor<T, 0>();
+  auto x = in.template tensor<T, 0>();
+  auto y = out->template tensor<T, 0>();
   // In the scalar case we simply copy the input.
   y.device(d) = x;
 }
diff --git a/tensorflow/core/kernels/tile_ops.cc b/tensorflow/core/kernels/tile_ops.cc
index c49ebc068..8901be29a 100644
--- a/tensorflow/core/kernels/tile_ops.cc
+++ b/tensorflow/core/kernels/tile_ops.cc
@@ -388,8 +388,8 @@ class TileGradientOp : public OpKernel {
     bool first = true;
     while (true) {
       functor::TileGrad<Device, T, NDIM>()(
-          context->eigen_device<Device>(), result->tensor<T, NDIM>(),
-          context->input(0).tensor<T, NDIM>(), indices, sizes, first);
+          context->eigen_device<Device>(), result->template tensor<T, NDIM>(),
+          context->input(0).template tensor<T, NDIM>(), indices, sizes, first);
       first = false;
       // Increment the begin indices.
       int i = 0;
@@ -422,8 +422,8 @@ class TileGradientOp : public OpKernel {
     }
 
     functor::ReduceAndReshape<Device, T, NDIM, REDUCENDIM>()(
-        context->eigen_device<Device>(), result->tensor<T, NDIM>(),
-        context->input(0).tensor<T, NDIM>(), reduce_dim, reshape_dim);
+        context->eigen_device<Device>(), result->template tensor<T, NDIM>(),
+        context->input(0).template tensor<T, NDIM>(), reduce_dim, reshape_dim);
   }
 
   TF_DISALLOW_COPY_AND_ASSIGN(TileGradientOp);
diff --git a/tensorflow/core/kernels/transpose_op.cc b/tensorflow/core/kernels/transpose_op.cc
index d3305fb83..b897bd2b3 100644
--- a/tensorflow/core/kernels/transpose_op.cc
+++ b/tensorflow/core/kernels/transpose_op.cc
@@ -98,8 +98,8 @@ REGISTER_KERNEL_BUILDER(Name("InvertPermutation")
 // Specifically, the returned tensor output meets the following condition:
 // 1) output.dims() == input.dims();
 // 2) output.dim_size(i) == input.dim_size(perm[i]);
-// 3) output.tensor<T, N>(i_0, i_1, ..., i_N-1) ==
-//      input.tensor<T, N>(j_0, j_1, ..., j_N-1),
+// 3) output.template tensor<T, N>(i_0, i_1, ..., i_N-1) ==
+//      input.template tensor<T, N>(j_0, j_1, ..., j_N-1),
 //    where i_s == j_{perm[s]}
 //
 // REQUIRES: perm is a vector of int32.
diff --git a/tensorflow/core/kernels/unpack_op.cc b/tensorflow/core/kernels/unpack_op.cc
index 7fd1def1f..1fb06adc6 100644
--- a/tensorflow/core/kernels/unpack_op.cc
+++ b/tensorflow/core/kernels/unpack_op.cc
@@ -103,7 +103,7 @@ class UnpackOp : public OpKernel {
     // Except for shape, unpack is a special case of split, so we reuse the
     // same computational kernels.
     auto input_reshaped =
-        input.shaped<T, 3>({1, before_dim, axis_dim * after_dim});
+        input.template shaped<T, 3>({1, before_dim, axis_dim * after_dim});
 
     for (int i = 0; i < num; ++i) {
       Tensor* output;
diff --git a/tensorflow/core/kernels/variable_ops.h b/tensorflow/core/kernels/variable_ops.h
index 355140d44..4fe0eefc8 100644
--- a/tensorflow/core/kernels/variable_ops.h
+++ b/tensorflow/core/kernels/variable_ops.h
@@ -202,7 +202,7 @@ class IsVariableInitializedOp : public OpKernel {
     Tensor* output = nullptr;
     OP_REQUIRES_OK(context,
                    context->allocate_output(0, TensorShape({}), &output));
-    auto output_tensor = output->tensor<bool, 0>();
+    auto output_tensor = output->template tensor<bool, 0>();
     bool result = input_tensor.IsInitialized();
     output_tensor() = result;
   }
diff --git a/tensorflow/core/kernels/where_op.cc b/tensorflow/core/kernels/where_op.cc
index 59b474e41..20fc8be26 100644
--- a/tensorflow/core/kernels/where_op.cc
+++ b/tensorflow/core/kernels/where_op.cc
@@ -138,7 +138,7 @@ class WhereCPUOp : public OpKernel {
   case NDIM: {                                                             \
     Status s = functor::Where<CPUDevice, NDIM, int64>::Compute(            \
         context, context->eigen_device<CPUDevice>(),                       \
-        input.tensor<bool, NDIM>(), output->matrix<int64>(), &found_true); \
+        input.template tensor<bool, NDIM>(), output->matrix<int64>(), &found_true); \
     OP_REQUIRES_OK(context, s);                                            \
   } break;
 
@@ -282,7 +282,7 @@ class WhereGPUOp : public AsyncOpKernel {
 #define HANDLE_DIM(NDIM)                                                 \
   case NDIM: {                                                           \
     Status s = functor::Where<GPUDevice, NDIM, Tindex>::Compute(         \
-        context, d, input.tensor<bool, NDIM>(), output->matrix<int64>(), \
+        context, d, input.template tensor<bool, NDIM>(), output->matrix<int64>(), \
         &found_true);                                                    \
     OP_REQUIRES_OK_ASYNC(context, s, done);                              \
   } break;
diff --git a/tensorflow/core/util/sparse/sparse_tensor_test.cc b/tensorflow/core/util/sparse/sparse_tensor_test.cc
index efdd97fd3..17584586f 100644
--- a/tensorflow/core/util/sparse/sparse_tensor_test.cc
+++ b/tensorflow/core/util/sparse/sparse_tensor_test.cc
@@ -356,7 +356,7 @@ TEST(SparseTensorTest, SparseTensorToDenseTensor) {
   Tensor dense(DT_STRING, TensorShape({4, 4, 5}));
   st.ToDense<string>(&dense);
 
-  auto dense_t = dense.tensor<string, 3>();
+  auto dense_t = dense.template tensor<string, 3>();
   Eigen::array<Eigen::DenseIndex, NDIM> ix_n;
   for (int n = 0; n < N; ++n) {
     for (int d = 0; d < NDIM; ++d) ix_n[d] = ix_t(n, d);
@@ -395,7 +395,7 @@ TEST(SparseTensorTest, SparseTensorToLargerDenseTensor) {
   Tensor dense(DT_STRING, TensorShape({10, 10, 10}));
   st.ToDense<string>(&dense);
 
-  auto dense_t = dense.tensor<string, 3>();
+  auto dense_t = dense.template tensor<string, 3>();
   Eigen::array<Eigen::DenseIndex, NDIM> ix_n;
   for (int n = 0; n < N; ++n) {
     for (int d = 0; d < NDIM; ++d) ix_n[d] = ix_t(n, d);
diff --git a/tensorflow/examples/ios/benchmark/BenchmarkViewController.mm b/tensorflow/examples/ios/benchmark/BenchmarkViewController.mm
index 9fc5f6ded..c41ad8dce 100644
--- a/tensorflow/examples/ios/benchmark/BenchmarkViewController.mm
+++ b/tensorflow/examples/ios/benchmark/BenchmarkViewController.mm
@@ -231,7 +231,7 @@ bool PortableReadFileToProto(const std::string& file_name,
       tensorflow::DT_FLOAT,
       tensorflow::TensorShape(
           {1, wanted_height, wanted_width, wanted_channels}));
-  auto image_tensor_mapped = image_tensor.tensor<float, 4>();
+  auto image_tensor_mapped = image_tensor.template tensor<float, 4>();
   tensorflow::uint8* in = image_data.data();
   float* out = image_tensor_mapped.data();
   for (int y = 0; y < wanted_height; ++y) {
diff --git a/tensorflow/examples/ios/camera/CameraExampleViewController.mm b/tensorflow/examples/ios/camera/CameraExampleViewController.mm
index d113d50ff..6fa31811a 100644
--- a/tensorflow/examples/ios/camera/CameraExampleViewController.mm
+++ b/tensorflow/examples/ios/camera/CameraExampleViewController.mm
@@ -293,7 +293,7 @@ - (void)runCNNOnFrame:(CVPixelBufferRef)pixelBuffer {
       tensorflow::DT_FLOAT,
       tensorflow::TensorShape(
           {1, wanted_input_height, wanted_input_width, wanted_input_channels}));
-  auto image_tensor_mapped = image_tensor.tensor<float, 4>();
+  auto image_tensor_mapped = image_tensor.template tensor<float, 4>();
   tensorflow::uint8 *in = sourceStartAddr;
   float *out = image_tensor_mapped.data();
   for (int y = 0; y < wanted_input_height; ++y) {
diff --git a/tensorflow/examples/ios/simple/RunModelViewController.mm b/tensorflow/examples/ios/simple/RunModelViewController.mm
index c8ccb5c77..c124d9c7b 100644
--- a/tensorflow/examples/ios/simple/RunModelViewController.mm
+++ b/tensorflow/examples/ios/simple/RunModelViewController.mm
@@ -180,7 +180,7 @@ bool PortableReadFileToProto(const std::string& file_name,
       tensorflow::DT_FLOAT,
       tensorflow::TensorShape({
           1, wanted_height, wanted_width, wanted_channels}));
-  auto image_tensor_mapped = image_tensor.tensor<float, 4>();
+  auto image_tensor_mapped = image_tensor.template tensor<float, 4>();
   tensorflow::uint8* in = image_data.data();
   // tensorflow::uint8* in_end = (in + (image_height * image_width * image_channels));
   float* out = image_tensor_mapped.data();
diff --git a/tensorflow/tools/graph_transforms/flatten_atrous.cc b/tensorflow/tools/graph_transforms/flatten_atrous.cc
index a6f7cb0ed..cb852b229 100644
--- a/tensorflow/tools/graph_transforms/flatten_atrous.cc
+++ b/tensorflow/tools/graph_transforms/flatten_atrous.cc
@@ -81,8 +81,8 @@ Status FlattenAtrousConv(const GraphDef& input_graph_def,
             TensorShape({upsampled_filter_height, upsampled_filter_width,
                          in_channels, out_channels}));
 
-        auto filter_eigen = filter.tensor<float, 4>();
-        auto upsampled_filter_eigen = upsampled_filter.tensor<float, 4>();
+        auto filter_eigen = filter.template tensor<float, 4>();
+        auto upsampled_filter_eigen = upsampled_filter.template tensor<float, 4>();
 
         upsampled_filter_eigen.setZero();
         for (int h = 0; h < filter_height; ++h) {
