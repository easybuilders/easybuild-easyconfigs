easyblock = 'PythonBundle'

name = 'CLIP'
version = '20230220'
versionsuffix = '-CUDA-%(cudaver)s'
_commit = 'a9b1bf5'

homepage = 'https://github.com/openai/CLIP'
description = """
CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a
variety of (image, text) pairs. It can be instructed in natural language to
predict the most relevant text snippet, given an image, without directly
optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and
3."""

toolchain = {'name': 'foss', 'version': '2022a'}

dependencies = [
    ('Python', '3.10.4'),
    ('CUDA', '11.7.0', '', SYSTEM),
    ('PyTorch', '1.12.0', versionsuffix),
    ('tqdm', '4.64.0'),
    ('torchvision', '0.13.1', versionsuffix),
]

use_pip = True

exts_list = [
    ('ftfy', '6.1.1', {
        'checksums': ['bfc2019f84fcd851419152320a6375604a0f1459c281b5b199b2cd0d2e727f8f'],
    }),
    (name, version, {
        'source_urls': ['https://github.com/openai/CLIP/archive'],
        'sources': [{'download_filename': _commit + '.tar.gz', 'filename': '%(name)s-%(version)s.tar.gz'}],
        'checksums': ['9cbe833d1a8c1d5ea6db87c290119fda4d35a3fe2f7a94d6a88779de502a98e3'],
    }),
]

sanity_pip_check = True

moduleclass = 'lib'
