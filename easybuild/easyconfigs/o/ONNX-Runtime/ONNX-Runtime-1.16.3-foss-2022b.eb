easyblock = 'PythonBundle'

name = 'ONNX-Runtime'
version = '1.16.3'

homepage = 'https://onnxruntime.ai'
description = """ONNX Runtime inference can enable faster customer experiences and lower costs,
supporting models from deep learning frameworks such as PyTorch and
TensorFlow/Keras as well as classical machine learning libraries such as
scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different
hardware, drivers, and operating systems, and provides optimal performance by
leveraging hardware accelerators where applicable alongside graph optimizations
and transforms."""

toolchain = {'name': 'foss', 'version': '2022b'}

dependencies = [
    ('Python', '3.10.8'),
    ('ONNX', '1.15.0'),
    ('flatbuffers-python', '23.1.4'),
    ('sympy', '1.12'),
]

use_pip = True

local_whl_tmpl = 'onnxruntime-%%(version)s-cp310-cp310-manylinux_2_17_%s.manylinux2014_%s.whl'

exts_list = [
    ('humanfriendly', '10.0', {
        'checksums': ['6b0b831ce8f15f7300721aa49829fc4e83921a9a301cc7f606be6686a2288ddc'],
    }),
    ('coloredlogs', '15.0.1', {
        'checksums': ['7c991aa71a4577af2f82600d8f8f3a89f936baeaf9b50a9c197da014e5bf16b0'],
    }),
    (name, version, {
        'source_urls': ['http://pypi.python.org/packages/source/o/onnxruntime'],
        'sources': [local_whl_tmpl % ('%(arch)s', '%(arch)s')],
        'checksums': [{
            local_whl_tmpl % ('x86_64', 'x86_64'):
                'ef2b1fc269cabd27f129fb9058917d6fdc89b188c49ed8700f300b945c81f889',
            local_whl_tmpl % ('aarch64', 'aarch64'):
                '5f91f5497fe3df4ceee2f9e66c6148d9bfeb320cd6a71df361c66c5b8bac985a',
        }],
        'modulename': 'onnxruntime',
    }),
]

sanity_pip_check = True

moduleclass = 'devel'
