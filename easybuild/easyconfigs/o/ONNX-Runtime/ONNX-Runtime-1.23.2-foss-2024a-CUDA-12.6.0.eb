easyblock = 'PythonBundle'

name = 'ONNX-Runtime'
version = '1.23.2'
versionsuffix = '-CUDA-%(cudaver)s'

homepage = 'https://onnxruntime.ai'
description = """ONNX Runtime inference can enable faster customer experiences and lower costs,
supporting models from deep learning frameworks such as PyTorch and
TensorFlow/Keras as well as classical machine learning libraries such as
scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different
hardware, drivers, and operating systems, and provides optimal performance by
leveraging hardware accelerators where applicable alongside graph optimizations
and transforms."""

toolchain = {'name': 'foss', 'version': '2024a'}

builddependencies = [
    ('CMake', '3.31.8'),
    ('Ninja', '1.12.1'),
    ('Eigen', '3.4.0'),
]
dependencies = [
    ('CUDA', '12.6.0', '', SYSTEM),
    ('cuDNN', '9.5.1.17', versionsuffix, SYSTEM),
    ('Python', '3.12.3'),
    ('SciPy-bundle', '2024.05'),
    ('ONNX', '1.20.0'),
    ('flatbuffers-python', '24.3.25'),
    ('sympy', '1.13.3'),
    ('Abseil', '20240722.0'),
]

# CUSTOM BUILD
local_onnx_buildcmd = ""
# do not fetch and install Abseil - use installed one from the module
# https://github.com/microsoft/onnxruntime/blob/v1.23.2/cmake/external/abseil-cpp.cmake#L39
local_onnx_buildcmd += "sed -i 's/20250512/20240722/g' %(start_dir)s/cmake/external/abseil-cpp.cmake && "
# the build command for onnx-runtime wheels
# creates /build/Linux/Release/dist/onnxruntime-1.23.2-cp312-cp312-linux_x86_64.whl
local_onnx_buildcmd += """
./build.sh \
--config Release \
--update --build \
--parallel %(parallel)s \
--use_cuda \
--cuda_home="$EBROOTCUDA" \
--cudnn_home="$EBROOTCUDNN" \
--cuda_version=%(cudashortver)s \
--skip_tests \
--build_shared_lib \
--build_wheel \
--skip_submodule_sync \
--cmake_generator Ninja \
--compile_no_warning_as_error \
--cmake_extra_defines \
absl_DIR=$EBROOTABSEIL/lib/cmake/absl \
"CMAKE_CUDA_ARCHITECTURES=%(cuda_cc_cmake)s" \
ONNXRUNTIME_VERSION=%(version)s
"""

exts_list = [
    ('humanfriendly', '10.0', {
        'checksums': ['6b0b831ce8f15f7300721aa49829fc4e83921a9a301cc7f606be6686a2288ddc'],
    }),
    ('coloredlogs', '15.0.1', {
        'checksums': ['7c991aa71a4577af2f82600d8f8f3a89f936baeaf9b50a9c197da014e5bf16b0'],
    }),
    (name, version, {
        'modulename': 'onnxruntime',
        'buildcmd': local_onnx_buildcmd,
        'install_src': '%(start_dir)s/build/Linux/Release/dist/*.whl',
        'source_urls': ['https://github.com/microsoft/onnxruntime/archive/'],
        'sources': [{'download_filename': 'v%(version)s.tar.gz', 'filename': SOURCE_TAR_GZ}],
        'patches': ['ONNX-Runtime-1.23.2_gpu-package-name.patch'],
        'checksums': [
            {'ONNX-Runtime-1.23.2.tar.gz': '99bcf964ce4e869d823c99b2294562a9050cbfa8e76ec81c8683cb3c7e19c2b4'},
            {'ONNX-Runtime-1.23.2_gpu-package-name.patch':
             'f0b80ae45878be371a1c5ef2b917dc34095af9351dfb379450b7be798f6d43bd'},
        ],
    }),
]

sanity_check_commands = ["python -c 'import onnxruntime; onnxruntime.get_available_providers()'"]

sanity_check_paths = {
    'files': ['bin/onnxruntime_test'],
    'dirs': ['lib'],
}

moduleclass = 'devel'
