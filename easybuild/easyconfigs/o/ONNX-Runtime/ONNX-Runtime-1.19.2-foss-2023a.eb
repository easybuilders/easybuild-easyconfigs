easyblock = 'PythonBundle'

name = 'ONNX-Runtime'
version = '1.19.2'

homepage = 'https://onnxruntime.ai'
description = """ONNX Runtime inference can enable faster customer experiences and lower costs,
supporting models from deep learning frameworks such as PyTorch and
TensorFlow/Keras as well as classical machine learning libraries such as
scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different
hardware, drivers, and operating systems, and provides optimal performance by
leveraging hardware accelerators where applicable alongside graph optimizations
and transforms."""

toolchain = {'name': 'foss', 'version': '2023a'}

dependencies = [
    ('Python', '3.11.3'),
    ('ONNX', '1.15.0'),
    ('flatbuffers-python', '23.5.26'),
    ('sympy', '1.12'),
]

use_pip = True

local_whl_tmpl = 'onnxruntime-%%(version)s-cp311-cp311-manylinux_2_27_%s.manylinux_2_28_%s.whl'

exts_list = [
    ('humanfriendly', '10.0', {
        'checksums': ['6b0b831ce8f15f7300721aa49829fc4e83921a9a301cc7f606be6686a2288ddc'],
    }),
    ('coloredlogs', '15.0.1', {
        'checksums': ['7c991aa71a4577af2f82600d8f8f3a89f936baeaf9b50a9c197da014e5bf16b0'],
    }),
    (name, version, {
        'source_urls': ['http://pypi.python.org/packages/source/o/onnxruntime'],
        'sources': [local_whl_tmpl % ('%(arch)s', '%(arch)s')],
        'checksums': [{
            local_whl_tmpl % ('x86_64', 'x86_64'):
                'a36511dc07c5c964b916697e42e366fa43c48cdb3d3503578d78cef30417cb84',
            local_whl_tmpl % ('aarch64', 'aarch64'):
                'c1dfe4f660a71b31caa81fc298a25f9612815215a47b286236e61d540350d7b6',
        }],
        'modulename': 'onnxruntime',
    }),
]

sanity_pip_check = True

moduleclass = 'devel'
